{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Memory & Conversation Management\n",
    "\n",
    "## Persistent Conversations and Knowledge Integration\n",
    "\n",
    "**Module Duration:** 15 minutes | **Focus:** Memory patterns and knowledge retrieval\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "Master RAG and memory patterns for production conversational AI:\n",
    "\n",
    "- **RAG Architecture:** Retrieval-Augmented Generation with vector search\n",
    "- **FAISS Integration:** Production-grade similarity search and indexing\n",
    "- **Conversation Persistence:** SQLite-based session and turn management\n",
    "- **Context Management:** Token-aware window management and compression\n",
    "- **Memory-Enhanced Agents:** Combining knowledge retrieval with conversation history\n",
    "\n",
    "**What You'll Build:**\n",
    "- Vector similarity search system with FAISS\n",
    "- Persistent conversation storage with SQLite\n",
    "- Memory-enhanced agent with knowledge retrieval\n",
    "- Production-ready memory management patterns\n",
    "\n",
    "This covers memory patterns used in enterprise conversational AI systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† AGENT MEMORY & CONVERSATION MANAGEMENT\n",
      "=============================================\n",
      "Session: 2025-06-16 12:19:43\n",
      "Focus: Vector embeddings and similarity search\n",
      "\n",
      "üîç Testing Vector Embeddings:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c73a5a4b73485aadddba16fced7cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Created embedding for: 'I love programming in Python' (dimension: 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2153de0c63c4fc1abf20e0ffc984445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Created embedding for: 'Python is a great programming language' (dimension: 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80e28da38934341bcfdf94ed6f6c887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Created embedding for: 'The weather is sunny today' (dimension: 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514ae10569f747898088b6f7d4fda363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Created embedding for: 'Machine learning uses algorithms to learn patterns' (dimension: 384)\n",
      "\n",
      "üìä Similarity Analysis:\n",
      "   'I love programming in Python...' vs 'Python is a great programming ...': 0.868\n",
      "   'I love programming in Python...' vs 'The weather is sunny today...': 0.029\n",
      "   'I love programming in Python...' vs 'Machine learning uses algorith...': 0.227\n",
      "   'Python is a great programming ...' vs 'The weather is sunny today...': 0.036\n",
      "   'Python is a great programming ...' vs 'Machine learning uses algorith...': 0.167\n",
      "   'The weather is sunny today...' vs 'Machine learning uses algorith...': 0.019\n",
      "\n",
      "‚úÖ Vector embedding system working:\n",
      "   Sentence transformer model loaded\n",
      "   Embedding dimension: 384\n",
      "   Cosine similarity calculation ready\n"
     ]
    }
   ],
   "source": [
    "# Vector Embeddings & Similarity Foundation\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üß† AGENT MEMORY & CONVERSATION MANAGEMENT\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Session: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"Focus: Vector embeddings and similarity search\")\n",
    "print()\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def create_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"Create normalized embedding for text\"\"\"\n",
    "    embedding = embedding_model.encode([text])[0]\n",
    "    # Normalize for cosine similarity\n",
    "    return embedding / np.linalg.norm(embedding)\n",
    "\n",
    "def calculate_similarity(embedding1: np.ndarray, embedding2: np.ndarray) -> float:\n",
    "    \"\"\"Calculate cosine similarity between embeddings\"\"\"\n",
    "    return float(np.dot(embedding1, embedding2))\n",
    "\n",
    "# Test embedding functionality\n",
    "print(\"üîç Testing Vector Embeddings:\")\n",
    "test_texts = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python is a great programming language\", \n",
    "    \"The weather is sunny today\",\n",
    "    \"Machine learning uses algorithms to learn patterns\"\n",
    "]\n",
    "\n",
    "embeddings = []\n",
    "for text in test_texts:\n",
    "    embedding = create_embedding(text)\n",
    "    embeddings.append((text, embedding))\n",
    "    print(f\"   ‚úÖ Created embedding for: '{text}' (dimension: {len(embedding)})\")\n",
    "\n",
    "# Test similarity\n",
    "print(\"\\nüìä Similarity Analysis:\")\n",
    "for i in range(len(embeddings)):\n",
    "    for j in range(i+1, len(embeddings)):\n",
    "        text1, emb1 = embeddings[i]\n",
    "        text2, emb2 = embeddings[j]\n",
    "        similarity = calculate_similarity(emb1, emb2)\n",
    "        print(f\"   '{text1[:30]}...' vs '{text2[:30]}...': {similarity:.3f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Vector embedding system working:\")\n",
    "print(\"   Sentence transformer model loaded\")\n",
    "print(\"   Embedding dimension: {len(embeddings[0][1])}\")\n",
    "print(\"   Cosine similarity calculation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAISS Integration for Fast Similarity Search\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) enables efficient similarity search across large collections of vectors:\n",
    "\n",
    "**Key Benefits:**\n",
    "- **Speed:** Optimized for fast nearest neighbor search\n",
    "- **Scalability:** Handles millions of vectors efficiently\n",
    "- **Flexibility:** Multiple index types for different use cases\n",
    "- **Memory Efficiency:** Optimized storage and retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Testing FAISS Vector Memory:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a291870389400cba66e03bc2f63733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Added memory: 24d502ea - 'Python is a programming language known for simplic...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee6e2d145dd455ab977aa4b49ab2775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Added memory: e1490352 - 'Machine learning enables computers to learn from d...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e919689ae3ef48c3982248f4ce6e3353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Added memory: 717c6814 - 'FAISS provides efficient similarity search for lar...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b9c5e05a6a4018881d5f7aaa943d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Added memory: 21a32a20 - 'Vector databases store high-dimensional embeddings...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326c46a3b354405b9ff4395266e8b464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Added memory: f6e2d78b - 'Natural language processing helps computers unders...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Testing Vector Search:\n",
      "\n",
      "   Query: 'programming languages'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201b3bc9b3f547e9b29981c523c04930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory search for 'programming languages...' found 2 matches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Match (score: 0.579): Python is a programming language known for simplicity and readability\n",
      "   ‚úÖ Match (score: 0.401): Natural language processing helps computers understand human language\n",
      "\n",
      "   Query: 'artificial intelligence and learning'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d57c63d8bd44803a7208e4cb6fb8cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory search for 'artificial intelligence and le...' found 2 matches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Match (score: 0.522): Machine learning enables computers to learn from data automatically\n",
      "   ‚úÖ Match (score: 0.359): Natural language processing helps computers understand human language\n",
      "\n",
      "   Query: 'search algorithms'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1605687bcf2437a850847a25a7e3d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory search for 'search algorithms...' found 2 matches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Match (score: 0.457): FAISS provides efficient similarity search for large vector collections\n",
      "   ‚úÖ Match (score: 0.401): Vector databases store high-dimensional embeddings for semantic search\n",
      "\n",
      "‚úÖ FAISS vector memory system ready:\n",
      "   Total entries: 5\n",
      "   Vector dimension: 384\n",
      "   FAISS index size: 5\n"
     ]
    }
   ],
   "source": [
    "# FAISS Integration for Vector Search\n",
    "import faiss\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MemoryEntry:\n",
    "    \"\"\"Structured memory entry with metadata\"\"\"\n",
    "    entry_id: str\n",
    "    content: str\n",
    "    embedding: np.ndarray\n",
    "    metadata: Dict[str, Any]\n",
    "    created_at: str\n",
    "\n",
    "class VectorMemorySystem:\n",
    "    \"\"\"Production vector memory with FAISS\"\"\"\n",
    "    \n",
    "    def __init__(self, dimension: int = 384):\n",
    "        self.dimension = dimension\n",
    "        self.index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
    "        self.entries = []\n",
    "        self.entry_map = {}  # Maps FAISS index to entry_id\n",
    "        \n",
    "    def add_memory(self, content: str, metadata: Dict[str, Any] = None) -> str:\n",
    "        \"\"\"Add content to vector memory\"\"\"\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "            \n",
    "        entry_id = str(uuid.uuid4())\n",
    "        embedding = create_embedding(content)\n",
    "        \n",
    "        # Create memory entry\n",
    "        entry = MemoryEntry(\n",
    "            entry_id=entry_id,\n",
    "            content=content,\n",
    "            embedding=embedding,\n",
    "            metadata=metadata,\n",
    "            created_at=datetime.now().isoformat()\n",
    "        )\n",
    "        \n",
    "        # Add to FAISS index\n",
    "        faiss_index = len(self.entries)\n",
    "        self.index.add(embedding.reshape(1, -1))\n",
    "        self.entries.append(entry)\n",
    "        self.entry_map[faiss_index] = entry_id\n",
    "        \n",
    "        logger.info(f\"Added memory: {entry_id[:8]} - '{content[:50]}...'\")\n",
    "        return entry_id\n",
    "    \n",
    "    def search_memory(self, query: str, top_k: int = 5, threshold: float = 0.3) -> List[Tuple[MemoryEntry, float]]:\n",
    "        \"\"\"Search memory using vector similarity\"\"\"\n",
    "        if len(self.entries) == 0:\n",
    "            return []\n",
    "        \n",
    "        query_embedding = create_embedding(query)\n",
    "        scores, indices = self.index.search(query_embedding.reshape(1, -1), min(top_k, len(self.entries)))\n",
    "        \n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], indices[0]):\n",
    "            if score >= threshold:\n",
    "                entry = self.entries[idx]\n",
    "                results.append((entry, float(score)))\n",
    "        \n",
    "        logger.info(f\"Memory search for '{query[:30]}...' found {len(results)} matches\")\n",
    "        return results\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get memory statistics\"\"\"\n",
    "        return {\n",
    "            \"total_entries\": len(self.entries),\n",
    "            \"index_size\": self.index.ntotal,\n",
    "            \"dimension\": self.dimension\n",
    "        }\n",
    "\n",
    "# Initialize vector memory\n",
    "vector_memory = VectorMemorySystem()\n",
    "\n",
    "# Test with knowledge entries\n",
    "print(\"\\nüîß Testing FAISS Vector Memory:\")\n",
    "knowledge_base = [\n",
    "    (\"Python is a programming language known for simplicity and readability\", {\"topic\": \"programming\"}),\n",
    "    (\"Machine learning enables computers to learn from data automatically\", {\"topic\": \"ai\"}),\n",
    "    (\"FAISS provides efficient similarity search for large vector collections\", {\"topic\": \"search\"}),\n",
    "    (\"Vector databases store high-dimensional embeddings for semantic search\", {\"topic\": \"databases\"}),\n",
    "    (\"Natural language processing helps computers understand human language\", {\"topic\": \"nlp\"})\n",
    "]\n",
    "\n",
    "for content, metadata in knowledge_base:\n",
    "    entry_id = vector_memory.add_memory(content, metadata)\n",
    "\n",
    "# Test search functionality\n",
    "print(\"\\nüîç Testing Vector Search:\")\n",
    "test_queries = [\n",
    "    \"programming languages\",\n",
    "    \"artificial intelligence and learning\", \n",
    "    \"search algorithms\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n   Query: '{query}'\")\n",
    "    results = vector_memory.search_memory(query, top_k=2)\n",
    "    for entry, score in results:\n",
    "        print(f\"   ‚úÖ Match (score: {score:.3f}): {entry.content}\")\n",
    "\n",
    "print(\"\\n‚úÖ FAISS vector memory system ready:\")\n",
    "stats = vector_memory.get_stats()\n",
    "print(\"   Total entries: {stats['total_entries']}\")\n",
    "print(\"   Vector dimension: {stats['dimension']}\")\n",
    "print(\"   FAISS index size: {stats['index_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Persistence with SQLite\n",
    "\n",
    "For production memory systems, we need persistent storage that survives agent restarts:\n",
    "\n",
    "**Storage Requirements:**\n",
    "- **Session Management:** Track individual conversation sessions\n",
    "- **Turn Storage:** Store each user-agent interaction\n",
    "- **Metadata Tracking:** Context and knowledge retrieval logging\n",
    "- **Query Performance:** Fast retrieval of conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Database initialized: agent_memory.db\n",
      "INFO:__main__:Created session: f677dcc9 for user demo_user\n",
      "INFO:__main__:Saved turn: 7dde1afc for session f677dcc9\n",
      "INFO:__main__:Saved turn: 252f8ca2 for session f677dcc9\n",
      "INFO:__main__:Saved turn: 3091fef5 for session f677dcc9\n",
      "INFO:__main__:Retrieved 3 turns for session f677dcc9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Testing Conversation Persistence:\n",
      "\n",
      "üìö Testing History Retrieval:\n",
      "   Turn 1:\n",
      "     User: Hello, I'm learning about AI\n",
      "     Agent: Hi! I'd be happy to help you learn about AI. What specifically interests you?\n",
      "   Turn 2:\n",
      "     User: What is machine learning?\n",
      "     Agent: Machine learning is a subset of AI that enables computers to learn from data without explicit programming.\n",
      "   Turn 3:\n",
      "     User: How does it relate to neural networks?\n",
      "     Agent: Neural networks are one approach to machine learning, inspired by how biological brains process information.\n",
      "\n",
      "‚úÖ Conversation persistence ready:\n",
      "   SQLite database: agent_memory.db\n",
      "   Session tracking with turn history\n",
      "   Knowledge usage logging\n"
     ]
    }
   ],
   "source": [
    "# Conversation Persistence Manager\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ConversationTurn:\n",
    "    \"\"\"Individual conversation turn with metadata\"\"\"\n",
    "    turn_id: str\n",
    "    session_id: str\n",
    "    timestamp: str\n",
    "    user_message: str\n",
    "    agent_response: str\n",
    "    knowledge_used: List[str]\n",
    "\n",
    "class ConversationManager:\n",
    "    \"\"\"Manages conversation persistence with SQLite\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"agent_memory.db\"):\n",
    "        self.db_path = db_path\n",
    "        self.init_database()\n",
    "        \n",
    "    def init_database(self):\n",
    "        \"\"\"Initialize SQLite database\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Sessions table\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS sessions (\n",
    "                session_id TEXT PRIMARY KEY,\n",
    "                user_id TEXT NOT NULL,\n",
    "                started_at TEXT NOT NULL,\n",
    "                last_active TEXT NOT NULL,\n",
    "                total_turns INTEGER DEFAULT 0\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Conversation turns table\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS turns (\n",
    "                turn_id TEXT PRIMARY KEY,\n",
    "                session_id TEXT NOT NULL,\n",
    "                timestamp TEXT NOT NULL,\n",
    "                user_message TEXT NOT NULL,\n",
    "                agent_response TEXT NOT NULL,\n",
    "                knowledge_used TEXT,\n",
    "                FOREIGN KEY (session_id) REFERENCES sessions (session_id)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        logger.info(f\"Database initialized: {self.db_path}\")\n",
    "    \n",
    "    def create_session(self, user_id: str) -> str:\n",
    "        \"\"\"Create new conversation session\"\"\"\n",
    "        session_id = str(uuid.uuid4())\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        \n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            INSERT INTO sessions (session_id, user_id, started_at, last_active, total_turns)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        ''', (session_id, user_id, timestamp, timestamp, 0))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        logger.info(f\"Created session: {session_id[:8]} for user {user_id}\")\n",
    "        return session_id\n",
    "    \n",
    "    def save_turn(self, session_id: str, user_message: str, agent_response: str, \n",
    "                  knowledge_used: List[str] = None) -> str:\n",
    "        \"\"\"Save conversation turn\"\"\"\n",
    "        turn_id = str(uuid.uuid4())\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        \n",
    "        if knowledge_used is None:\n",
    "            knowledge_used = []\n",
    "        \n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Save turn\n",
    "        cursor.execute('''\n",
    "            INSERT INTO turns (turn_id, session_id, timestamp, user_message, agent_response, knowledge_used)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        ''', (turn_id, session_id, timestamp, user_message, agent_response, json.dumps(knowledge_used)))\n",
    "        \n",
    "        # Update session\n",
    "        cursor.execute('''\n",
    "            UPDATE sessions SET last_active = ?, total_turns = total_turns + 1\n",
    "            WHERE session_id = ?\n",
    "        ''', (timestamp, session_id))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        logger.info(f\"Saved turn: {turn_id[:8]} for session {session_id[:8]}\")\n",
    "        return turn_id\n",
    "    \n",
    "    def get_conversation_history(self, session_id: str, last_n: int = 5) -> List[ConversationTurn]:\n",
    "        \"\"\"Get recent conversation history\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            SELECT turn_id, session_id, timestamp, user_message, agent_response, knowledge_used\n",
    "            FROM turns WHERE session_id = ?\n",
    "            ORDER BY timestamp DESC LIMIT ?\n",
    "        ''', (session_id, last_n))\n",
    "        \n",
    "        turns = []\n",
    "        for row in cursor.fetchall():\n",
    "            turn = ConversationTurn(\n",
    "                turn_id=row[0],\n",
    "                session_id=row[1], \n",
    "                timestamp=row[2],\n",
    "                user_message=row[3],\n",
    "                agent_response=row[4],\n",
    "                knowledge_used=json.loads(row[5]) if row[5] else []\n",
    "            )\n",
    "            turns.append(turn)\n",
    "        \n",
    "        conn.close()\n",
    "        turns.reverse()  # Chronological order\n",
    "        \n",
    "        logger.info(f\"Retrieved {len(turns)} turns for session {session_id[:8]}\")\n",
    "        return turns\n",
    "\n",
    "# Initialize conversation manager\n",
    "conversation_manager = ConversationManager()\n",
    "\n",
    "# Test conversation persistence\n",
    "print(\"\\nüíæ Testing Conversation Persistence:\")\n",
    "test_session = conversation_manager.create_session(\"demo_user\")\n",
    "\n",
    "# Save some test conversations\n",
    "test_conversations = [\n",
    "    (\"Hello, I'm learning about AI\", \"Hi! I'd be happy to help you learn about AI. What specifically interests you?\"),\n",
    "    (\"What is machine learning?\", \"Machine learning is a subset of AI that enables computers to learn from data without explicit programming.\"),\n",
    "    (\"How does it relate to neural networks?\", \"Neural networks are one approach to machine learning, inspired by how biological brains process information.\")\n",
    "]\n",
    "\n",
    "for user_msg, agent_resp in test_conversations:\n",
    "    turn_id = conversation_manager.save_turn(test_session, user_msg, agent_resp, [\"ai_knowledge\"])\n",
    "\n",
    "# Test retrieval\n",
    "print(\"\\nüìö Testing History Retrieval:\")\n",
    "history = conversation_manager.get_conversation_history(test_session, last_n=3)\n",
    "for i, turn in enumerate(history, 1):\n",
    "    print(f\"   Turn {i}:\")\n",
    "    print(f\"     User: {turn.user_message}\")\n",
    "    print(f\"     Agent: {turn.agent_response}\")\n",
    "\n",
    "print(\"\\n‚úÖ Conversation persistence ready:\")\n",
    "print(\"   SQLite database: {conversation_manager.db_path}\")\n",
    "print(\"   Session tracking with turn history\")\n",
    "print(\"   Knowledge usage logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-Enhanced Agent Integration\n",
    "\n",
    "Now we combine vector memory and conversation persistence with ADK agents:\n",
    "\n",
    "**Integration Features:**\n",
    "- **Context Building:** Combine conversation history with relevant knowledge\n",
    "- **Smart Retrieval:** Search knowledge based on current conversation\n",
    "- **Response Enhancement:** Use retrieved context to improve responses\n",
    "- **Memory Tracking:** Log what knowledge and context influenced each response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Created session: ebe381a2 for user demo_user\n",
      "INFO:__main__:Memory agent ready - Conversation: ebe381a2, ADK: adk_ebe3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory-enhanced agent ready:\n",
      "   Vector knowledge retrieval integrated\n",
      "   Conversation history tracking\n",
      "   Context-aware response generation\n",
      "   Session management fixed\n"
     ]
    }
   ],
   "source": [
    "# Memory-Enhanced Agent with ADK (Fixed Session Management)\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.genai import types\n",
    "\n",
    "class MemoryAgent:\n",
    "    \"\"\"Agent with vector memory and conversation persistence\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vector_memory = vector_memory\n",
    "        self.conversation_manager = conversation_manager\n",
    "        self.current_session = None\n",
    "        self.adk_session_id = None  # Separate ADK session ID\n",
    "        \n",
    "    async def setup(self, user_id: str = \"demo_user\"):\n",
    "        \"\"\"Initialize memory-enhanced agent\"\"\"\n",
    "        # Create conversation session\n",
    "        self.current_session = self.conversation_manager.create_session(user_id)\n",
    "        \n",
    "        # Create separate ADK session ID\n",
    "        self.adk_session_id = f\"adk_{self.current_session}\"\n",
    "        \n",
    "        # Setup ADK agent\n",
    "        model = LiteLlm(model=\"ollama_chat/llama3.2:latest\")\n",
    "        \n",
    "        self.agent = Agent(\n",
    "            name=\"MemoryAgent\",\n",
    "            model=model,\n",
    "            instruction=\"\"\"You are an intelligent agent with persistent memory capabilities.\n",
    "\n",
    "You have access to:\n",
    "- A knowledge base with relevant information\n",
    "- Previous conversation history with this user\n",
    "- Context from past interactions\n",
    "\n",
    "When responding:\n",
    "1. Use relevant knowledge from your memory when helpful\n",
    "2. Reference previous conversations naturally\n",
    "3. Build on past context to provide personalized responses\n",
    "4. Be conversational and remember what you've discussed\n",
    "\n",
    "Always be helpful and maintain conversation continuity.\"\"\"\n",
    "        )\n",
    "        \n",
    "        self.session_service = InMemorySessionService()\n",
    "        self.runner = Runner(\n",
    "            agent=self.agent,\n",
    "            app_name=\"memory_agent\", \n",
    "            session_service=self.session_service\n",
    "        )\n",
    "        \n",
    "        # Create ADK session with the correct ID\n",
    "        await self.session_service.create_session(\n",
    "            app_name=\"memory_agent\",\n",
    "            user_id=user_id,\n",
    "            session_id=self.adk_session_id\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Memory agent ready - Conversation: {self.current_session[:8]}, ADK: {self.adk_session_id[:8]}\")\n",
    "    \n",
    "    async def chat(self, user_message: str) -> str:\n",
    "        \"\"\"Chat with memory-enhanced responses\"\"\"\n",
    "        # Search relevant knowledge\n",
    "        knowledge_results = self.vector_memory.search_memory(user_message, top_k=3, threshold=0.2)\n",
    "        relevant_knowledge = [entry.content for entry, score in knowledge_results]\n",
    "        \n",
    "        # Get conversation history\n",
    "        history = self.conversation_manager.get_conversation_history(self.current_session, last_n=3)\n",
    "        \n",
    "        # Build context\n",
    "        context_parts = []\n",
    "        \n",
    "        if relevant_knowledge:\n",
    "            context_parts.append(\"Relevant Knowledge:\")\n",
    "            for knowledge in relevant_knowledge:\n",
    "                context_parts.append(f\"- {knowledge}\")\n",
    "        \n",
    "        if history:\n",
    "            context_parts.append(\"\\nRecent Conversation:\")\n",
    "            for turn in history:\n",
    "                context_parts.append(f\"User: {turn.user_message}\")\n",
    "                context_parts.append(f\"Assistant: {turn.agent_response}\")\n",
    "        \n",
    "        context_parts.append(f\"\\nCurrent User Message: {user_message}\")\n",
    "        \n",
    "        enhanced_message = \"\\n\".join(context_parts)\n",
    "        \n",
    "        # Send to agent using the correct ADK session ID\n",
    "        message = types.Content(role=\"user\", parts=[types.Part(text=enhanced_message)])\n",
    "        \n",
    "        response = \"\"\n",
    "        async for event in self.runner.run_async(\n",
    "            user_id=\"memory_user\",\n",
    "            session_id=self.adk_session_id,  # Use ADK session ID here\n",
    "            new_message=message\n",
    "        ):\n",
    "            if event.is_final_response():\n",
    "                response = event.content.parts[0].text\n",
    "                break\n",
    "        \n",
    "        # Save conversation using conversation session ID\n",
    "        knowledge_used = [f\"{entry.content[:50]}...\" for entry, _ in knowledge_results]\n",
    "        self.conversation_manager.save_turn(self.current_session, user_message, response, knowledge_used)\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Initialize memory agent\n",
    "memory_agent = MemoryAgent()\n",
    "await memory_agent.setup(\"demo_user\")\n",
    "\n",
    "print(\"‚úÖ Memory-enhanced agent ready:\")\n",
    "print(\"   Vector knowledge retrieval integrated\")\n",
    "print(\"   Conversation history tracking\")\n",
    "print(\"   Context-aware response generation\")\n",
    "print(\"   Session management fixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory System Demonstration\n",
    "\n",
    "Let's test the complete memory system with realistic conversations:\n",
    "\n",
    "**Test Scenarios:**\n",
    "- **Knowledge Integration:** Agent uses vector search to find relevant information\n",
    "- **Conversation Continuity:** Agent remembers previous discussion points\n",
    "- **Context Building:** Combines knowledge and history for better responses\n",
    "- **Memory Tracking:** Logs what information influenced each response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ MEMORY SYSTEM DEMONSTRATION\n",
      "===================================\n",
      "\n",
      "üí¨ Memory-Enhanced Conversations:\n",
      "\n",
      "--- Turn 1 ---\n",
      "üë§ User: Hi, I'm interested in learning about Python programming\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c072e033077455d83c33447280d7b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory search for 'Hi, I'm interested in learning...' found 2 matches\n",
      "INFO:__main__:Retrieved 0 turns for session ebe381a2\n",
      "\u001b[92m12:39:38 - LiteLLM:INFO\u001b[0m: utils.py:3119 - \n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:40:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Saved turn: b03306f6 for session ebe381a2\n",
      "/Users/pragatikunwer/PycharmProjects/google-adk-course/google-adk-enterprise-agents/.venv/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content=\"Hello! W...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:40:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: Hello! Welcome to our conversation about Python programming. It's great that you're interested in learning more about it.\n",
      "\n",
      "Python is indeed an excellent choice for beginners and experienced programmers alike due to its simplicity, readability, and versatility. One of the key features of Python is its syntax, which is designed to be easy to understand and write. This makes it a fantastic language for rapid prototyping and development.\n",
      "\n",
      "I'd like to know more about your goals with learning Python. Are you looking to get started with programming in general, or do you have a specific project or area of interest (e.g., data science, web development) that you'd like to explore?\n",
      "\n",
      "Also, since we're just getting started, I'll mention that natural language processing can play a significant role in automating tasks, such as text analysis and machine learning. But for now, let's focus on the basics of Python programming.\n",
      "\n",
      "What do you think? Would you like to start with some basic tutorials or explore a specific area of Python programming?\n",
      "\n",
      "--- Turn 2 ---\n",
      "üë§ User: What makes Python good for machine learning?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa2d9bd4e0d4a8b9282aa626fe67c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory search for 'What makes Python good for mac...' found 3 matches\n",
      "INFO:__main__:Retrieved 1 turns for session ebe381a2\n",
      "\u001b[92m12:40:09 - LiteLLM:INFO\u001b[0m: utils.py:3119 - \n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:40:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Saved turn: 28853cc4 for session ebe381a2\n",
      "/Users/pragatikunwer/PycharmProjects/google-adk-course/google-adk-enterprise-agents/.venv/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content=\"A natura...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:40:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: A natural follow-up question! You're interested in exploring how Python can be used for machine learning, which is an exciting field that's all about enabling computers to learn from data automatically.\n",
      "\n",
      "Python is an excellent choice for machine learning because of its simplicity and readability, making it easy for developers to write and implement machine learning algorithms. Additionally, Python has a vast array of libraries and frameworks that make machine learning more accessible, such as scikit-learn, TensorFlow, and Keras.\n",
      "\n",
      "One of the key reasons Python is well-suited for machine learning is its ability to handle large datasets efficiently. With libraries like Pandas and NumPy, you can easily manipulate and analyze data in Python, which makes it a great choice for tasks like data preprocessing, feature engineering, and model training.\n",
      "\n",
      "Another advantage of using Python for machine learning is its flexibility. You can use it to develop both supervised and unsupervised learning models, as well as neural networks, decision trees, and more.\n",
      "\n",
      "From our previous conversation, I mentioned natural language processing (NLP), which can also play a significant role in machine learning applications like text classification, sentiment analysis, and topic modeling. Python's NLP libraries, such as NLTK and spaCy, make it easy to work with human language data and build intelligent systems that can understand and generate human-like text.\n",
      "\n",
      "Would you like to explore some examples of machine learning projects in Python or dive deeper into the world of NLP?\n",
      "\n",
      "--- Turn 3 ---\n",
      "üë§ User: Can you explain how vector search works?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a1a06b0290446aa7ebea3d0e5f8d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory search for 'Can you explain how vector sea...' found 3 matches\n",
      "INFO:__main__:Retrieved 2 turns for session ebe381a2\n",
      "\u001b[92m12:40:43 - LiteLLM:INFO\u001b[0m: utils.py:3119 - \n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:41:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Saved turn: ad033332 for session ebe381a2\n",
      "/Users/pragatikunwer/PycharmProjects/google-adk-course/google-adk-enterprise-agents/.venv/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content=\"Vector s...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:41:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: Vector search! That's a fantastic topic, especially for those interested in data science and natural language processing. Vector search is a technique used to find similar items within a large dataset by representing each item as a dense vector.\n",
      "\n",
      "In the context of natural language processing (NLP), vector search is often applied to text documents or entities in a database. These vectors are usually high-dimensional, meaning they have many features that describe the document or entity, such as word frequencies, sentiment scores, and semantic roles.\n",
      "\n",
      "The goal of vector search is to find similar items in the dataset by computing the cosine similarity between all pairs of vectors. This allows us to identify documents or entities that share similar characteristics, such as topics, themes, or even emotional tone.\n",
      "\n",
      "One popular library for efficient vector search is FAISS (Facebook AI Similarity Search). FAISS provides a fast and scalable way to compute similarities between vectors, making it an excellent choice for large-scale applications. It's especially useful in scenarios where you need to query millions of documents in a database to find the most relevant results.\n",
      "\n",
      "To illustrate this concept better, imagine you're building a search engine that needs to index and retrieve similar web pages based on their content. By representing each web page as a dense vector, you can use FAISS or another vector search library to quickly identify the most relevant pages when a user submits a query.\n",
      "\n",
      "Now, let's dive deeper into how this works in practice. Are you interested in exploring some examples of how FAISS is used in real-world applications or would you like me to provide more details on the underlying mathematics behind vector search?\n",
      "\n",
      "--- Turn 4 ---\n",
      "üë§ User: Earlier you mentioned Python - what did you say about its advantages?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e065d7851b1043199c90c3da97b0deba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory search for 'Earlier you mentioned Python -...' found 2 matches\n",
      "INFO:__main__:Retrieved 3 turns for session ebe381a2\n",
      "\u001b[92m12:41:30 - LiteLLM:INFO\u001b[0m: utils.py:3119 - \n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:42:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Saved turn: aa6bde0a for session ebe381a2\n",
      "/Users/pragatikunwer/PycharmProjects/google-adk-course/google-adk-enterprise-agents/.venv/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content=\"You're r...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:42:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: You're referring back to our earlier conversation about the advantages of using Python for machine learning and other tasks. I mentioned that Python is an excellent choice due to its simplicity, readability, and versatility.\n",
      "\n",
      "One of the key features of Python is its syntax, which is designed to be easy to understand and write. This makes it a fantastic language for rapid prototyping and development. Additionally, Python has a vast array of libraries and frameworks that make many tasks more accessible, such as scikit-learn, TensorFlow, and Keras.\n",
      "\n",
      "I also mentioned that Python's simplicity and readability allow developers to focus on writing code rather than wrestling with complex syntax or semantics. This makes it an ideal choice for beginners and experienced programmers alike, regardless of their background or experience level.\n",
      "\n",
      "Moreover, Python's versatility is another significant advantage. It can be used for a wide range of applications, from web development and data science to machine learning, scientific computing, and more. Its large community and extensive libraries make it easy to find resources, libraries, and tools to help you tackle specific challenges.\n",
      "\n",
      "Overall, Python's unique combination of simplicity, readability, and versatility makes it an incredibly powerful tool for anyone looking to learn programming or expand their skills in the field of machine learning and other areas.\n",
      "\n",
      "Would you like me to elaborate on any specific aspect of Python's advantages or dive into some examples of how its simplicity and versatility can be put into practice?\n",
      "\n",
      "--- Turn 5 ---\n",
      "üë§ User: How do vector databases help with the machine learning concepts we discussed?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7649058cbb49471fb33dd02baabeba0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory search for 'How do vector databases help w...' found 3 matches\n",
      "INFO:__main__:Retrieved 3 turns for session ebe381a2\n",
      "\u001b[92m12:42:27 - LiteLLM:INFO\u001b[0m: utils.py:3119 - \n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:43:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Saved turn: 2eda09c1 for session ebe381a2\n",
      "/Users/pragatikunwer/PycharmProjects/google-adk-course/google-adk-enterprise-agents/.venv/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content=\"Vector d...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:43:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:LiteLLM:selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: Vector databases play a crucial role in supporting machine learning concepts, particularly those related to natural language processing (NLP) and semantic search. By storing high-dimensional embeddings for text documents or entities in a database, vector databases enable efficient similarity searches that are essential for many machine learning applications.\n",
      "\n",
      "In the context of NLP, vector databases can be used to store and query dense vectors representing words, phrases, or entire texts. This allows developers to perform tasks like language modeling, sentiment analysis, and topic modeling more efficiently. Vector databases also support techniques like word embeddings, which map words to vectors that capture their semantic meaning.\n",
      "\n",
      "For example, in a search engine application, vector databases can be used to store the dense vectors of web pages. When a user submits a query, the database can quickly retrieve the most relevant documents by computing the similarity between the query vector and the document vectors stored in the database. This enables fast and scalable searching, even when dealing with millions of documents.\n",
      "\n",
      "FAISS (Facebook AI Similarity Search) is an excellent choice for these applications because it provides efficient and scalable similarity search capabilities. By using FAISS, developers can leverage the power of vector databases to build sophisticated NLP systems that support a wide range of machine learning tasks.\n",
      "\n",
      "To illustrate this further, imagine you're building a conversational AI system that needs to understand user intent behind natural language inputs. A vector database can be used to store and query dense vectors representing words, phrases, or entire sentences. By computing the similarity between user input vectors and stored document vectors, the system can identify relevant documents and provide more accurate responses.\n",
      "\n",
      "Overall, vector databases play a vital role in supporting machine learning concepts like NLP, semantic search, and text analysis by providing efficient and scalable ways to store, query, and analyze high-dimensional data.\n",
      "\n",
      "Would you like me to elaborate on how vector databases can be used in specific real-world applications or explore some examples of how they support other machine learning tasks?\n",
      "\n",
      "üìä MEMORY SYSTEM ANALYSIS\n",
      "==============================\n",
      "\n",
      "üß† Vector Memory:\n",
      "   Knowledge Entries: 5\n",
      "   Vector Dimension: 384\n",
      "   FAISS Index Size: 5\n",
      "\n",
      "üîç Knowledge Retrieval Test:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0f88f80e8f4f32b542c2ea3dda9e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Memory search for 'programming and artificial int...' found 3 matches\n",
      "INFO:__main__:Retrieved 5 turns for session ebe381a2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Query: 'programming and artificial intelligence'\n",
      "   ‚úÖ 0.468: Python is a programming language known for simplicity and re...\n",
      "   ‚úÖ 0.431: Machine learning enables computers to learn from data automa...\n",
      "   ‚úÖ 0.425: Natural language processing helps computers understand human...\n",
      "\n",
      "üí¨ Conversation History:\n",
      "   Total turns in session: 5\n",
      "   Session ID: ebe381a2\n",
      "\n",
      "‚úÖ MEMORY SYSTEM DEMONSTRATION COMPLETE:\n",
      "   ‚úÖ Vector Knowledge Base: Semantic search with FAISS\n",
      "   ‚úÖ Persistent Conversations: SQLite storage with history\n",
      "   ‚úÖ Context Integration: Knowledge + history in responses\n",
      "   ‚úÖ Memory Tracking: What knowledge influenced each response\n",
      "   ‚úÖ Production Ready: Scalable architecture with enterprise patterns\n"
     ]
    }
   ],
   "source": [
    "# Complete Memory System Demonstration\n",
    "\n",
    "# Update the existing chat method directly\n",
    "async def chat(self, user_message: str) -> str:\n",
    "    \"\"\"Chat with memory-enhanced responses\"\"\"\n",
    "    # Search relevant knowledge\n",
    "    knowledge_results = self.vector_memory.search_memory(user_message, top_k=3, threshold=0.2)\n",
    "    relevant_knowledge = [entry.content for entry, score in knowledge_results]\n",
    "    \n",
    "    # Get conversation history\n",
    "    history = self.conversation_manager.get_conversation_history(self.current_session, last_n=3)\n",
    "    \n",
    "    # Build context\n",
    "    context_parts = []\n",
    "    \n",
    "    if relevant_knowledge:\n",
    "        context_parts.append(\"Relevant Knowledge:\")\n",
    "        for knowledge in relevant_knowledge:\n",
    "            context_parts.append(f\"- {knowledge}\")\n",
    "    \n",
    "    if history:\n",
    "        context_parts.append(\"\\nRecent Conversation:\")\n",
    "        for turn in history:\n",
    "            context_parts.append(f\"User: {turn.user_message}\")\n",
    "            context_parts.append(f\"Assistant: {turn.agent_response}\")\n",
    "    \n",
    "    context_parts.append(f\"\\nCurrent User Message: {user_message}\")\n",
    "    \n",
    "    enhanced_message = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # Send to agent using the correct user_id\n",
    "    message = types.Content(role=\"user\", parts=[types.Part(text=enhanced_message)])\n",
    "    \n",
    "    response = \"\"\n",
    "    async for event in self.runner.run_async(\n",
    "        user_id=\"demo_user\",  # Fixed: use same user_id as setup\n",
    "        session_id=self.adk_session_id,\n",
    "        new_message=message\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            response = event.content.parts[0].text\n",
    "            break\n",
    "    \n",
    "    # Save conversation\n",
    "    knowledge_used = [f\"{entry.content[:50]}...\" for entry, _ in knowledge_results]\n",
    "    self.conversation_manager.save_turn(self.current_session, user_message, response, knowledge_used)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Update the method properly\n",
    "MemoryAgent.chat = chat\n",
    "\n",
    "async def demonstrate_memory_system():\n",
    "    \"\"\"Test memory-enhanced conversations\"\"\"\n",
    "    \n",
    "    print(\"üß™ MEMORY SYSTEM DEMONSTRATION\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    conversations = [\n",
    "        \"Hi, I'm interested in learning about Python programming\",\n",
    "        \"What makes Python good for machine learning?\", \n",
    "        \"Can you explain how vector search works?\",\n",
    "        \"Earlier you mentioned Python - what did you say about its advantages?\",\n",
    "        \"How do vector databases help with the machine learning concepts we discussed?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüí¨ Memory-Enhanced Conversations:\")\n",
    "    \n",
    "    for i, user_message in enumerate(conversations, 1):\n",
    "        print(f\"\\n--- Turn {i} ---\")\n",
    "        print(f\"üë§ User: {user_message}\")\n",
    "        \n",
    "        response = await memory_agent.chat(user_message)\n",
    "        print(f\"ü§ñ Agent: {response}\")\n",
    "        \n",
    "        await asyncio.sleep(0.5)\n",
    "\n",
    "# Run demonstration\n",
    "await demonstrate_memory_system()\n",
    "\n",
    "print(\"\\nüìä MEMORY SYSTEM ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Memory statistics\n",
    "memory_stats = vector_memory.get_stats()\n",
    "print(\"\\nüß† Vector Memory:\")\n",
    "print(f\"   Knowledge Entries: {memory_stats['total_entries']}\")\n",
    "print(f\"   Vector Dimension: {memory_stats['dimension']}\")\n",
    "print(f\"   FAISS Index Size: {memory_stats['index_size']}\")\n",
    "\n",
    "# Test knowledge retrieval\n",
    "print(\"\\nüîç Knowledge Retrieval Test:\")\n",
    "test_query = \"programming and artificial intelligence\"\n",
    "results = vector_memory.search_memory(test_query, top_k=3)\n",
    "print(f\"   Query: '{test_query}'\")\n",
    "for entry, score in results:\n",
    "    print(f\"   ‚úÖ {score:.3f}: {entry.content[:60]}...\")\n",
    "\n",
    "# Conversation history\n",
    "history = conversation_manager.get_conversation_history(memory_agent.current_session)\n",
    "print(\"\\nüí¨ Conversation History:\")\n",
    "print(f\"   Total turns in session: {len(history)}\")\n",
    "print(f\"   Session ID: {memory_agent.current_session[:8]}\")\n",
    "\n",
    "print(\"\\n‚úÖ MEMORY SYSTEM DEMONSTRATION COMPLETE:\")\n",
    "print(\"   ‚úÖ Vector Knowledge Base: Semantic search with FAISS\")\n",
    "print(\"   ‚úÖ Persistent Conversations: SQLite storage with history\")\n",
    "print(\"   ‚úÖ Context Integration: Knowledge + history in responses\")\n",
    "print(\"   ‚úÖ Memory Tracking: What knowledge influenced each response\")\n",
    "print(\"   ‚úÖ Production Ready: Scalable architecture with enterprise patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Agent Memory & Conversation Management Mastery Complete!\n",
    "\n",
    "**You've mastered sophisticated memory patterns for conversational AI systems.**\n",
    "\n",
    "### üèÜ **What You've Accomplished:**\n",
    "\n",
    "**‚úÖ Vector Memory System:**\n",
    "- **FAISS Integration:** Production-grade similarity search with optimized indexing\n",
    "- **Semantic Embeddings:** Sentence transformers for meaningful vector representations\n",
    "- **Knowledge Storage:** Structured memory with metadata and fast retrieval\n",
    "- **Similarity Search:** Context-aware knowledge retrieval with configurable thresholds\n",
    "\n",
    "**‚úÖ Conversation Persistence:**\n",
    "- **SQLite Backend:** Persistent storage surviving agent restarts\n",
    "- **Session Management:** Multi-user conversation isolation and tracking\n",
    "- **Turn Storage:** Complete conversation history with metadata\n",
    "- **Query Performance:** Efficient retrieval of conversation context\n",
    "\n",
    "**‚úÖ Memory-Enhanced Agents:**\n",
    "- **Context Integration:** Seamless combination of knowledge and conversation history\n",
    "- **Smart Retrieval:** Query-based knowledge search for relevant information\n",
    "- **Response Enhancement:** Context-aware generation using retrieved memory\n",
    "- **Memory Tracking:** Comprehensive logging of knowledge usage in responses\n",
    "\n",
    "### üöÄ **Production Applications:**\n",
    "\n",
    "These patterns power enterprise conversational AI systems:\n",
    "- **Customer Service:** Agents remember customer history and preferences\n",
    "- **Knowledge Management:** RAG systems with persistent conversation context\n",
    "- **Virtual Assistants:** Personalized responses based on interaction history\n",
    "- **Educational AI:** Adaptive learning with student progress tracking\n",
    "\n",
    "---\n",
    "\n",
    "**üéñÔ∏è Achievement Unlocked: Memory Management Expert**\n",
    "\n",
    "*You've implemented production-ready memory patterns that enable truly intelligent, context-aware conversational agents.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Google ADK Multi-Provider",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
