{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Developer Workspace Setup - Start Building in 15 Minutes ğŸš€\n",
        "\n",
        "**Get your complete ADK development workspace ready - FREE local development first, then scale to cloud when ready**\n",
        "\n",
        "## ğŸ¯ What We'll Set Up Today (Following AI Agent Bootcamp Success Pattern)\n",
        "\n",
        "### ğŸ†“ **Phase 1: FREE Local Development (Recommended)**\n",
        "âœ… **Ollama + Llama 3.2** - FREE local AI models optimized for coding and agents (zero API costs)  \n",
        "âœ… **Enterprise-Grade Models** - Same quality as production systems  \n",
        "âœ… **Google ADK** - Enterprise patterns with local models  \n",
        "âœ… **Zero Cost Learning** - Master patterns without spending money  \n",
        "\n",
        "### â˜ï¸ **Phase 2: Multi-Cloud Scaling (Optional)**\n",
        "âœ… **Google AI Studio** - Primary cloud option  \n",
        "âœ… **OpenAI** - Alternative cloud provider  \n",
        "âœ… **Anthropic** - Alternative cloud provider  \n",
        "âœ… **Azure OpenAI** - Enterprise cloud option  \n",
        "\n",
        "### ğŸ› ï¸ **Phase 3: Professional Tools**\n",
        "âœ… **Python 3.9+** - Core development environment  \n",
        "âœ… **VS Code** - Professional IDE with extensions  \n",
        "âœ… **Virtual Environment** - Isolated development space  \n",
        "âœ… **Smart Configuration** - Multi-provider with intelligent fallbacks  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ The Proven \"Start FREE, Scale Smart\" Approach\n",
        "\n",
        "**Why this approach works (from AI Agent Bootcamp with 15,000+ students):**\n",
        "\n",
        "ğŸ†“ **Remove barriers:** Start learning immediately without API costs  \n",
        "ğŸ¯ **Build confidence:** Master patterns with unlimited experimentation  \n",
        "ğŸ“ˆ **Scale intelligently:** Add cloud providers when you need them  \n",
        "ğŸ’° **Cost control:** Always know exactly what you're spending  \n",
        "\n",
        "**Enterprise truth:** Google's ADK patterns work the same whether you use local models or cloud APIs. Learn the architecture for FREE, then scale with confidence.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ğŸ†“ Phase 1: FREE Local Development Setup\n",
        "\n",
        "## Step 1: Install Python 3.9+ ğŸ\n",
        "\n",
        "**ğŸ‘‰ Download Python:** [python.org/downloads](https://www.python.org/downloads/)\n",
        "\n",
        "**âš ï¸ Important during installation:**\n",
        "- âœ… Check **\"Add Python to PATH\"**\n",
        "- âœ… Choose **\"Install for all users\"** (recommended)\n",
        "- âœ… Use **Python 3.9, 3.10, or 3.11** (avoid 3.12 for compatibility)\n",
        "\n",
        "**âœ… Verify in terminal:**\n",
        "```bash\n",
        "python --version\n",
        "# Should show: Python 3.9.x or higher\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 2: Install Ollama (FREE Local AI) ğŸ¤–\n",
        "\n",
        "**This is your secret weapon for cost-free learning!**\n",
        "\n",
        "### Download & Install Ollama:\n",
        "**ğŸ‘‰ Visit:** [ollama.ai](https://ollama.ai)  \n",
        "- **Windows:** Download .exe installer\n",
        "- **macOS:** Download .dmg installer  \n",
        "- **Linux:** `curl -fsSL https://ollama.ai/install.sh | sh`\n",
        "\n",
        "### Install a FREE Model:\n",
        "```bash\n",
        "# Start with lightweight, capable model (1.3GB)\n",
        "ollama pull llama3.2:1b\n",
        "\n",
        "# Optional: More capable model (2GB) \n",
        "ollama pull llama3.2:3b\n",
        "\n",
        "# Test your setup\n",
        "ollama run llama3.2:1b \"Hello! Test my local AI setup for coding and agent tasks\"\n",
        "```\n",
        "\n",
        "**ğŸ’¡ Why start with Llama 3.2 local models?**\n",
        "- âœ… **$0 cost** while learning and experimenting\n",
        "- âœ… **No rate limits** - unlimited requests\n",
        "- âœ… **Privacy** - everything runs on your machine\n",
        "- âœ… **Optimized for coding and agents** - Perfect for ADK use cases\n",
        "- âœ… **Enterprise-grade** - Same patterns Google uses internally\n",
        "\n",
        "---\n",
        "\n",
        "## Step 3: VS Code + Essential Extensions ğŸ’»\n",
        "\n",
        "**ğŸ‘‰ Download VS Code:** [code.visualstudio.com](https://code.visualstudio.com/)\n",
        "\n",
        "**Essential Extensions:**\n",
        "1. **Python** (by Microsoft)\n",
        "2. **Jupyter** (by Microsoft)\n",
        "3. **Python Docstring Generator**\n",
        "4. **GitLens** (optional)\n",
        "\n",
        "**Install extensions:** `Ctrl+Shift+X` â†’ Search â†’ Install\n",
        "\n",
        "---\n",
        "\n",
        "## Step 4: Get Course Repository ğŸ“\n",
        "\n",
        "### Method A: Clone with Git\n",
        "```bash\n",
        "git clone https://github.com/pragatidev/google-adk-enterprise-agents.git\n",
        "cd google-adk-enterprise-agents\n",
        "code .\n",
        "```\n",
        "\n",
        "### Method B: Download ZIP\n",
        "1. Go to the GitHub repository\n",
        "2. **Code** â†’ **Download ZIP**\n",
        "3. Extract and open in VS Code\n",
        "\n",
        "---\n",
        "\n",
        "## Step 5: Create Virtual Environment ğŸ \n",
        "\n",
        "**In VS Code Terminal** (`Ctrl+` backtick):\n",
        "```bash\n",
        "# Create isolated environment\n",
        "python -m venv .venv\n",
        "\n",
        "# Activate it\n",
        "# Windows:\n",
        ".venv\\Scripts\\activate\n",
        "\n",
        "# macOS/Linux:\n",
        "source .venv/bin/activate\n",
        "```\n",
        "\n",
        "**âœ… Success:** Terminal shows `(.venv)` at the beginning\n",
        "\n",
        "---\n",
        "\n",
        "## Step 6: Install Multi-Provider Dependencies ğŸ“¦\n",
        "\n",
        "```bash\n",
        "# Upgrade pip first\n",
        "python -m pip install --upgrade pip\n",
        "\n",
        "# Install complete toolkit\n",
        "pip install -r requirements.txt\n",
        "\n",
        "# Setup Jupyter kernel\n",
        "python -m ipykernel install --user --name=venv --display-name=\"Google ADK Multi-Provider\"\n",
        "```\n",
        "\n",
        "**This installs:**\n",
        "- Google ADK framework + Gemini API client\n",
        "- **Ollama Python client** (for Llama 3.2 local models)\n",
        "- **LiteLLM** (multi-provider support)\n",
        "- OpenAI, Anthropic, Groq, Together, Mistral, Cohere clients\n",
        "- All supporting packages for enterprise development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# â˜ï¸ Phase 2: Multi-Provider Configuration (Smart Scaling)\n",
        "\n",
        "## Create Smart Environment Configuration ğŸ”§\n",
        "\n",
        "### Copy Multi-Provider Template:\n",
        "```bash\n",
        "# Windows:\n",
        "copy .env.example .env\n",
        "\n",
        "# macOS/Linux:\n",
        "cp .env.example .env\n",
        "```\n",
        "\n",
        "### Your .env.example Template:\n",
        "```bash\n",
        "# =============================================================================\n",
        "# Google ADK Multi-Provider Configuration - Start FREE, Scale Smart\n",
        "# =============================================================================\n",
        "\n",
        "# LOCAL DEVELOPMENT (RECOMMENDED FOR LEARNING)\n",
        "OLLAMA_BASE_URL=http://localhost:11434\n",
        "OLLAMA_MODEL=llama3.2:1b\n",
        "USE_LOCAL_MODELS=true\n",
        "\n",
        "# GOOGLE AI STUDIO (PRIMARY CLOUD OPTION)\n",
        "# Get free key: https://aistudio.google.com/app/apikey\n",
        "GOOGLE_API_KEY=your-google-api-key-here\n",
        "GOOGLE_MODEL=gemini-1.5-flash\n",
        "\n",
        "# OPENAI (POPULAR CLOUD OPTION)\n",
        "# Get key: https://platform.openai.com/api-keys\n",
        "OPENAI_API_KEY=your-openai-api-key-here\n",
        "OPENAI_MODEL=gpt-4o-mini\n",
        "\n",
        "# ANTHROPIC (QUALITY CLOUD OPTION)\n",
        "# Get key: https://console.anthropic.com/\n",
        "ANTHROPIC_API_KEY=your-anthropic-api-key-here\n",
        "ANTHROPIC_MODEL=claude-3-haiku-20240307\n",
        "\n",
        "# GROQ (FAST INFERENCE)\n",
        "# Get key: https://console.groq.com/keys\n",
        "GROQ_API_KEY=your-groq-api-key-here\n",
        "GROQ_MODEL=llama3-8b-8192\n",
        "\n",
        "# DEEPSEEK (VIA OPENAI-COMPATIBLE API)\n",
        "# Get key: https://platform.deepseek.com/api_keys\n",
        "DEEPSEEK_API_KEY=your-deepseek-api-key-here\n",
        "DEEPSEEK_BASE_URL=https://api.deepseek.com/v1\n",
        "DEEPSEEK_MODEL=deepseek-chat\n",
        "\n",
        "# SMART PROVIDER SELECTION\n",
        "PREFERRED_PROVIDER=local  # Start FREE!\n",
        "FALLBACK_PROVIDER=google\n",
        "\n",
        "# COST CONTROL\n",
        "MONTHLY_BUDGET_LIMIT=50.00\n",
        "COST_TRACKING_ENABLED=true\n",
        "ALERT_THRESHOLD_PERCENT=80\n",
        "\n",
        "# DEVELOPMENT SETTINGS\n",
        "DEBUG=true\n",
        "TEMPERATURE=0.7\n",
        "MAX_TOKENS=1000\n",
        "```\n",
        "\n",
        "### Configure for FREE Development:\n",
        "1. **Edit .env file** in VS Code\n",
        "2. **Keep defaults:** `USE_LOCAL_MODELS=true` and `PREFERRED_PROVIDER=local`\n",
        "3. **Leave cloud API keys blank** initially (add them when you want to scale)\n",
        "4. **Save file**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’° Cost Comparison (Always Know Your Options)\n",
        "\n",
        "| Provider | Cost/1M tokens | Best For | Setup Time |\n",
        "|----------|----------------|----------|------------|\n",
        "| **Ollama (Llama 3.2)** | **$0.00** | **Learning & Development** | **5 min** |\n",
        "| Gemini Flash | $0.075 | Production (Budget) | 2 min |\n",
        "| GPT-4o-mini | $0.15 | Production (Balanced) | 2 min |\n",
        "| Claude Haiku | $0.25 | Production (Quality) | 2 min |\n",
        "| Groq (Llama3-8B) | $0.05 | Fast Inference | 2 min |\n",
        "| Deepseek Chat | $0.14 | International Option | 2 min |\n",
        "\n",
        "**ğŸ’¡ Smart Learning Strategy:**\n",
        "1. **Master patterns** with FREE Llama 3.2 local models (optimized for coding/agents)\n",
        "2. **Test cloud providers** when ready (small experiments)\n",
        "3. **Scale production** with full cost visibility\n",
        "4. **Mix and match** based on use case requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# âœ… Phase 3: Verification & Testing\n",
        "\n",
        "## Select Your Jupyter Kernel ğŸ¯\n",
        "\n",
        "**In VS Code:**\n",
        "1. Open this notebook\n",
        "2. Click kernel selector (top-right)\n",
        "3. Select **\"Google ADK Multi-Provider\"**\n",
        "4. Wait for connection\n",
        "\n",
        "**âœ… Ready to test? Run the verification cells below! ğŸ‘‡**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” MULTI-PROVIDER SETUP VERIFICATION\n",
            "=============================================\n",
            "ğŸ Python Version: 3.11.9\n",
            "âœ… Python version perfect for Google ADK!\n",
            "\n",
            "ğŸ  Virtual Environment: âœ… Active\n",
            "âœ… Using isolated development environment\n",
            "ğŸ“ Python path: c:\\Users\\praga\\google-adk-enterprise-agents\\.venv\\Scripts\\python.exe\n",
            "\n",
            "ğŸ“‚ Project Directory: Section_1_ADK Foundations & Your AI Engineer Journey\n",
            "\n",
            "ğŸ“„ Project Files:\n",
            "âœ… ..\\requirements.txt - Dependencies configuration\n",
            "âœ… ..\\.env.example - Environment template\n",
            "âœ… ..\\.env         - Your configuration (optional)\n",
            "\n",
            "ğŸ‰ Project structure ready!\n",
            "â–¶ï¸ Continue to dependency verification\n"
          ]
        }
      ],
      "source": [
        "# Multi-Provider Setup Verification\n",
        "print(\"ğŸ” MULTI-PROVIDER SETUP VERIFICATION\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Check Python version\n",
        "version = sys.version_info\n",
        "print(f\"ğŸ Python Version: {version.major}.{version.minor}.{version.micro}\")\n",
        "\n",
        "if version.major == 3 and version.minor >= 9 and version.minor <= 11:\n",
        "    print(\"âœ… Python version perfect for Google ADK!\")\n",
        "else:\n",
        "    print(\"âš ï¸ Consider Python 3.9-3.11 for best compatibility\")\n",
        "\n",
        "# Check virtual environment\n",
        "in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
        "print(f\"\\nğŸ  Virtual Environment: {'âœ… Active' if in_venv else 'âŒ Not Active'}\")\n",
        "\n",
        "if in_venv:\n",
        "    print(\"âœ… Using isolated development environment\")\n",
        "    print(f\"ğŸ“ Python path: {sys.executable}\")\n",
        "else:\n",
        "    print(\"ğŸ’¡ Activate virtual environment: .venv\\\\Scripts\\\\activate (Windows) or source .venv/bin/activate (Mac/Linux)\")\n",
        "\n",
        "# Check project structure\n",
        "current_dir = Path.cwd()\n",
        "print(f\"\\nğŸ“‚ Project Directory: {current_dir.name}\")\n",
        "\n",
        "# Look for essential files\n",
        "essential_files = {\n",
        "    '..\\\\requirements.txt': 'Dependencies configuration',\n",
        "    '..\\\\.env.example': 'Environment template',\n",
        "    '..\\\\.env': 'Your configuration (optional)'\n",
        "}\n",
        "\n",
        "print(\"\\nğŸ“„ Project Files:\")\n",
        "setup_complete = True\n",
        "for file, description in essential_files.items():\n",
        "    if Path(file).exists():\n",
        "        print(f\"âœ… {file:<15} - {description}\")\n",
        "    else:\n",
        "        print(f\"âŒ {file:<15} - {description} (MISSING)\")\n",
        "        if file != '.env':  # .env is created during setup\n",
        "            setup_complete = False\n",
        "\n",
        "if setup_complete:\n",
        "    print(\"\\nğŸ‰ Project structure ready!\")\n",
        "    print(\"â–¶ï¸ Continue to dependency verification\")\n",
        "else:\n",
        "    print(\"\\nğŸ”§ Complete Phase 1 setup first\")\n",
        "    print(\"ğŸ’¡ Make sure you're in the correct project directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¦ COMPLETE MULTI-PROVIDER DEPENDENCIES CHECK\n",
            "==================================================\n",
            "\n",
            "ğŸ“‹ Core Framework:\n",
            "  âœ… google.adk.agents    - Google ADK Framework\n",
            "  âœ… dotenv               - Environment Management\n",
            "  âœ… pydantic             - Data Validation & Settings\n",
            "  ğŸ‰ Core Framework: Complete (3/3)\n",
            "\n",
            "ğŸ“‹ Local AI (FREE):\n",
            "  âœ… ollama               - Local Model Integration (Llama 3.2)\n",
            "  ğŸ‰ Local AI (FREE): Complete (1/1)\n",
            "\n",
            "ğŸ“‹ Major Cloud Providers:\n",
            "  âœ… google.generativeai  - Google AI Studio\n",
            "  âœ… openai               - OpenAI Integration\n",
            "  âœ… anthropic            - Anthropic Integration\n",
            "  ğŸ‰ Major Cloud Providers: Complete (3/3)\n",
            "\n",
            "ğŸ“‹ Additional Cloud Providers:\n",
            "  âœ… groq                 - Groq Fast Inference\n",
            "  âœ… together             - Together AI Platform\n",
            "  âœ… mistralai            - Mistral AI Platform\n",
            "  âœ… cohere               - Cohere Platform\n",
            "  ğŸ‰ Additional Cloud Providers: Complete (4/4)\n",
            "\n",
            "ğŸ“‹ Multi-Provider Interface:\n",
            "  âœ… litellm              - Universal LLM Interface\n",
            "  âœ… requests             - HTTP Client\n",
            "  âœ… httpx                - Modern HTTP Client\n",
            "  ğŸ‰ Multi-Provider Interface: Complete (3/3)\n",
            "\n",
            "ğŸ“‹ Development Environment:\n",
            "  âœ… jupyter              - Jupyter Notebooks\n",
            "  âœ… ipykernel            - Kernel Management\n",
            "  âœ… rich                 - Enhanced Terminal Output\n",
            "  ğŸ‰ Development Environment: Complete (3/3)\n",
            "\n",
            "ğŸ“Š Overall Installation Status: 17/17 packages\n",
            "ğŸ‰ ALL DEPENDENCIES INSTALLED!\n",
            "ğŸš€ Complete multi-provider development environment ready\n",
            "ğŸŒŸ You can use ANY supported LLM provider\n",
            "\n",
            "â–¶ï¸ Next: Configure your preferred providers in .env file\n"
          ]
        }
      ],
      "source": [
        "# Complete Multi-Provider Dependencies Verification\n",
        "print(\"ğŸ“¦ COMPLETE MULTI-PROVIDER DEPENDENCIES CHECK\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Comprehensive dependencies for multi-provider support\n",
        "dependencies = {\n",
        "    'Core Framework': {\n",
        "        'google.adk.agents': 'Google ADK Framework',\n",
        "        'dotenv': 'Environment Management',\n",
        "        'pydantic': 'Data Validation & Settings'\n",
        "    },\n",
        "    'Local AI (FREE)': {\n",
        "        'ollama': 'Local Model Integration (Llama 3.2)',\n",
        "    },\n",
        "    'Major Cloud Providers': {\n",
        "        'google.generativeai': 'Google AI Studio',\n",
        "        'openai': 'OpenAI Integration',\n",
        "        'anthropic': 'Anthropic Integration'\n",
        "    },\n",
        "    'Additional Cloud Providers': {\n",
        "        'groq': 'Groq Fast Inference',\n",
        "        'together': 'Together AI Platform',\n",
        "        'mistralai': 'Mistral AI Platform',\n",
        "        'cohere': 'Cohere Platform'\n",
        "    },\n",
        "    'Multi-Provider Interface': {\n",
        "        'litellm': 'Universal LLM Interface',\n",
        "        'requests': 'HTTP Client',\n",
        "        'httpx': 'Modern HTTP Client'\n",
        "    },\n",
        "    'Development Environment': {\n",
        "        'jupyter': 'Jupyter Notebooks',\n",
        "        'ipykernel': 'Kernel Management',\n",
        "        'rich': 'Enhanced Terminal Output'\n",
        "    }\n",
        "}\n",
        "\n",
        "total_deps = sum(len(deps) for deps in dependencies.values())\n",
        "installed_count = 0\n",
        "missing_deps = []\n",
        "\n",
        "for category, deps in dependencies.items():\n",
        "    print(f\"\\nğŸ“‹ {category}:\")\n",
        "    category_installed = 0\n",
        "    category_total = len(deps)\n",
        "    \n",
        "    for package, description in deps.items():\n",
        "        try:\n",
        "            # Handle special import cases\n",
        "            if package == 'google.adk.agents':\n",
        "                from google.adk.agents import Agent\n",
        "            elif package == 'dotenv':\n",
        "                from dotenv import load_dotenv\n",
        "            elif package == 'mistralai':\n",
        "                import mistralai\n",
        "            else:\n",
        "                # Standard import\n",
        "                __import__(package.replace('-', '_'))\n",
        "            \n",
        "            print(f\"  âœ… {package:<20} - {description}\")\n",
        "            installed_count += 1\n",
        "            category_installed += 1\n",
        "        except ImportError:\n",
        "            print(f\"  âŒ {package:<20} - {description} (MISSING)\")\n",
        "            missing_deps.append(package)\n",
        "    \n",
        "    # Category summary\n",
        "    if category_installed == category_total:\n",
        "        print(f\"  ğŸ‰ {category}: Complete ({category_installed}/{category_total})\")\n",
        "    elif category_installed > 0:\n",
        "        print(f\"  âš ï¸ {category}: Partial ({category_installed}/{category_total})\")\n",
        "    else:\n",
        "        print(f\"  ğŸš« {category}: Missing ({category_installed}/{category_total})\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Overall Installation Status: {installed_count}/{total_deps} packages\")\n",
        "\n",
        "# Smart recommendations based on what's missing\n",
        "if installed_count == total_deps:\n",
        "    print(\"ğŸ‰ ALL DEPENDENCIES INSTALLED!\")\n",
        "    print(\"ğŸš€ Complete multi-provider development environment ready\")\n",
        "    print(\"ğŸŒŸ You can use ANY supported LLM provider\")\n",
        "    \n",
        "elif installed_count >= (total_deps * 0.7):  # 70% or more\n",
        "    print(\"âœ… Core dependencies ready - mostly functional\")\n",
        "    print(f\"ğŸ’¡ {len(missing_deps)} optional packages missing\")\n",
        "    print(\"ğŸ“ˆ You can proceed and add providers as needed\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ Critical packages missing\")\n",
        "    print(\"ğŸ›‘ Course environment not ready\")\n",
        "    print(\"\\nğŸ”§ COMPLETE FIX:\")\n",
        "    print(\"1. Ensure virtual environment is activated:\")\n",
        "    print(\"   Windows: .venv\\\\Scripts\\\\activate\")\n",
        "    print(\"   Mac/Linux: source .venv/bin/activate\")\n",
        "    print(\"2. Install all dependencies:\")\n",
        "    print(\"   pip install -r requirements.txt\")\n",
        "    print(\"3. Restart Jupyter kernel\")\n",
        "    print(\"4. Re-run this cell\")\n",
        "\n",
        "print(\"\\nâ–¶ï¸ Next: Configure your preferred providers in .env file\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ MULTI-PROVIDER CONFIGURATION TEST\n",
            "=============================================\n",
            "ğŸ“„ Environment Configuration:\n",
            "ğŸ†“ Local Models Enabled: âœ… YES\n",
            "ğŸ¯ Preferred Provider: local\n",
            "âœ… Configured for FREE local development (recommended!)\n",
            "ğŸ¤– Ollama URL: http://localhost:11434\n",
            "ğŸ“¦ Default Model: llama3.2\n",
            "âœ… Ollama running with 3 model(s):\n",
            "   ğŸ“¦ qwen2.5-coder:latest\n",
            "   ğŸ¯ llama3.2:1b (PERFECT for coding/agents!)\n",
            "   ğŸ¯ llama3.2:latest (PERFECT for coding/agents!)\n",
            "ğŸ‰ Llama 3.2 detected - optimized for enterprise agent tasks!\n",
            "\n",
            "â˜ï¸ Cloud Provider Status:\n",
            "âœ… Google     - Configured\n",
            "ğŸ’¤ OpenAI     - Not configured (optional)\n",
            "ğŸ’¤ Anthropic  - Not configured (optional)\n",
            "âœ… Groq       - Configured\n",
            "âœ… Deepseek   - Configured\n",
            "\n",
            "ğŸ¯ Setup Assessment:\n",
            "âœ… Ready for FREE local development\n",
            "ğŸš€ You can start building immediately with zero costs\n",
            "ğŸ“ˆ Plus 3 cloud provider(s) for scaling\n",
            "ğŸ¯ Llama 3.2 provides enterprise-grade capabilities for agent development\n",
            "\n",
            "â–¶ï¸ Next: Test Google ADK framework\n"
          ]
        }
      ],
      "source": [
        "# Multi-Provider Configuration Test\n",
        "print(\"ğŸ”§ MULTI-PROVIDER CONFIGURATION TEST\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    import os\n",
        "    \n",
        "    # Load environment configuration\n",
        "    load_dotenv()\n",
        "    \n",
        "    print(\"ğŸ“„ Environment Configuration:\")\n",
        "    \n",
        "    # Check local setup (preferred)\n",
        "    use_local = os.getenv('USE_LOCAL_MODELS', 'true').lower() == 'true'\n",
        "    preferred_provider = os.getenv('PREFERRED_PROVIDER', 'local')\n",
        "    \n",
        "    print(f\"ğŸ†“ Local Models Enabled: {'âœ… YES' if use_local else 'âŒ NO'}\")\n",
        "    print(f\"ğŸ¯ Preferred Provider: {preferred_provider}\")\n",
        "    \n",
        "    if use_local and preferred_provider == 'local':\n",
        "        print(\"âœ… Configured for FREE local development (recommended!)\")\n",
        "        \n",
        "        # Test Ollama connection\n",
        "        ollama_url = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')\n",
        "        ollama_model = os.getenv('OLLAMA_MODEL', 'llama3.2:1b')\n",
        "        print(f\"ğŸ¤– Ollama URL: {ollama_url}\")\n",
        "        print(f\"ğŸ“¦ Default Model: {ollama_model}\")\n",
        "        \n",
        "        try:\n",
        "            import requests\n",
        "            response = requests.get(f\"{ollama_url}/api/tags\", timeout=5)\n",
        "            if response.status_code == 200:\n",
        "                models = response.json().get('models', [])\n",
        "                if models:\n",
        "                    print(f\"âœ… Ollama running with {len(models)} model(s):\")\n",
        "                    for model in models[:3]:  # Show first 3\n",
        "                        model_name = model['name']\n",
        "                        if 'llama3.2' in model_name:\n",
        "                            print(f\"   ğŸ¯ {model_name} (PERFECT for coding/agents!)\")\n",
        "                        else:\n",
        "                            print(f\"   ğŸ“¦ {model_name}\")\n",
        "                    \n",
        "                    # Check if recommended model is available\n",
        "                    available_models = [m['name'] for m in models]\n",
        "                    if any('llama3.2' in name for name in available_models):\n",
        "                        print(\"ğŸ‰ Llama 3.2 detected - optimized for enterprise agent tasks!\")\n",
        "                    else:\n",
        "                        print(\"ğŸ’¡ Consider installing Llama 3.2: ollama pull llama3.2:1b\")\n",
        "                else:\n",
        "                    print(\"âš ï¸ Ollama running but no models installed\")\n",
        "                    print(\"ğŸ’¡ Install Llama 3.2: ollama pull llama3.2:1b\")\n",
        "            else:\n",
        "                print(\"âŒ Ollama not responding\")\n",
        "                print(\"ğŸ’¡ Start Ollama service and install models\")\n",
        "        except Exception as e:\n",
        "            print(\"âŒ Cannot connect to Ollama\")\n",
        "            print(\"ğŸ’¡ Start Ollama: Visit ollama.ai for installation\")\n",
        "            print(f\"   Error details: {str(e)[:100]}...\")\n",
        "    \n",
        "    # Check cloud provider configurations (optional)\n",
        "    print(\"\\nâ˜ï¸ Cloud Provider Status:\")\n",
        "    \n",
        "    cloud_providers = {\n",
        "        'Google': 'GOOGLE_API_KEY',\n",
        "        'OpenAI': 'OPENAI_API_KEY', \n",
        "        'Anthropic': 'ANTHROPIC_API_KEY',\n",
        "        'Groq': 'GROQ_API_KEY',\n",
        "        'Deepseek': 'DEEPSEEK_API_KEY'\n",
        "    }\n",
        "    \n",
        "    configured_providers = []\n",
        "    for provider, key_name in cloud_providers.items():\n",
        "        api_key = os.getenv(key_name)\n",
        "        if api_key and api_key != f'your-{key_name.lower().replace(\"_\", \"-\")}-here':\n",
        "            print(f\"âœ… {provider:<10} - Configured\")\n",
        "            configured_providers.append(provider)\n",
        "        else:\n",
        "            print(f\"ğŸ’¤ {provider:<10} - Not configured (optional)\")\n",
        "    \n",
        "    # Smart configuration assessment\n",
        "    print(f\"\\nğŸ¯ Setup Assessment:\")\n",
        "    if use_local:\n",
        "        print(\"âœ… Ready for FREE local development\")\n",
        "        print(\"ğŸš€ You can start building immediately with zero costs\")\n",
        "        if configured_providers:\n",
        "            print(f\"ğŸ“ˆ Plus {len(configured_providers)} cloud provider(s) for scaling\")\n",
        "        print(\"ğŸ¯ Llama 3.2 provides enterprise-grade capabilities for agent development\")\n",
        "    elif configured_providers:\n",
        "        print(f\"âœ… Ready for cloud development with {len(configured_providers)} provider(s)\")\n",
        "    else:\n",
        "        print(\"âš ï¸ No providers configured\")\n",
        "        print(\"ğŸ’¡ Recommendation: Keep USE_LOCAL_MODELS=true for FREE learning\")\n",
        "    \n",
        "    print(\"\\nâ–¶ï¸ Next: Test Google ADK framework\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Configuration error: {e}\")\n",
        "    print(\"\\nğŸ”§ TROUBLESHOOTING:\")\n",
        "    print(\"1. Make sure .env file exists (copy from .env.example)\")\n",
        "    print(\"2. Check file permissions\")\n",
        "    print(\"3. Verify environment variable syntax\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ GOOGLE ADK FRAMEWORK TEST\n",
            "=============================================\n",
            "âœ… Google ADK imported successfully\n",
            "ğŸ¤– Testing with local model: ollama/llama3.2:1b\n",
            "ğŸ’° Cost: $0.00 (FREE local development)\n",
            "ğŸ¯ Optimized for: Coding, agents, enterprise tasks\n",
            "âœ… Google ADK Agent created successfully\n",
            "   ğŸ“‹ Agent name: WorkspaceVerificationAgent\n",
            "   ğŸ§  Model: ollama/llama3.2:1b\n",
            "   ğŸ“ Instruction configured: âœ…\n",
            "\n",
            "ğŸ” ADK Framework Capabilities:\n",
            "âœ… Agent creation and configuration\n",
            "âœ… Model abstraction layer\n",
            "âœ… Instruction-based behavior\n",
            "âœ… Enterprise-grade architecture\n",
            "âœ… Multi-provider model support\n",
            "\n",
            "ğŸ‰ WORKSPACE SETUP COMPLETE!\n",
            "ğŸš€ Your Google ADK development workspace is fully ready!\n",
            "\n",
            "âœ… What you've accomplished:\n",
            "   ğŸ†“ FREE local development environment\n",
            "   ğŸ  Isolated virtual environment (.venv)\n",
            "   ğŸ”§ Multi-provider configuration\n",
            "   ğŸ¤– Google ADK framework ready\n",
            "   ğŸ“¦ Professional development tools\n",
            "   ğŸ¯ Llama 3.2 optimized for coding and agent tasks\n",
            "\n",
            "ğŸ’¡ Pro Tips:\n",
            "   ğŸ†“ You're starting with FREE Llama 3.2 models - perfect for learning coding and agents!\n",
            "   ğŸ“ˆ Add cloud API keys to .env when you want to scale\n",
            "   ğŸ’° Local development = unlimited experimentation with zero cost\n",
            "   ğŸ¯ Llama 3.2 is optimized for the exact use cases you'll build in this course\n",
            "\n",
            "ğŸ¯ NEXT STEPS:\n",
            "   â–¶ï¸ Proceed to: 'Your First Google ADK Agent'\n",
            "   â–¶ï¸ Start building enterprise AI solutions!\n",
            "   â–¶ï¸ Follow the same patterns Google uses internally\n"
          ]
        }
      ],
      "source": [
        "# Google ADK Framework Test\n",
        "print(\"ğŸš€ GOOGLE ADK FRAMEWORK TEST\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "try:\n",
        "    # Import Google ADK\n",
        "    from google.adk.agents import Agent\n",
        "    print(\"âœ… Google ADK imported successfully\")\n",
        "    \n",
        "    # Load configuration\n",
        "    from dotenv import load_dotenv\n",
        "    import os\n",
        "    load_dotenv()\n",
        "    \n",
        "    # Determine which model to use\n",
        "    use_local = os.getenv('USE_LOCAL_MODELS', 'true').lower() == 'true'\n",
        "    preferred_provider = os.getenv('PREFERRED_PROVIDER', 'local')\n",
        "    \n",
        "    if use_local and preferred_provider == 'local':\n",
        "        # Test with local model configuration\n",
        "        model_name = \"ollama/llama3.2:1b\"  # ADK format for Ollama\n",
        "        print(f\"ğŸ¤– Testing with local model: {model_name}\")\n",
        "        print(\"ğŸ’° Cost: $0.00 (FREE local development)\")\n",
        "        print(\"ğŸ¯ Optimized for: Coding, agents, enterprise tasks\")\n",
        "    else:\n",
        "        # Test with cloud model\n",
        "        model_name = os.getenv('GOOGLE_MODEL', 'gemini-1.5-flash')\n",
        "        print(f\"â˜ï¸ Testing with cloud model: {model_name}\")\n",
        "        print(\"ğŸ’° Cost: ~$0.075 per 1M tokens\")\n",
        "    \n",
        "    # Create test agent (framework validation)\n",
        "    test_agent = Agent(\n",
        "        name=\"WorkspaceVerificationAgent\",\n",
        "        model=model_name,\n",
        "        instruction=\"You are a test agent created to verify the Google ADK development workspace is properly configured. You excel at coding tasks and enterprise agent workflows.\"\n",
        "    )\n",
        "    \n",
        "    print(\"âœ… Google ADK Agent created successfully\")\n",
        "    print(f\"   ğŸ“‹ Agent name: {test_agent.name}\")\n",
        "    print(f\"   ğŸ§  Model: {test_agent.model}\")\n",
        "    print(f\"   ğŸ“ Instruction configured: {'âœ…' if test_agent.instruction else 'âŒ'}\")\n",
        "    \n",
        "    # Framework capabilities check\n",
        "    print(\"\\nğŸ” ADK Framework Capabilities:\")\n",
        "    print(\"âœ… Agent creation and configuration\")\n",
        "    print(\"âœ… Model abstraction layer\")\n",
        "    print(\"âœ… Instruction-based behavior\")\n",
        "    print(\"âœ… Enterprise-grade architecture\")\n",
        "    print(\"âœ… Multi-provider model support\")\n",
        "    \n",
        "    print(\"\\nğŸ‰ WORKSPACE SETUP COMPLETE!\")\n",
        "    print(\"ğŸš€ Your Google ADK development workspace is fully ready!\")\n",
        "    \n",
        "    print(\"\\nâœ… What you've accomplished:\")\n",
        "    print(\"   ğŸ†“ FREE local development environment\")\n",
        "    print(\"   ğŸ  Isolated virtual environment (.venv)\")\n",
        "    print(\"   ğŸ”§ Multi-provider configuration\")\n",
        "    print(\"   ğŸ¤– Google ADK framework ready\")\n",
        "    print(\"   ğŸ“¦ Professional development tools\")\n",
        "    if use_local:\n",
        "        print(\"   ğŸ¯ Llama 3.2 optimized for coding and agent tasks\")\n",
        "    \n",
        "    print(\"\\nğŸ’¡ Pro Tips:\")\n",
        "    if use_local:\n",
        "        print(\"   ğŸ†“ You're starting with FREE Llama 3.2 models - perfect for learning coding and agents!\")\n",
        "        print(\"   ğŸ“ˆ Add cloud API keys to .env when you want to scale\")\n",
        "        print(\"   ğŸ’° Local development = unlimited experimentation with zero cost\")\n",
        "        print(\"   ğŸ¯ Llama 3.2 is optimized for the exact use cases you'll build in this course\")\n",
        "    \n",
        "    print(\"\\nğŸ¯ NEXT STEPS:\")\n",
        "    print(\"   â–¶ï¸ Proceed to: 'Your First Google ADK Agent'\")\n",
        "    print(\"   â–¶ï¸ Start building enterprise AI solutions!\")\n",
        "    print(\"   â–¶ï¸ Follow the same patterns Google uses internally\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Google ADK import failed: {e}\")\n",
        "    print(\"\\nğŸ”§ TROUBLESHOOTING:\")\n",
        "    print(\"1. Ensure virtual environment is activated\")\n",
        "    print(\"2. Run: pip install -r requirements.txt\")\n",
        "    print(\"3. Restart Jupyter kernel\")\n",
        "    print(\"4. Check requirements.txt includes google-adk\")\n",
        "    print(\"5. Verify kernel is set to 'Google ADK Multi-Provider'\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Setup issue: {e}\")\n",
        "    print(\"ğŸ’¡ Check your .env configuration\")\n",
        "    print(\"ğŸ’¡ Verify Ollama is running if using local models\")\n",
        "    print(\"ğŸ’¡ Ensure all dependencies are properly installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ‰ Congratulations! Your Multi-Provider Development Workspace is Ready!\n",
        "\n",
        "### âœ… What You've Successfully Built:\n",
        "\n",
        "ğŸ†“ **FREE Local Development** - Llama 3.2 with local models (zero API costs, optimized for coding/agents)  \n",
        "â˜ï¸ **Multi-Cloud Ready** - Google, OpenAI, Anthropic, Groq, Deepseek configuration  \n",
        "ğŸ  **Professional Environment** - VS Code, .venv, proper isolation  \n",
        "ğŸ¤– **Google ADK Framework** - Enterprise-grade agent development toolkit  \n",
        "ğŸ”§ **Smart Configuration** - Intelligent provider selection and fallbacks  \n",
        "ğŸ’° **Cost Control** - Complete visibility and budget management  \n",
        "\n",
        "### ğŸš€ You're Now Ready For:\n",
        "\n",
        "**Immediate Learning:**\n",
        "- Build agents with FREE Llama 3.2 local models (enterprise-optimized)\n",
        "- Master Google's enterprise patterns\n",
        "- Unlimited experimentation (zero cost)\n",
        "- Professional development practices\n",
        "\n",
        "**Smart Scaling:**\n",
        "- Add cloud providers when needed\n",
        "- Compare performance across models\n",
        "- Optimize costs for production\n",
        "- Enterprise deployment patterns\n",
        "\n",
        "### ğŸ’¡ Your Competitive Advantage\n",
        "\n",
        "**Following the proven AI Agent Bootcamp pattern, you now have:**\n",
        "- **Barrier-free learning:** Start immediately without API costs\n",
        "- **Enterprise patterns:** Same architecture Google uses internally\n",
        "- **Provider flexibility:** Never locked into a single vendor\n",
        "- **Cost intelligence:** Always know what you're spending\n",
        "- **Professional setup:** Industry-standard development environment\n",
        "- **Optimized models:** Llama 3.2 specifically chosen for coding and agent tasks\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”— Quick Reference Guide\n",
        "\n",
        "### Essential Commands:\n",
        "```bash\n",
        "# Activate your workspace\n",
        "cd google-adk-enterprise-agents\n",
        ".venv\\Scripts\\activate  # Windows\n",
        "source .venv/bin/activate  # Mac/Linux\n",
        "\n",
        "# Start Ollama (if using local models)\n",
        "ollama serve\n",
        "\n",
        "# Test local model\n",
        "ollama run llama3.2:1b \"Hello world\"\n",
        "\n",
        "# Install/update dependencies\n",
        "pip install -r requirements.txt\n",
        "\n",
        "# Create/update Jupyter kernel\n",
        "python -m ipykernel install --user --name=venv --display-name=\"Google ADK Multi-Provider\"\n",
        "\n",
        "# Open workspace\n",
        "code .\n",
        "```\n",
        "\n",
        "### Configuration Files:\n",
        "- **`.env`** - Your provider configurations (keep secure!)\n",
        "- **`requirements.txt`** - Python dependencies\n",
        "- **`.venv/`** - Virtual environment (don't commit to Git)\n",
        "- **`.env.example`** - Template for environment setup\n",
        "\n",
        "### Provider Cost Quick Reference:\n",
        "```\n",
        "Ollama (Llama 3.2):    $0.00/request     â† Start here! (Best for coding/agents)\n",
        "Groq (Llama3-8B):      $0.05/1M tokens   â† Fast inference\n",
        "Gemini Flash:          $0.075/1M tokens  â† Budget production\n",
        "GPT-4o-mini:           $0.15/1M tokens   â† Balanced production\n",
        "Claude Haiku:          $0.25/1M tokens   â† Quality production\n",
        "```\n",
        "\n",
        "### Troubleshooting Common Issues:\n",
        "\n",
        "**Import Errors:**\n",
        "- âœ… Activate .venv first: `.venv\\Scripts\\activate`\n",
        "- âœ… Install dependencies: `pip install -r requirements.txt`\n",
        "- âœ… Restart Jupyter kernel\n",
        "\n",
        "**Ollama Issues:**\n",
        "- âœ… Check if service is running: `ollama serve`\n",
        "- âœ… Install models: `ollama pull llama3.2:1b`\n",
        "- âœ… Test connection: `ollama run llama3.2:1b \"test\"`\n",
        "\n",
        "**API Errors:**\n",
        "- âœ… Verify keys in .env file\n",
        "- âœ… Check key format (no quotes, proper prefix)\n",
        "- âœ… Ensure .env file is in project root\n",
        "\n",
        "**Kernel Issues:**\n",
        "- âœ… Select \"Google ADK Multi-Provider\" kernel\n",
        "- âœ… Restart kernel if imports fail\n",
        "- âœ… Recreate kernel if needed\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Smart Development Strategy\n",
        "\n",
        "### Phase 1: Master with FREE Local (Recommended)\n",
        "âœ… Learn Google ADK patterns with Llama 3.2 (optimized for coding/agents)  \n",
        "âœ… Build and test unlimited agents (zero cost)  \n",
        "âœ… Experiment with different architectures  \n",
        "âœ… Develop confidence and expertise with enterprise-grade models  \n",
        "\n",
        "### Phase 2: Validate with Cloud (When Ready)\n",
        "âœ… Test key agents with cloud providers  \n",
        "âœ… Compare performance and costs  \n",
        "âœ… Validate production assumptions  \n",
        "âœ… Choose optimal provider mix  \n",
        "\n",
        "### Phase 3: Scale to Production (Advanced)\n",
        "âœ… Deploy with chosen providers  \n",
        "âœ… Implement monitoring and alerts  \n",
        "âœ… Optimize costs and performance  \n",
        "âœ… Enterprise security and compliance  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”® What's Next in Your Learning Journey\n",
        "\n",
        "### **Upcoming Lectures:**\n",
        "1. **Your First Google ADK Agent** - Build a working agent in 20 lines\n",
        "2. **Multi-Agent Architecture** - Design enterprise agent systems\n",
        "3. **Customer Service Automation** - Real-world agent orchestration\n",
        "4. **Enterprise Research Agent** - Advanced document processing\n",
        "5. **Production Deployment** - Scale to enterprise environments\n",
        "\n",
        "### **Portfolio Projects You'll Build:**\n",
        "- ğŸ¤– **Intelligent Customer Service System** - Multi-agent workflow\n",
        "- ğŸ“Š **Enterprise Research Agent** - Document analysis and insights\n",
        "- ğŸš€ **Production-Ready Platform** - Full deployment with monitoring\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ Ready to Build Enterprise AI Agents!\n",
        "\n",
        "**Your multi-provider Google ADK development workspace is complete.**\n",
        "\n",
        "**Following the proven success pattern from AI Agent Bootcamp, you now have everything needed to master Google's enterprise agent development framework - starting completely FREE with Llama 3.2 models optimized for coding and agent tasks!**\n",
        "\n",
        "---\n",
        "\n",
        "*Next up: Build your first Google ADK agent in under 20 lines of code! ğŸš€*\n",
        "\n",
        "**Click to the next lecture and let's start building enterprise AI solutions together!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Google ADK Multi-Provider",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
