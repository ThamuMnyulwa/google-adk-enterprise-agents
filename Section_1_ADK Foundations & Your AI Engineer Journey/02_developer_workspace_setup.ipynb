{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Developer Workspace Setup - Start Building in 15 Minutes üöÄ\n",
        "\n",
        "**Get your complete ADK development workspace ready - FREE local development first, then scale to cloud when ready**\n",
        "\n",
        "## üéØ What We'll Set Up Today (Following AI Agent Bootcamp Success Pattern)\n",
        "\n",
        "### üÜì **Phase 1: FREE Local Development (Recommended)**\n",
        "‚úÖ **Ollama + Llama 3.2** - FREE local AI models optimized for coding and agents (zero API costs)  \n",
        "‚úÖ **Enterprise-Grade Models** - Same quality as production systems  \n",
        "‚úÖ **Google ADK** - Enterprise patterns with local models  \n",
        "‚úÖ **Zero Cost Learning** - Master patterns without spending money  \n",
        "\n",
        "### ‚òÅÔ∏è **Phase 2: Multi-Cloud Scaling (Optional)**\n",
        "‚úÖ **Google AI Studio** - Primary cloud option  \n",
        "‚úÖ **OpenAI** - Alternative cloud provider  \n",
        "‚úÖ **Anthropic** - Alternative cloud provider  \n",
        "‚úÖ **Azure OpenAI** - Enterprise cloud option  \n",
        "\n",
        "### üõ†Ô∏è **Phase 3: Professional Tools**\n",
        "‚úÖ **Python 3.9+** - Core development environment  \n",
        "‚úÖ **VS Code** - Professional IDE with extensions  \n",
        "‚úÖ **Virtual Environment** - Isolated development space  \n",
        "‚úÖ **Smart Configuration** - Multi-provider with intelligent fallbacks  \n",
        "\n",
        "---\n",
        "\n",
        "## üí° The Proven \"Start FREE, Scale Smart\" Approach\n",
        "\n",
        "**Why this approach works (from AI Agent Bootcamp with 15,000+ students):**\n",
        "\n",
        "üÜì **Remove barriers:** Start learning immediately without API costs  \n",
        "üéØ **Build confidence:** Master patterns with unlimited experimentation  \n",
        "üìà **Scale intelligently:** Add cloud providers when you need them  \n",
        "üí∞ **Cost control:** Always know exactly what you're spending  \n",
        "\n",
        "**Enterprise truth:** Google's ADK patterns work the same whether you use local models or cloud APIs. Learn the architecture for FREE, then scale with confidence.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üÜì Phase 1: FREE Local Development Setup\n",
        "\n",
        "## Step 1: Install Python 3.9+ üêç\n",
        "\n",
        "**üëâ Download Python:** [python.org/downloads](https://www.python.org/downloads/)\n",
        "\n",
        "**‚ö†Ô∏è Important during installation:**\n",
        "- ‚úÖ Check **\"Add Python to PATH\"**\n",
        "- ‚úÖ Choose **\"Install for all users\"** (recommended)\n",
        "- ‚úÖ Use **Python 3.9, 3.10, or 3.11** (avoid 3.12 for compatibility)\n",
        "\n",
        "**‚úÖ Verify in terminal:**\n",
        "```bash\n",
        "python --version\n",
        "# Should show: Python 3.9.x or higher\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 2: Install Ollama (FREE Local AI) ü§ñ\n",
        "\n",
        "**This is your secret weapon for cost-free learning!**\n",
        "\n",
        "### Download & Install Ollama:\n",
        "**üëâ Visit:** [ollama.ai](https://ollama.ai)  \n",
        "- **Windows:** Download .exe installer\n",
        "- **macOS:** Download .dmg installer  \n",
        "- **Linux:** `curl -fsSL https://ollama.ai/install.sh | sh`\n",
        "\n",
        "### Install a FREE Model:\n",
        "```bash\n",
        "# Start with lightweight, capable model (1.3GB)\n",
        "ollama pull llama3.2:1b\n",
        "\n",
        "# Optional: More capable model (2GB) \n",
        "ollama pull llama3.2:3b\n",
        "\n",
        "# Test your setup\n",
        "ollama run llama3.2:1b \"Hello! Test my local AI setup for coding and agent tasks\"\n",
        "```\n",
        "\n",
        "**üí° Why start with Llama 3.2 local models?**\n",
        "- ‚úÖ **$0 cost** while learning and experimenting\n",
        "- ‚úÖ **No rate limits** - unlimited requests\n",
        "- ‚úÖ **Privacy** - everything runs on your machine\n",
        "- ‚úÖ **Optimized for coding and agents** - Perfect for ADK use cases\n",
        "- ‚úÖ **Enterprise-grade** - Same patterns Google uses internally\n",
        "\n",
        "---\n",
        "\n",
        "## Step 3: VS Code + Essential Extensions üíª\n",
        "\n",
        "**üëâ Download VS Code:** [code.visualstudio.com](https://code.visualstudio.com/)\n",
        "\n",
        "**Essential Extensions:**\n",
        "1. **Python** (by Microsoft)\n",
        "2. **Jupyter** (by Microsoft)\n",
        "3. **Python Docstring Generator**\n",
        "4. **GitLens** (optional)\n",
        "\n",
        "**Install extensions:** `Ctrl+Shift+X` ‚Üí Search ‚Üí Install\n",
        "\n",
        "---\n",
        "\n",
        "## Step 4: Get Course Repository üìÅ\n",
        "\n",
        "### Method A: Clone with Git\n",
        "```bash\n",
        "git clone https://github.com/pragatidev/google-adk-enterprise-agents.git\n",
        "cd google-adk-enterprise-agents\n",
        "code .\n",
        "```\n",
        "\n",
        "### Method B: Download ZIP\n",
        "1. Go to the GitHub repository\n",
        "2. **Code** ‚Üí **Download ZIP**\n",
        "3. Extract and open in VS Code\n",
        "\n",
        "---\n",
        "\n",
        "## Step 5: Create Virtual Environment üè†\n",
        "\n",
        "**In VS Code Terminal** (`Ctrl+` backtick):\n",
        "```bash\n",
        "# Create isolated environment\n",
        "python -m venv .venv\n",
        "\n",
        "# Activate it\n",
        "# Windows:\n",
        ".venv\\Scripts\\activate\n",
        "\n",
        "# macOS/Linux:\n",
        "source .venv/bin/activate\n",
        "```\n",
        "\n",
        "**‚úÖ Success:** Terminal shows `(.venv)` at the beginning\n",
        "\n",
        "---\n",
        "\n",
        "## Step 6: Install Multi-Provider Dependencies üì¶\n",
        "\n",
        "```bash\n",
        "# Upgrade pip first\n",
        "python -m pip install --upgrade pip\n",
        "\n",
        "# Install complete toolkit\n",
        "pip install -r requirements.txt\n",
        "\n",
        "# Setup Jupyter kernel\n",
        "python -m ipykernel install --user --name=venv --display-name=\"Google ADK Multi-Provider\"\n",
        "```\n",
        "\n",
        "**This installs:**\n",
        "- Google ADK framework + Gemini API client\n",
        "- **Ollama Python client** (for Llama 3.2 local models)\n",
        "- **LiteLLM** (multi-provider support)\n",
        "- OpenAI, Anthropic, Groq, Together, Mistral, Cohere clients\n",
        "- All supporting packages for enterprise development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ‚òÅÔ∏è Phase 2: Multi-Provider Configuration (Smart Scaling)\n",
        "\n",
        "## Create Smart Environment Configuration üîß\n",
        "\n",
        "### Copy Multi-Provider Template:\n",
        "```bash\n",
        "# Windows:\n",
        "copy .env.example .env\n",
        "\n",
        "# macOS/Linux:\n",
        "cp .env.example .env\n",
        "```\n",
        "\n",
        "### Your .env.example Template:\n",
        "```bash\n",
        "# =============================================================================\n",
        "# Google ADK Multi-Provider Configuration - Start FREE, Scale Smart\n",
        "# =============================================================================\n",
        "\n",
        "# LOCAL DEVELOPMENT (RECOMMENDED FOR LEARNING)\n",
        "OLLAMA_BASE_URL=http://localhost:11434\n",
        "OLLAMA_MODEL=llama3.2:1b\n",
        "USE_LOCAL_MODELS=true\n",
        "\n",
        "# GOOGLE AI STUDIO (PRIMARY CLOUD OPTION)\n",
        "# Get free key: https://aistudio.google.com/app/apikey\n",
        "GOOGLE_API_KEY=your-google-api-key-here\n",
        "GOOGLE_MODEL=gemini-1.5-flash\n",
        "\n",
        "# OPENAI (POPULAR CLOUD OPTION)\n",
        "# Get key: https://platform.openai.com/api-keys\n",
        "OPENAI_API_KEY=your-openai-api-key-here\n",
        "OPENAI_MODEL=gpt-4o-mini\n",
        "\n",
        "# ANTHROPIC (QUALITY CLOUD OPTION)\n",
        "# Get key: https://console.anthropic.com/\n",
        "ANTHROPIC_API_KEY=your-anthropic-api-key-here\n",
        "ANTHROPIC_MODEL=claude-3-haiku-20240307\n",
        "\n",
        "# GROQ (FAST INFERENCE)\n",
        "# Get key: https://console.groq.com/keys\n",
        "GROQ_API_KEY=your-groq-api-key-here\n",
        "GROQ_MODEL=llama3-8b-8192\n",
        "\n",
        "# DEEPSEEK (VIA OPENAI-COMPATIBLE API)\n",
        "# Get key: https://platform.deepseek.com/api_keys\n",
        "DEEPSEEK_API_KEY=your-deepseek-api-key-here\n",
        "DEEPSEEK_BASE_URL=https://api.deepseek.com/v1\n",
        "DEEPSEEK_MODEL=deepseek-chat\n",
        "\n",
        "# SMART PROVIDER SELECTION\n",
        "PREFERRED_PROVIDER=local  # Start FREE!\n",
        "FALLBACK_PROVIDER=google\n",
        "\n",
        "# COST CONTROL\n",
        "MONTHLY_BUDGET_LIMIT=50.00\n",
        "COST_TRACKING_ENABLED=true\n",
        "ALERT_THRESHOLD_PERCENT=80\n",
        "\n",
        "# DEVELOPMENT SETTINGS\n",
        "DEBUG=true\n",
        "TEMPERATURE=0.7\n",
        "MAX_TOKENS=1000\n",
        "```\n",
        "\n",
        "### Configure for FREE Development:\n",
        "1. **Edit .env file** in VS Code\n",
        "2. **Keep defaults:** `USE_LOCAL_MODELS=true` and `PREFERRED_PROVIDER=local`\n",
        "3. **Leave cloud API keys blank** initially (add them when you want to scale)\n",
        "4. **Save file**\n",
        "\n",
        "---\n",
        "\n",
        "## üí∞ Cost Comparison (Always Know Your Options)\n",
        "\n",
        "| Provider | Cost/1M tokens | Best For | Setup Time |\n",
        "|----------|----------------|----------|------------|\n",
        "| **Ollama (Llama 3.2)** | **$0.00** | **Learning & Development** | **5 min** |\n",
        "| Gemini Flash | $0.075 | Production (Budget) | 2 min |\n",
        "| GPT-4o-mini | $0.15 | Production (Balanced) | 2 min |\n",
        "| Claude Haiku | $0.25 | Production (Quality) | 2 min |\n",
        "| Groq (Llama3-8B) | $0.05 | Fast Inference | 2 min |\n",
        "| Deepseek Chat | $0.14 | International Option | 2 min |\n",
        "\n",
        "**üí° Smart Learning Strategy:**\n",
        "1. **Master patterns** with FREE Llama 3.2 local models (optimized for coding/agents)\n",
        "2. **Test cloud providers** when ready (small experiments)\n",
        "3. **Scale production** with full cost visibility\n",
        "4. **Mix and match** based on use case requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ‚úÖ Phase 3: Verification & Testing\n",
        "\n",
        "## Select Your Jupyter Kernel üéØ\n",
        "\n",
        "**In VS Code:**\n",
        "1. Open this notebook\n",
        "2. Click kernel selector (top-right)\n",
        "3. Select **\"Google ADK Multi-Provider\"**\n",
        "4. Wait for connection\n",
        "\n",
        "**‚úÖ Ready to test? Run the verification cells below! üëá**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç MULTI-PROVIDER SETUP VERIFICATION\n",
            "=============================================\n",
            "üêç Python Version: 3.11.9\n",
            "‚úÖ Python version perfect for Google ADK!\n",
            "\n",
            "üè† Virtual Environment: ‚úÖ Active\n",
            "‚úÖ Using isolated development environment\n",
            "üìç Python path: c:\\Users\\praga\\google-adk-enterprise-agents\\.venv\\Scripts\\python.exe\n",
            "\n",
            "üìÇ Project Directory: Section_1_ADK Foundations & Your AI Engineer Journey\n",
            "\n",
            "üìÑ Project Files:\n",
            "‚úÖ ..\\requirements.txt - Dependencies configuration\n",
            "‚úÖ ..\\.env.example - Environment template\n",
            "‚úÖ ..\\.env         - Your configuration (optional)\n",
            "\n",
            "üéâ Project structure ready!\n",
            "‚ñ∂Ô∏è Continue to dependency verification\n"
          ]
        }
      ],
      "source": [
        "# Multi-Provider Setup Verification\n",
        "print(\"üîç MULTI-PROVIDER SETUP VERIFICATION\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Check Python version\n",
        "version = sys.version_info\n",
        "print(f\"üêç Python Version: {version.major}.{version.minor}.{version.micro}\")\n",
        "\n",
        "if version.major == 3 and version.minor >= 9 and version.minor <= 11:\n",
        "    print(\"‚úÖ Python version perfect for Google ADK!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Consider Python 3.9-3.11 for best compatibility\")\n",
        "\n",
        "# Check virtual environment\n",
        "in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
        "print(f\"\\nüè† Virtual Environment: {'‚úÖ Active' if in_venv else '‚ùå Not Active'}\")\n",
        "\n",
        "if in_venv:\n",
        "    print(\"‚úÖ Using isolated development environment\")\n",
        "    print(f\"üìç Python path: {sys.executable}\")\n",
        "else:\n",
        "    print(\"üí° Activate virtual environment: .venv\\\\Scripts\\\\activate (Windows) or source .venv/bin/activate (Mac/Linux)\")\n",
        "\n",
        "# Check project structure\n",
        "current_dir = Path.cwd()\n",
        "print(f\"\\nüìÇ Project Directory: {current_dir.name}\")\n",
        "\n",
        "# Look for essential files\n",
        "essential_files = {\n",
        "    '..\\\\requirements.txt': 'Dependencies configuration',\n",
        "    '..\\\\.env.example': 'Environment template',\n",
        "    '..\\\\.env': 'Your configuration (optional)'\n",
        "}\n",
        "\n",
        "print(\"\\nüìÑ Project Files:\")\n",
        "setup_complete = True\n",
        "for file, description in essential_files.items():\n",
        "    if Path(file).exists():\n",
        "        print(f\"‚úÖ {file:<15} - {description}\")\n",
        "    else:\n",
        "        print(f\"‚ùå {file:<15} - {description} (MISSING)\")\n",
        "        if file != '.env':  # .env is created during setup\n",
        "            setup_complete = False\n",
        "\n",
        "if setup_complete:\n",
        "    print(\"\\nüéâ Project structure ready!\")\n",
        "    print(\"‚ñ∂Ô∏è Continue to dependency verification\")\n",
        "else:\n",
        "    print(\"\\nüîß Complete Phase 1 setup first\")\n",
        "    print(\"üí° Make sure you're in the correct project directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ COMPLETE MULTI-PROVIDER DEPENDENCIES CHECK\n",
            "==================================================\n",
            "\n",
            "üìã Core Framework:\n",
            "  ‚úÖ google.adk.agents    - Google ADK Framework\n",
            "  ‚úÖ dotenv               - Environment Management\n",
            "  ‚úÖ pydantic             - Data Validation & Settings\n",
            "  üéâ Core Framework: Complete (3/3)\n",
            "\n",
            "üìã Local AI (FREE):\n",
            "  ‚úÖ ollama               - Local Model Integration (Llama 3.2)\n",
            "  üéâ Local AI (FREE): Complete (1/1)\n",
            "\n",
            "üìã Major Cloud Providers:\n",
            "  ‚úÖ google.generativeai  - Google AI Studio\n",
            "  ‚úÖ openai               - OpenAI Integration\n",
            "  ‚úÖ anthropic            - Anthropic Integration\n",
            "  üéâ Major Cloud Providers: Complete (3/3)\n",
            "\n",
            "üìã Additional Cloud Providers:\n",
            "  ‚úÖ groq                 - Groq Fast Inference\n",
            "  ‚úÖ together             - Together AI Platform\n",
            "  ‚úÖ mistralai            - Mistral AI Platform\n",
            "  ‚úÖ cohere               - Cohere Platform\n",
            "  üéâ Additional Cloud Providers: Complete (4/4)\n",
            "\n",
            "üìã Multi-Provider Interface:\n",
            "  ‚úÖ litellm              - Universal LLM Interface\n",
            "  ‚úÖ requests             - HTTP Client\n",
            "  ‚úÖ httpx                - Modern HTTP Client\n",
            "  üéâ Multi-Provider Interface: Complete (3/3)\n",
            "\n",
            "üìã Development Environment:\n",
            "  ‚úÖ jupyter              - Jupyter Notebooks\n",
            "  ‚úÖ ipykernel            - Kernel Management\n",
            "  ‚úÖ rich                 - Enhanced Terminal Output\n",
            "  üéâ Development Environment: Complete (3/3)\n",
            "\n",
            "üìä Overall Installation Status: 17/17 packages\n",
            "üéâ ALL DEPENDENCIES INSTALLED!\n",
            "üöÄ Complete multi-provider development environment ready\n",
            "üåü You can use ANY supported LLM provider\n",
            "\n",
            "‚ñ∂Ô∏è Next: Configure your preferred providers in .env file\n"
          ]
        }
      ],
      "source": [
        "# Complete Multi-Provider Dependencies Verification\n",
        "print(\"üì¶ COMPLETE MULTI-PROVIDER DEPENDENCIES CHECK\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Comprehensive dependencies for multi-provider support\n",
        "dependencies = {\n",
        "    'Core Framework': {\n",
        "        'google.adk.agents': 'Google ADK Framework',\n",
        "        'dotenv': 'Environment Management',\n",
        "        'pydantic': 'Data Validation & Settings'\n",
        "    },\n",
        "    'Local AI (FREE)': {\n",
        "        'ollama': 'Local Model Integration (Llama 3.2)',\n",
        "    },\n",
        "    'Major Cloud Providers': {\n",
        "        'google.generativeai': 'Google AI Studio',\n",
        "        'openai': 'OpenAI Integration',\n",
        "        'anthropic': 'Anthropic Integration'\n",
        "    },\n",
        "    'Additional Cloud Providers': {\n",
        "        'groq': 'Groq Fast Inference',\n",
        "        'together': 'Together AI Platform',\n",
        "        'mistralai': 'Mistral AI Platform',\n",
        "        'cohere': 'Cohere Platform'\n",
        "    },\n",
        "    'Multi-Provider Interface': {\n",
        "        'litellm': 'Universal LLM Interface',\n",
        "        'requests': 'HTTP Client',\n",
        "        'httpx': 'Modern HTTP Client'\n",
        "    },\n",
        "    'Development Environment': {\n",
        "        'jupyter': 'Jupyter Notebooks',\n",
        "        'ipykernel': 'Kernel Management',\n",
        "        'rich': 'Enhanced Terminal Output'\n",
        "    }\n",
        "}\n",
        "\n",
        "total_deps = sum(len(deps) for deps in dependencies.values())\n",
        "installed_count = 0\n",
        "missing_deps = []\n",
        "\n",
        "for category, deps in dependencies.items():\n",
        "    print(f\"\\nüìã {category}:\")\n",
        "    category_installed = 0\n",
        "    category_total = len(deps)\n",
        "    \n",
        "    for package, description in deps.items():\n",
        "        try:\n",
        "            # Handle special import cases\n",
        "            if package == 'google.adk.agents':\n",
        "                from google.adk.agents import Agent\n",
        "            elif package == 'dotenv':\n",
        "                from dotenv import load_dotenv\n",
        "            elif package == 'mistralai':\n",
        "                import mistralai\n",
        "            else:\n",
        "                # Standard import\n",
        "                __import__(package.replace('-', '_'))\n",
        "            \n",
        "            print(f\"  ‚úÖ {package:<20} - {description}\")\n",
        "            installed_count += 1\n",
        "            category_installed += 1\n",
        "        except ImportError:\n",
        "            print(f\"  ‚ùå {package:<20} - {description} (MISSING)\")\n",
        "            missing_deps.append(package)\n",
        "    \n",
        "    # Category summary\n",
        "    if category_installed == category_total:\n",
        "        print(f\"  üéâ {category}: Complete ({category_installed}/{category_total})\")\n",
        "    elif category_installed > 0:\n",
        "        print(f\"  ‚ö†Ô∏è {category}: Partial ({category_installed}/{category_total})\")\n",
        "    else:\n",
        "        print(f\"  üö´ {category}: Missing ({category_installed}/{category_total})\")\n",
        "\n",
        "print(f\"\\nüìä Overall Installation Status: {installed_count}/{total_deps} packages\")\n",
        "\n",
        "# Smart recommendations based on what's missing\n",
        "if installed_count == total_deps:\n",
        "    print(\"üéâ ALL DEPENDENCIES INSTALLED!\")\n",
        "    print(\"üöÄ Complete multi-provider development environment ready\")\n",
        "    print(\"üåü You can use ANY supported LLM provider\")\n",
        "    \n",
        "elif installed_count >= (total_deps * 0.7):  # 70% or more\n",
        "    print(\"‚úÖ Core dependencies ready - mostly functional\")\n",
        "    print(f\"üí° {len(missing_deps)} optional packages missing\")\n",
        "    print(\"üìà You can proceed and add providers as needed\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Critical packages missing\")\n",
        "    print(\"üõë Course environment not ready\")\n",
        "    print(\"\\nüîß COMPLETE FIX:\")\n",
        "    print(\"1. Ensure virtual environment is activated:\")\n",
        "    print(\"   Windows: .venv\\\\Scripts\\\\activate\")\n",
        "    print(\"   Mac/Linux: source .venv/bin/activate\")\n",
        "    print(\"2. Install all dependencies:\")\n",
        "    print(\"   pip install -r requirements.txt\")\n",
        "    print(\"3. Restart Jupyter kernel\")\n",
        "    print(\"4. Re-run this cell\")\n",
        "\n",
        "print(\"\\n‚ñ∂Ô∏è Next: Configure your preferred providers in .env file\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß MULTI-PROVIDER CONFIGURATION TEST\n",
            "=============================================\n",
            "üìÑ Environment Configuration:\n",
            "üÜì Local Models Enabled: ‚úÖ YES\n",
            "üéØ Preferred Provider: local\n",
            "‚úÖ Configured for FREE local development (recommended!)\n",
            "ü§ñ Ollama URL: http://localhost:11434\n",
            "üì¶ Default Model: llama3.2\n",
            "‚úÖ Ollama running with 3 model(s):\n",
            "   üì¶ qwen2.5-coder:latest\n",
            "   üéØ llama3.2:1b (PERFECT for coding/agents!)\n",
            "   üéØ llama3.2:latest (PERFECT for coding/agents!)\n",
            "üéâ Llama 3.2 detected - optimized for enterprise agent tasks!\n",
            "\n",
            "‚òÅÔ∏è Cloud Provider Status:\n",
            "‚úÖ Google     - Configured\n",
            "üí§ OpenAI     - Not configured (optional)\n",
            "üí§ Anthropic  - Not configured (optional)\n",
            "‚úÖ Groq       - Configured\n",
            "‚úÖ Deepseek   - Configured\n",
            "\n",
            "üéØ Setup Assessment:\n",
            "‚úÖ Ready for FREE local development\n",
            "üöÄ You can start building immediately with zero costs\n",
            "üìà Plus 3 cloud provider(s) for scaling\n",
            "üéØ Llama 3.2 provides enterprise-grade capabilities for agent development\n",
            "\n",
            "‚ñ∂Ô∏è Next: Test Google ADK framework\n"
          ]
        }
      ],
      "source": [
        "# Multi-Provider Configuration Test\n",
        "print(\"üîß MULTI-PROVIDER CONFIGURATION TEST\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    import os\n",
        "    \n",
        "    # Load environment configuration\n",
        "    load_dotenv()\n",
        "    \n",
        "    print(\"üìÑ Environment Configuration:\")\n",
        "    \n",
        "    # Check local setup (preferred)\n",
        "    use_local = os.getenv('USE_LOCAL_MODELS', 'true').lower() == 'true'\n",
        "    preferred_provider = os.getenv('PREFERRED_PROVIDER', 'local')\n",
        "    \n",
        "    print(f\"üÜì Local Models Enabled: {'‚úÖ YES' if use_local else '‚ùå NO'}\")\n",
        "    print(f\"üéØ Preferred Provider: {preferred_provider}\")\n",
        "    \n",
        "    if use_local and preferred_provider == 'local':\n",
        "        print(\"‚úÖ Configured for FREE local development (recommended!)\")\n",
        "        \n",
        "        # Test Ollama connection\n",
        "        ollama_url = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')\n",
        "        ollama_model = os.getenv('OLLAMA_MODEL', 'llama3.2:1b')\n",
        "        print(f\"ü§ñ Ollama URL: {ollama_url}\")\n",
        "        print(f\"üì¶ Default Model: {ollama_model}\")\n",
        "        \n",
        "        try:\n",
        "            import requests\n",
        "            response = requests.get(f\"{ollama_url}/api/tags\", timeout=5)\n",
        "            if response.status_code == 200:\n",
        "                models = response.json().get('models', [])\n",
        "                if models:\n",
        "                    print(f\"‚úÖ Ollama running with {len(models)} model(s):\")\n",
        "                    for model in models[:3]:  # Show first 3\n",
        "                        model_name = model['name']\n",
        "                        if 'llama3.2' in model_name:\n",
        "                            print(f\"   üéØ {model_name} (PERFECT for coding/agents!)\")\n",
        "                        else:\n",
        "                            print(f\"   üì¶ {model_name}\")\n",
        "                    \n",
        "                    # Check if recommended model is available\n",
        "                    available_models = [m['name'] for m in models]\n",
        "                    if any('llama3.2' in name for name in available_models):\n",
        "                        print(\"üéâ Llama 3.2 detected - optimized for enterprise agent tasks!\")\n",
        "                    else:\n",
        "                        print(\"üí° Consider installing Llama 3.2: ollama pull llama3.2:1b\")\n",
        "                else:\n",
        "                    print(\"‚ö†Ô∏è Ollama running but no models installed\")\n",
        "                    print(\"üí° Install Llama 3.2: ollama pull llama3.2:1b\")\n",
        "            else:\n",
        "                print(\"‚ùå Ollama not responding\")\n",
        "                print(\"üí° Start Ollama service and install models\")\n",
        "        except Exception as e:\n",
        "            print(\"‚ùå Cannot connect to Ollama\")\n",
        "            print(\"üí° Start Ollama: Visit ollama.ai for installation\")\n",
        "            print(f\"   Error details: {str(e)[:100]}...\")\n",
        "    \n",
        "    # Check cloud provider configurations (optional)\n",
        "    print(\"\\n‚òÅÔ∏è Cloud Provider Status:\")\n",
        "    \n",
        "    cloud_providers = {\n",
        "        'Google': 'GOOGLE_API_KEY',\n",
        "        'OpenAI': 'OPENAI_API_KEY', \n",
        "        'Anthropic': 'ANTHROPIC_API_KEY',\n",
        "        'Groq': 'GROQ_API_KEY',\n",
        "        'Deepseek': 'DEEPSEEK_API_KEY'\n",
        "    }\n",
        "    \n",
        "    configured_providers = []\n",
        "    for provider, key_name in cloud_providers.items():\n",
        "        api_key = os.getenv(key_name)\n",
        "        if api_key and api_key != f'your-{key_name.lower().replace(\"_\", \"-\")}-here':\n",
        "            print(f\"‚úÖ {provider:<10} - Configured\")\n",
        "            configured_providers.append(provider)\n",
        "        else:\n",
        "            print(f\"üí§ {provider:<10} - Not configured (optional)\")\n",
        "    \n",
        "    # Smart configuration assessment\n",
        "    print(f\"\\nüéØ Setup Assessment:\")\n",
        "    if use_local:\n",
        "        print(\"‚úÖ Ready for FREE local development\")\n",
        "        print(\"üöÄ You can start building immediately with zero costs\")\n",
        "        if configured_providers:\n",
        "            print(f\"üìà Plus {len(configured_providers)} cloud provider(s) for scaling\")\n",
        "        print(\"üéØ Llama 3.2 provides enterprise-grade capabilities for agent development\")\n",
        "    elif configured_providers:\n",
        "        print(f\"‚úÖ Ready for cloud development with {len(configured_providers)} provider(s)\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No providers configured\")\n",
        "        print(\"üí° Recommendation: Keep USE_LOCAL_MODELS=true for FREE learning\")\n",
        "    \n",
        "    print(\"\\n‚ñ∂Ô∏è Next: Test Google ADK framework\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Configuration error: {e}\")\n",
        "    print(\"\\nüîß TROUBLESHOOTING:\")\n",
        "    print(\"1. Make sure .env file exists (copy from .env.example)\")\n",
        "    print(\"2. Check file permissions\")\n",
        "    print(\"3. Verify environment variable syntax\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ GOOGLE ADK FRAMEWORK TEST\n",
            "=============================================\n",
            "‚úÖ Google ADK imported successfully\n",
            "ü§ñ Testing with local model: ollama/llama3.2:1b\n",
            "üí∞ Cost: $0.00 (FREE local development)\n",
            "üéØ Optimized for: Coding, agents, enterprise tasks\n",
            "‚úÖ Google ADK Agent created successfully\n",
            "   üìã Agent name: WorkspaceVerificationAgent\n",
            "   üß† Model: ollama/llama3.2:1b\n",
            "   üìù Instruction configured: ‚úÖ\n",
            "\n",
            "üîç ADK Framework Capabilities:\n",
            "‚úÖ Agent creation and configuration\n",
            "‚úÖ Model abstraction layer\n",
            "‚úÖ Instruction-based behavior\n",
            "‚úÖ Enterprise-grade architecture\n",
            "‚úÖ Multi-provider model support\n",
            "\n",
            "üéâ WORKSPACE SETUP COMPLETE!\n",
            "üöÄ Your Google ADK development workspace is fully ready!\n",
            "\n",
            "‚úÖ What you've accomplished:\n",
            "   üÜì FREE local development environment\n",
            "   üè† Isolated virtual environment (.venv)\n",
            "   üîß Multi-provider configuration\n",
            "   ü§ñ Google ADK framework ready\n",
            "   üì¶ Professional development tools\n",
            "   üéØ Llama 3.2 optimized for coding and agent tasks\n",
            "\n",
            "üí° Pro Tips:\n",
            "   üÜì You're starting with FREE Llama 3.2 models - perfect for learning coding and agents!\n",
            "   üìà Add cloud API keys to .env when you want to scale\n",
            "   üí∞ Local development = unlimited experimentation with zero cost\n",
            "   üéØ Llama 3.2 is optimized for the exact use cases you'll build in this course\n",
            "\n",
            "üéØ NEXT STEPS:\n",
            "   ‚ñ∂Ô∏è Proceed to: 'Your First Google ADK Agent'\n",
            "   ‚ñ∂Ô∏è Start building enterprise AI solutions!\n",
            "   ‚ñ∂Ô∏è Follow the same patterns Google uses internally\n"
          ]
        }
      ],
      "source": [
        "# Google ADK Framework Test\n",
        "print(\"üöÄ GOOGLE ADK FRAMEWORK TEST\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "try:\n",
        "    # Import Google ADK\n",
        "    from google.adk.agents import Agent\n",
        "    print(\"‚úÖ Google ADK imported successfully\")\n",
        "    \n",
        "    # Load configuration\n",
        "    from dotenv import load_dotenv\n",
        "    import os\n",
        "    load_dotenv()\n",
        "    \n",
        "    # Determine which model to use\n",
        "    use_local = os.getenv('USE_LOCAL_MODELS', 'true').lower() == 'true'\n",
        "    preferred_provider = os.getenv('PREFERRED_PROVIDER', 'local')\n",
        "    \n",
        "    if use_local and preferred_provider == 'local':\n",
        "        # Test with local model configuration\n",
        "        model_name = \"ollama/llama3.2:1b\"  # ADK format for Ollama\n",
        "        print(f\"ü§ñ Testing with local model: {model_name}\")\n",
        "        print(\"üí∞ Cost: $0.00 (FREE local development)\")\n",
        "        print(\"üéØ Optimized for: Coding, agents, enterprise tasks\")\n",
        "    else:\n",
        "        # Test with cloud model\n",
        "        model_name = os.getenv('GOOGLE_MODEL', 'gemini-1.5-flash')\n",
        "        print(f\"‚òÅÔ∏è Testing with cloud model: {model_name}\")\n",
        "        print(\"üí∞ Cost: ~$0.075 per 1M tokens\")\n",
        "    \n",
        "    # Create test agent (framework validation)\n",
        "    test_agent = Agent(\n",
        "        name=\"WorkspaceVerificationAgent\",\n",
        "        model=model_name,\n",
        "        instruction=\"You are a test agent created to verify the Google ADK development workspace is properly configured. You excel at coding tasks and enterprise agent workflows.\"\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ Google ADK Agent created successfully\")\n",
        "    print(f\"   üìã Agent name: {test_agent.name}\")\n",
        "    print(f\"   üß† Model: {test_agent.model}\")\n",
        "    print(f\"   üìù Instruction configured: {'‚úÖ' if test_agent.instruction else '‚ùå'}\")\n",
        "    \n",
        "    # Framework capabilities check\n",
        "    print(\"\\nüîç ADK Framework Capabilities:\")\n",
        "    print(\"‚úÖ Agent creation and configuration\")\n",
        "    print(\"‚úÖ Model abstraction layer\")\n",
        "    print(\"‚úÖ Instruction-based behavior\")\n",
        "    print(\"‚úÖ Enterprise-grade architecture\")\n",
        "    print(\"‚úÖ Multi-provider model support\")\n",
        "    \n",
        "    print(\"\\nüéâ WORKSPACE SETUP COMPLETE!\")\n",
        "    print(\"üöÄ Your Google ADK development workspace is fully ready!\")\n",
        "    \n",
        "    print(\"\\n‚úÖ What you've accomplished:\")\n",
        "    print(\"   üÜì FREE local development environment\")\n",
        "    print(\"   üè† Isolated virtual environment (.venv)\")\n",
        "    print(\"   üîß Multi-provider configuration\")\n",
        "    print(\"   ü§ñ Google ADK framework ready\")\n",
        "    print(\"   üì¶ Professional development tools\")\n",
        "    if use_local:\n",
        "        print(\"   üéØ Llama 3.2 optimized for coding and agent tasks\")\n",
        "    \n",
        "    print(\"\\nüí° Pro Tips:\")\n",
        "    if use_local:\n",
        "        print(\"   üÜì You're starting with FREE Llama 3.2 models - perfect for learning coding and agents!\")\n",
        "        print(\"   üìà Add cloud API keys to .env when you want to scale\")\n",
        "        print(\"   üí∞ Local development = unlimited experimentation with zero cost\")\n",
        "        print(\"   üéØ Llama 3.2 is optimized for the exact use cases you'll build in this course\")\n",
        "    \n",
        "    print(\"\\nüéØ NEXT STEPS:\")\n",
        "    print(\"   ‚ñ∂Ô∏è Proceed to: 'Your First Google ADK Agent'\")\n",
        "    print(\"   ‚ñ∂Ô∏è Start building enterprise AI solutions!\")\n",
        "    print(\"   ‚ñ∂Ô∏è Follow the same patterns Google uses internally\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Google ADK import failed: {e}\")\n",
        "    print(\"\\nüîß TROUBLESHOOTING:\")\n",
        "    print(\"1. Ensure virtual environment is activated\")\n",
        "    print(\"2. Run: pip install -r requirements.txt\")\n",
        "    print(\"3. Restart Jupyter kernel\")\n",
        "    print(\"4. Check requirements.txt includes google-adk\")\n",
        "    print(\"5. Verify kernel is set to 'Google ADK Multi-Provider'\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Setup issue: {e}\")\n",
        "    print(\"üí° Check your .env configuration\")\n",
        "    print(\"üí° Verify Ollama is running if using local models\")\n",
        "    print(\"üí° Ensure all dependencies are properly installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ Congratulations! Your Multi-Provider Development Workspace is Ready!\n",
        "\n",
        "### ‚úÖ What You've Successfully Built:\n",
        "\n",
        "üÜì **FREE Local Development** - Llama 3.2 with local models (zero API costs, optimized for coding/agents)  \n",
        "‚òÅÔ∏è **Multi-Cloud Ready** - Google, OpenAI, Anthropic, Groq, Deepseek configuration  \n",
        "üè† **Professional Environment** - VS Code, .venv, proper isolation  \n",
        "ü§ñ **Google ADK Framework** - Enterprise-grade agent development toolkit  \n",
        "üîß **Smart Configuration** - Intelligent provider selection and fallbacks  \n",
        "üí∞ **Cost Control** - Complete visibility and budget management  \n",
        "\n",
        "### üöÄ You're Now Ready For:\n",
        "\n",
        "**Immediate Learning:**\n",
        "- Build agents with FREE Llama 3.2 local models (enterprise-optimized)\n",
        "- Master Google's enterprise patterns\n",
        "- Unlimited experimentation (zero cost)\n",
        "- Professional development practices\n",
        "\n",
        "**Smart Scaling:**\n",
        "- Add cloud providers when needed\n",
        "- Compare performance across models\n",
        "- Optimize costs for production\n",
        "- Enterprise deployment patterns\n",
        "\n",
        "### üí° Your Competitive Advantage\n",
        "\n",
        "**Following the proven AI Agent Bootcamp pattern, you now have:**\n",
        "- **Barrier-free learning:** Start immediately without API costs\n",
        "- **Enterprise patterns:** Same architecture Google uses internally\n",
        "- **Provider flexibility:** Never locked into a single vendor\n",
        "- **Cost intelligence:** Always know what you're spending\n",
        "- **Professional setup:** Industry-standard development environment\n",
        "- **Optimized models:** Llama 3.2 specifically chosen for coding and agent tasks\n",
        "\n",
        "---\n",
        "\n",
        "## üîó Quick Reference Guide\n",
        "\n",
        "### Essential Commands:\n",
        "```bash\n",
        "# Activate your workspace\n",
        "cd google-adk-enterprise-agents\n",
        ".venv\\Scripts\\activate  # Windows\n",
        "source .venv/bin/activate  # Mac/Linux\n",
        "\n",
        "# Start Ollama (if using local models)\n",
        "ollama serve\n",
        "\n",
        "# Test local model\n",
        "ollama run llama3.2:1b \"Hello world\"\n",
        "\n",
        "# Install/update dependencies\n",
        "pip install -r requirements.txt\n",
        "\n",
        "# Create/update Jupyter kernel\n",
        "python -m ipykernel install --user --name=venv --display-name=\"Google ADK Multi-Provider\"\n",
        "\n",
        "# Open workspace\n",
        "code .\n",
        "```\n",
        "\n",
        "### Configuration Files:\n",
        "- **`.env`** - Your provider configurations (keep secure!)\n",
        "- **`requirements.txt`** - Python dependencies\n",
        "- **`.venv/`** - Virtual environment (don't commit to Git)\n",
        "- **`.env.example`** - Template for environment setup\n",
        "\n",
        "### Provider Cost Quick Reference:\n",
        "```\n",
        "Ollama (Llama 3.2):    $0.00/request     ‚Üê Start here! (Best for coding/agents)\n",
        "Groq (Llama3-8B):      $0.05/1M tokens   ‚Üê Fast inference\n",
        "Gemini Flash:          $0.075/1M tokens  ‚Üê Budget production\n",
        "GPT-4o-mini:           $0.15/1M tokens   ‚Üê Balanced production\n",
        "Claude Haiku:          $0.25/1M tokens   ‚Üê Quality production\n",
        "```\n",
        "\n",
        "### Troubleshooting Common Issues:\n",
        "\n",
        "**Import Errors:**\n",
        "- ‚úÖ Activate .venv first: `.venv\\Scripts\\activate`\n",
        "- ‚úÖ Install dependencies: `pip install -r requirements.txt`\n",
        "- ‚úÖ Restart Jupyter kernel\n",
        "\n",
        "**Ollama Issues:**\n",
        "- ‚úÖ Check if service is running: `ollama serve`\n",
        "- ‚úÖ Install models: `ollama pull llama3.2:1b`\n",
        "- ‚úÖ Test connection: `ollama run llama3.2:1b \"test\"`\n",
        "\n",
        "**API Errors:**\n",
        "- ‚úÖ Verify keys in .env file\n",
        "- ‚úÖ Check key format (no quotes, proper prefix)\n",
        "- ‚úÖ Ensure .env file is in project root\n",
        "\n",
        "**Kernel Issues:**\n",
        "- ‚úÖ Select \"Google ADK Multi-Provider\" kernel\n",
        "- ‚úÖ Restart kernel if imports fail\n",
        "- ‚úÖ Recreate kernel if needed\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Smart Development Strategy\n",
        "\n",
        "### Phase 1: Master with FREE Local (Recommended)\n",
        "‚úÖ Learn Google ADK patterns with Llama 3.2 (optimized for coding/agents)  \n",
        "‚úÖ Build and test unlimited agents (zero cost)  \n",
        "‚úÖ Experiment with different architectures  \n",
        "‚úÖ Develop confidence and expertise with enterprise-grade models  \n",
        "\n",
        "### Phase 2: Validate with Cloud (When Ready)\n",
        "‚úÖ Test key agents with cloud providers  \n",
        "‚úÖ Compare performance and costs  \n",
        "‚úÖ Validate production assumptions  \n",
        "‚úÖ Choose optimal provider mix  \n",
        "\n",
        "### Phase 3: Scale to Production (Advanced)\n",
        "‚úÖ Deploy with chosen providers  \n",
        "‚úÖ Implement monitoring and alerts  \n",
        "‚úÖ Optimize costs and performance  \n",
        "‚úÖ Enterprise security and compliance  \n",
        "\n",
        "---\n",
        "\n",
        "## üîÆ What's Next in Your Learning Journey\n",
        "\n",
        "### **Upcoming Lectures:**\n",
        "1. **Your First Google ADK Agent** - Build a working agent in 20 lines\n",
        "2. **Multi-Agent Architecture** - Design enterprise agent systems\n",
        "3. **Customer Service Automation** - Real-world agent orchestration\n",
        "4. **Enterprise Research Agent** - Advanced document processing\n",
        "5. **Production Deployment** - Scale to enterprise environments\n",
        "\n",
        "### **Portfolio Projects You'll Build:**\n",
        "- ü§ñ **Intelligent Customer Service System** - Multi-agent workflow\n",
        "- üìä **Enterprise Research Agent** - Document analysis and insights\n",
        "- üöÄ **Production-Ready Platform** - Full deployment with monitoring\n",
        "\n",
        "---\n",
        "\n",
        "### üèÅ Ready to Build Enterprise AI Agents!\n",
        "\n",
        "**Your multi-provider Google ADK development workspace is complete.**\n",
        "\n",
        "**Following the proven success pattern from AI Agent Bootcamp, you now have everything needed to master Google's enterprise agent development framework - starting completely FREE with Llama 3.2 models optimized for coding and agent tasks!**\n",
        "\n",
        "---\n",
        "\n",
        "*Next up: Build your first Google ADK agent in under 20 lines of code! üöÄ*\n",
        "\n",
        "**Click to the next lecture and let's start building enterprise AI solutions together!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Google ADK Multi-Provider",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
