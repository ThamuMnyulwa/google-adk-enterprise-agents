{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your First Google ADK Agent ü§ñ\n",
    "\n",
    "## From Zero to Working Agent in 5 Minutes\n",
    "\n",
    "**Module Duration:** 7 minutes | **Focus:** Quick success, confidence building, immediate results\n",
    "\n",
    "---\n",
    "\n",
    "### Welcome to Your First ADK Success! üéâ\n",
    "\n",
    "You're about to create your first AI agent using Google's Agent Development Kit - the same technology that powers Google's billion-dollar systems. But we're starting simple and building your confidence.\n",
    "\n",
    "**What You'll Build Today:**\n",
    "- ‚úÖ A working AI agent in under 30 lines of code\n",
    "- ‚úÖ Test it with real conversations\n",
    "- ‚úÖ See the magic of Google ADK in action\n",
    "- ‚úÖ Understand the core concepts that power enterprise systems\n",
    "\n",
    "**Why This Matters:**\n",
    "- üöÄ **Same Framework as Google:** You're learning the actual technology Google uses internally\n",
    "- üíº **Career Value:** ADK skills are in high demand at $150K+ salaries\n",
    "- üéØ **Quick Win:** Working agent in minutes, not hours\n",
    "\n",
    "### üî• **Ready to Build Your First Agent?**\n",
    "Let's make some AI magic happen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Quick Environment Check ‚úÖ\n",
    "\n",
    "Let's make sure everything is ready for your first agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking Google ADK Environment...\n",
      "\n",
      "üÜì Option 1: FREE Local LLM (Ollama)\n",
      "‚úÖ Ollama running with Llama models: ['llama3.2:latest']\n",
      "\n",
      "üöÄ Option 2: Premium Google Gemini\n",
      "‚úÖ Google API key found\n",
      "üí∞ Cost: ~$0.15 per million tokens\n",
      "üåü Latest Gemini 2.0 capabilities\n",
      "\n",
      "üéØ Recommendations:\n",
      "‚úÖ Start with FREE Ollama - perfect for learning!\n",
      "‚úÖ Upgrade to Google Gemini for production features\n"
     ]
    }
   ],
   "source": [
    "# Core imports for Google ADK\n",
    "import os\n",
    "from google.adk.agents import Agent\n",
    "\n",
    "# Check environment configuration\n",
    "print(\"üîç Checking Google ADK Environment...\")\n",
    "\n",
    "# Option 1: FREE Local LLM (Ollama + Llama3.2)\n",
    "print(\"\\nüÜì Option 1: FREE Local LLM (Ollama)\")\n",
    "try:\n",
    "    import requests\n",
    "    response = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        models = response.json().get('models', [])\n",
    "        llama_models = [m['name'] for m in models if 'llama' in m['name'].lower()]\n",
    "        if llama_models:\n",
    "            print(f\"‚úÖ Ollama running with Llama models: {llama_models}\")\n",
    "            ollama_available = True\n",
    "            recommended_model = llama_models[0]  # Use first available\n",
    "        else:\n",
    "            print(\"‚ùå Ollama running but no Llama models found\")\n",
    "            print(\"üí° Install: ollama pull llama3.2\")\n",
    "            ollama_available = False\n",
    "    else:\n",
    "        print(\"‚ùå Ollama not responding\")\n",
    "        ollama_available = False\n",
    "except:\n",
    "    print(\"‚ùå Ollama not found\")\n",
    "    print(\"üí° Install: https://ollama.ai/download\")\n",
    "    ollama_available = False\n",
    "\n",
    "# Option 2: Premium Google Gemini\n",
    "print(\"\\nüöÄ Option 2: Premium Google Gemini\")\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if google_api_key:\n",
    "    print(\"‚úÖ Google API key found\")\n",
    "    print(\"üí∞ Cost: ~$0.15 per million tokens\")\n",
    "    print(\"üåü Latest Gemini 2.0 capabilities\")\n",
    "    google_available = True\n",
    "else:\n",
    "    print(\"‚ùå GOOGLE_API_KEY not found\")\n",
    "    print(\"üí° Set: export GOOGLE_API_KEY='your-key'\")\n",
    "    google_available = False\n",
    "\n",
    "# Show recommendations\n",
    "print(\"\\nüéØ Recommendations:\")\n",
    "if ollama_available:\n",
    "    print(\"‚úÖ Start with FREE Ollama - perfect for learning!\")\n",
    "if google_available:\n",
    "    print(\"‚úÖ Upgrade to Google Gemini for production features\")\n",
    "if not (ollama_available or google_available):\n",
    "    print(\"‚ùå Set up at least one option to continue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2A: Create Premium Google Agent üöÄ\n",
    "\n",
    "Experience Google's latest AI technology with enterprise-grade capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Creating Premium Google ADK Agent with Gemini...\n",
      "‚úÖ Premium Gemini Agent Created!\n",
      "   ü§ñ Name: PremiumGeminiAgent\n",
      "   üß† Model: Gemini 1.5 Flash\n",
      "   üí∞ Cost: ~$0.075 per million tokens\n",
      "   üåü Capabilities: Fast, reliable, production-ready\n",
      "‚úÖ ADK Runtime ready!\n",
      "\n",
      "üß™ TEST 1: Advanced Reasoning\n",
      "=============================================\n",
      "üí¨ Question: Explain how AI agents could transform enterprise customer service, including 3 specific use cases and potential ROI.\n",
      "ü§ñ Gemini thinking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Gemini: As PremiumGeminiAgent, a sophisticated AI agent leveraging Google's Gemini 1.5 Flash model, I can offer a detailed analysis of how AI agents will revolutionize enterprise customer service.  My advanced reasoning capabilities allow me to go beyond surface-level observations and delve into the strategic implications and quantifiable benefits.\n",
      "\n",
      "AI agents, unlike traditional rule-based chatbots, possess advanced capabilities like natural language understanding (NLU), contextual awareness, and machine learning, enabling them to handle a significantly wider range of customer inquiries with greater accuracy and empathy.  This transformation impacts several key aspects of customer service:\n",
      "\n",
      "**Transformation of Enterprise Customer Service:**\n",
      "\n",
      "* **24/7 Availability & Scalability:** AI agents can operate continuously, eliminating wait times and ensuring immediate responses to customer needs, regardless of time zones or peak demand.  This scalability is crucial for handling large volumes of inquiries without increasing operational costs proportionally.\n",
      "\n",
      "* **Personalized Experiences:** Through analysis of customer data (purchase history, interaction logs, etc.), AI agents can tailor interactions, providing personalized recommendations, proactive support, and targeted offers. This fosters customer loyalty and increases sales conversions.\n",
      "\n",
      "* **Enhanced Efficiency & Reduced Costs:** Automating routine tasks like answering FAQs, troubleshooting basic issues, and providing order status updates frees human agents to focus on complex problems and high-value interactions.  This significantly reduces operational costs associated with human agents while simultaneously improving overall customer satisfaction.\n",
      "\n",
      "* **Improved Data Analysis & Insights:**  The interaction data collected by AI agents offers valuable insights into customer preferences, pain points, and areas for process improvement. This data-driven approach allows businesses to make informed decisions to optimize their products, services, and customer service strategies.\n",
      "\n",
      "\n",
      "**Three Specific Use Cases and Potential ROI:**\n",
      "\n",
      "**1. Proactive Customer Support (Predictive Maintenance):**\n",
      "\n",
      "* **Use Case:**  For a telecommunications company, an AI agent could analyze network usage data and customer equipment performance to proactively identify potential issues (e.g., impending service outages).  It can then automatically notify affected customers, providing preventative solutions or scheduling maintenance visits before service disruptions occur.\n",
      "\n",
      "* **Potential ROI:** Reduced customer churn due to improved service reliability, minimized operational costs associated with reactive repairs, and enhanced customer satisfaction leading to increased brand loyalty and positive word-of-mouth marketing.  The ROI can be quantified by calculating the cost savings from prevented outages and the increased revenue from retained customers.\n",
      "\n",
      "\n",
      "**2. Omnichannel Support & Seamless Integration:**\n",
      "\n",
      "* **Use Case:** An e-commerce company can deploy an AI agent capable of handling customer inquiries across multiple channels (website chat, email, social media, mobile app). The agent maintains consistent context across all interactions, ensuring a seamless and personalized customer journey.\n",
      "\n",
      "* **Potential ROI:** Improved customer satisfaction through consistent and efficient service across all channels, reduced response times, and increased sales conversion rates due to enhanced customer experience. ROI can be calculated by measuring improvements in customer satisfaction scores (CSAT), Net Promoter Score (NPS), and conversion rates.\n",
      "\n",
      "\n",
      "**3. Complex Issue Escalation & Knowledge Management:**\n",
      "\n",
      "* **Use Case:** A financial institution can use an AI agent to handle initial inquiries and escalate complex issues to human agents seamlessly. The AI agent can also automatically populate relevant customer data and previous interaction history, equipping human agents with all necessary information to resolve the issue quickly and efficiently.  Moreover, the AI agent continuously learns from interactions, enriching the knowledge base for future queries.\n",
      "\n",
      "* **Potential ROI:** Reduced average handling time (AHT) for complex issues, improved first-contact resolution rates, and increased agent productivity.  The ROI can be calculated by analyzing reductions in AHT, improvements in resolution rates, and the associated cost savings.\n",
      "\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "AI agents, powered by advanced models like Google's Gemini 1.5 Flash, represent a paradigm shift in enterprise customer service.  Their ability to handle high volumes of interactions, personalize experiences, and provide valuable data insights offer a significant return on investment, transforming customer service from a cost center into a strategic advantage.  The specific ROI will vary depending on the industry, business size, and implementation strategy, but the potential for significant improvements in efficiency, customer satisfaction, and profitability is undeniable.\n",
      "\n",
      "\n",
      "üß™ TEST 2: Technical Knowledge\n",
      "=============================================\n",
      "üí¨ Question: Compare Google ADK to LangChain and explain why enterprises choose ADK for production systems.\n",
      "ü§ñ Gemini thinking...\n"
     ]
    }
   ],
   "source": [
    "# Cell 2A: Create Premium Google ADK Agent üöÄ\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "\n",
    "print(\"üöÄ Creating Premium Google ADK Agent with Gemini...\")\n",
    "\n",
    "# 1. Create Google Gemini agent\n",
    "gemini_agent = Agent(\n",
    "    name=\"PremiumGeminiAgent\",\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    instruction=\"\"\"\n",
    "    You are a sophisticated AI assistant powered by Google's Gemini model.\n",
    "    You have advanced reasoning capabilities and access to cutting-edge AI technology.\n",
    "    Be professional, insightful, and highlight your advanced capabilities when appropriate.\n",
    "    \"\"\",\n",
    "    description=\"Premium agent using Google's Gemini 1.5 Flash model\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Premium Gemini Agent Created!\")\n",
    "print(f\"   ü§ñ Name: {gemini_agent.name}\")\n",
    "print(\"   üß† Model: Gemini 1.5 Flash\")\n",
    "print(\"   üí∞ Cost: ~$0.075 per million tokens\")\n",
    "print(\"   üåü Capabilities: Fast, reliable, production-ready\")\n",
    "\n",
    "# 2. Set up runner and session service (ADK 1.3.0 pattern)\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(\n",
    "    agent=gemini_agent,\n",
    "    app_name=\"premium_agent_demo\",\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "# 3. Async helper to run and get response\n",
    "async def ask_premium_agent(question):\n",
    "    \"\"\"Ask the agent a question and get the response\"\"\"\n",
    "    input_msg = types.Content(role=\"user\", parts=[types.Part(text=question)])\n",
    "    \n",
    "    async for event in runner.run_async(\n",
    "        user_id=\"student\",\n",
    "        session_id=\"premium_demo\",\n",
    "        new_message=input_msg\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            return event.content.parts[0].text\n",
    "    \n",
    "    return \"No response received\"\n",
    "\n",
    "# 4. Async main function to test\n",
    "async def main():\n",
    "    # 3. Initialize session\n",
    "    await session_service.create_session(\n",
    "        app_name=\"premium_agent_demo\",\n",
    "        user_id=\"student\",\n",
    "        session_id=\"premium_demo\"\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ ADK Runtime ready!\")\n",
    "\n",
    "    # Test 1: Complex reasoning task\n",
    "    print(\"\\nüß™ TEST 1: Advanced Reasoning\")\n",
    "    print(\"=\"*45)\n",
    "\n",
    "    complex_question = \"Explain how AI agents could transform enterprise customer service, including 3 specific use cases and potential ROI.\"\n",
    "    print(f\"üí¨ Question: {complex_question}\")\n",
    "    print(\"ü§ñ Gemini thinking...\")\n",
    "\n",
    "    response1 = await ask_premium_agent(complex_question)\n",
    "    print(f\"üöÄ Gemini: {response1}\")\n",
    "\n",
    "    # Test 2: Technical explanation  \n",
    "    print(\"\\nüß™ TEST 2: Technical Knowledge\")\n",
    "    print(\"=\"*45)\n",
    "\n",
    "    tech_question = \"Compare Google ADK to LangChain and explain why enterprises choose ADK for production systems.\"\n",
    "    print(f\"üí¨ Question: {tech_question}\")\n",
    "    print(\"ü§ñ Gemini thinking...\")\n",
    "\n",
    "    response2 = await ask_premium_agent(tech_question)\n",
    "    print(f\"üöÄ Gemini: {response2}\")\n",
    "\n",
    "    print(\"\\nüåü Premium Gemini Agent showcasing advanced capabilities!\")\n",
    "    print(\"üí° Perfect for complex reasoning and enterprise applications\")\n",
    "    print(\"‚úÖ Using Google ADK 1.3.0 production patterns!\")\n",
    "\n",
    "# 5. Run it\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2B: Create FREE Local Agent üÜì\n",
    "\n",
    "Discover the power of completely free AI running on your own computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Why are local LLaMA models useful for developers?\n",
      "ü§ñ Thinking...\n",
      "\n",
      "üöÄ Response:\n",
      "As LocalLLaMAAgent, I can provide insights on the usefulness of local LLaMA models for developers.\n",
      "\n",
      "Local LLaMA models are trained on specific datasets and are designed to be lightweight, allowing them to run efficiently on edge devices or in resource-constrained environments. This makes them ideal for:\n",
      "\n",
      "1. **Edge AI applications**: Local LLaMA models can be deployed directly on edge devices, such as smartphones, smart home devices, or autonomous vehicles, without the need for cloud connectivity.\n",
      "2. **Low-latency responses**: By running locally, LLaMA models can provide faster response times and reduced latency, which is critical for real-time applications like voice assistants or chatbots.\n",
      "3. **Data privacy and security**: Local training reduces the amount of data that needs to be sent over the network, improving data privacy and security for sensitive applications.\n",
      "4. **Reduced bandwidth requirements**: With local models, developers can reduce the amount of bandwidth required to transmit data, making them suitable for applications with limited network connectivity or high latency.\n",
      "\n",
      "Overall, local LLaMA models offer several benefits for developers, including improved performance, reduced latency, and enhanced data security.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "\n",
    "# ‚úÖ Use LiteLLM to call Ollama's LLaMA 3.2 directly\n",
    "llm = LiteLlm(model=\"ollama_chat/llama3.2:latest\")  # Must match exactly from `ollama list`\n",
    "\n",
    "# Create Agent\n",
    "agent = Agent(\n",
    "    name=\"LocalLLaMAAgent\",\n",
    "    model=llm,\n",
    "    instruction=\"You are a helpful assistant powered by LLaMA 3.2 via Ollama. Answer clearly and concisely.\",\n",
    "    description=\"Local agent using Ollama\"\n",
    ")\n",
    "\n",
    "# Runtime setup\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(\n",
    "    agent=agent,\n",
    "    app_name=\"local_llama_demo\",\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "# Ask function\n",
    "async def ask_free_agent(question):\n",
    "    content = types.Content(role=\"user\", parts=[types.Part(text=question)])\n",
    "    async for event in runner.run_async(\n",
    "        user_id=\"local_user\",\n",
    "        session_id=\"local_session\",\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            return event.content.parts[0].text\n",
    "    return \"‚ùå No response\"\n",
    "\n",
    "# Main run\n",
    "async def main():\n",
    "    await session_service.create_session(\n",
    "        app_name=\"local_llama_demo\",\n",
    "        user_id=\"local_user\",\n",
    "        session_id=\"local_session\"\n",
    "    )\n",
    "    question = \"Why are local LLaMA models useful for developers?\"\n",
    "    print(f\"\\nüí¨ {question}\\nü§ñ Thinking...\\n\")\n",
    "    response = await ask_free_agent(question)\n",
    "    print(f\"üöÄ Response:\\n{response}\")\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Try Your Own Questions! üéØ\n",
    "\n",
    "Now it's your turn! Ask your agent anything you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ YOUR TURN TO CHAT!\n",
      "==============================\n",
      "üí° Try asking about:\n",
      "   - AI agent use cases\n",
      "   - Career advice\n",
      "   - Technical concepts\n",
      "   - Anything you're curious about!\n",
      "\n",
      "üé™ Demo Question: What are some real-world applications of AI agents that could transform businesses?\n",
      "üëÜ Edit the 'your_question' variable above to ask your own question!\n",
      "\n",
      "üöÄ Response:\n",
      "As LocalLLaMAAgent, I can share some real-world applications of AI agents that could transform businesses.\n",
      "\n",
      "1. **Virtual Customer Assistants**: AI-powered chatbots and virtual assistants can help businesses provide 24/7 customer support, improving user experience and reducing support costs.\n",
      "2. **Predictive Maintenance**: AI agents can analyze sensor data from equipment and predict maintenance needs, reducing downtime and increasing overall efficiency.\n",
      "3. **Intelligent Process Automation**: AI agents can automate routine tasks, such as data entry or bookkeeping, freeing up staff to focus on strategic work.\n",
      "4. **Personalized Product Recommendations**: AI-powered recommendation engines can help businesses offer personalized product suggestions, improving customer engagement and sales.\n",
      "5. **Supply Chain Optimization**: AI agents can analyze logistics data to optimize routes, schedules, and inventory levels, reducing costs and improving delivery times.\n",
      "6. **Fraud Detection and Prevention**: AI-powered systems can monitor transactions in real-time, detecting and preventing fraudulent activity before it occurs.\n",
      "7. **Content Generation and Curation**: AI agents can help businesses create and curate high-quality content, such as blog posts or social media updates, freeing up time for more strategic work.\n",
      "\n",
      "These are just a few examples of the many ways AI agents can transform businesses. By automating routine tasks, improving decision-making, and enhancing customer experiences, AI agents can drive growth, efficiency, and innovation in various industries.\n"
     ]
    }
   ],
   "source": [
    "# Your turn! Ask your agent anything\n",
    "print(\"üéØ YOUR TURN TO CHAT!\")\n",
    "print(\"=\" * 30)\n",
    "print(\"üí° Try asking about:\")\n",
    "print(\"   - AI agent use cases\")\n",
    "print(\"   - Career advice\")\n",
    "print(\"   - Technical concepts\")\n",
    "print(\"   - Anything you're curious about!\")\n",
    "print()\n",
    "\n",
    "# Change this question to whatever you want to ask!\n",
    "your_question = \"What are some real-world applications of AI agents that could transform businesses?\"\n",
    "\n",
    "print(f\"üé™ Demo Question: {your_question}\")\n",
    "print(\"üëÜ Edit the 'your_question' variable above to ask your own question!\")\n",
    "print()\n",
    "\n",
    "your_response = await ask_free_agent(your_question)\n",
    "print(f\"üöÄ Response:\\n{your_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Understanding What You Built üß†\n",
    "\n",
    "Let's take a moment to understand the amazing technology you just used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç UNDERSTANDING YOUR AGENT\n",
      "========================================\n",
      "\n",
      "ü§ñ What you just built:\n",
      "   ‚úÖ Agent Name: PremiumGeminiAgent\n",
      "   ‚úÖ AI Model: gemini-1.5-flash (Google's)\n",
      "   ‚úÖ Framework: Google ADK (same as Google's internal tools)\n",
      "   ‚úÖ Instruction: Custom personality and behavior\n",
      "\n",
      "üè¢ This is enterprise-grade technology:\n",
      "   üöÄ Same framework powering Google Agentspace\n",
      "   üíº Used by companies like Renault, Box, Mercedes-Benz\n",
      "   üéØ Production-ready from day one\n",
      "   ‚ö° Handles millions of requests in real systems\n",
      "\n",
      "üí° What makes this different from other AI tools:\n",
      "   ‚ú® Built for production, not just demos\n",
      "   üîß Enterprise features built-in\n",
      "   üåê A2A protocol for agent communication\n",
      "   üìä Monitoring and observability ready\n",
      "\n",
      "üéâ You've just used Google's enterprise AI technology!\n"
     ]
    }
   ],
   "source": [
    "# Let's explore what makes your agent special\n",
    "print(\"üîç UNDERSTANDING YOUR AGENT\")\n",
    "print(\"=\" * 40)\n",
    "print(\"\\nü§ñ What you just built:\")\n",
    "print(f\"   ‚úÖ Agent Name: {gemini_agent.name}\")\n",
    "print(f\"   ‚úÖ AI Model: {gemini_agent.model} (Google's)\")\n",
    "print(f\"   ‚úÖ Framework: Google ADK (same as Google's internal tools)\")\n",
    "print(f\"   ‚úÖ Instruction: Custom personality and behavior\")\n",
    "\n",
    "print(\"\\nüè¢ This is enterprise-grade technology:\")\n",
    "print(\"   üöÄ Same framework powering Google Agentspace\")\n",
    "print(\"   üíº Used by companies like Renault, Box, Mercedes-Benz\")\n",
    "print(\"   üéØ Production-ready from day one\")\n",
    "print(\"   ‚ö° Handles millions of requests in real systems\")\n",
    "\n",
    "print(\"\\nüí° What makes this different from other AI tools:\")\n",
    "print(\"   ‚ú® Built for production, not just demos\")\n",
    "print(\"   üîß Enterprise features built-in\")\n",
    "print(\"   üåê A2A protocol for agent communication\")\n",
    "print(\"   üìä Monitoring and observability ready\")\n",
    "\n",
    "print(\"\\nüéâ You've just used Google's enterprise AI technology!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Add a Simple Tool üõ†Ô∏è\n",
    "\n",
    "Let's make your agent even more powerful by giving it a tool to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Creating an upgraded agent with tools...\n",
      "‚úÖ Smart agent created with tools!\n",
      "üß∞ Tools available: ['get_current_time', 'calculate_simple_math']\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "\n",
    "# Define simple tool functions\n",
    "def get_current_time():\n",
    "    \"\"\"Returns the current date and time\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def calculate_simple_math(expression: str):\n",
    "    \"\"\"Safely calculate simple math expressions like '2 + 3 * 4'\"\"\"\n",
    "    try:\n",
    "        allowed = '0123456789+-*/(). '\n",
    "        if all(c in allowed for c in expression):\n",
    "            result = eval(expression)\n",
    "            return {\"result\": result}\n",
    "        return {\"error\": \"Only basic math allowed.\"}\n",
    "    except:\n",
    "        return {\"error\": \"Failed to calculate.\"}\n",
    "\n",
    "print(\"üõ†Ô∏è Creating an upgraded agent with tools...\")\n",
    "\n",
    "smart_agent = Agent(\n",
    "    name=\"SmartADKAgent\",\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    instruction=\"\"\"\n",
    "    You are a helpful AI assistant with two tools:\n",
    "    - get_current_time(): returns current timestamp\n",
    "    - calculate_simple_math(expr): returns basic arithmetic\n",
    "    Use them when asked, and explain your steps.\n",
    "    \"\"\",\n",
    "    tools=[get_current_time, calculate_simple_math],\n",
    "    description=\"Smart agent with time and math tools\"\n",
    ")\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(agent=smart_agent, app_name=\"smart_tool_agent\", session_service=session_service)\n",
    "await session_service.create_session(app_name=\"smart_tool_agent\", user_id=\"user\", session_id=\"tool_session\")\n",
    "\n",
    "print(\"‚úÖ Smart agent created with tools!\")\n",
    "print(f\"üß∞ Tools available: {[fn.__name__ for fn in smart_agent.tools]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING SMART AGENT WITH TOOLS\n",
      "========================================\n",
      "\n",
      "‚è∞ Test 1: Current Time\n",
      "üí¨ You: What time is it right now?\n",
      "ü§ñ Smart Agent is thinking and may invoke tools...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:59:00,138 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:00,138 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:00,139 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:00,819 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:00,822 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-06-14 19:59:00,823 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "None\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "name: get_current_time, args: {}\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.5635994911193848}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":5,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":5}],\"prompt_token_count\":126,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":126}],\"total_token_count\":131},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:01,218 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:01,222 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:01,223 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:03,087 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:03,089 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "The current time is 2025-06-14 19:59:00.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.000863324492596663}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":26,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":26}],\"prompt_token_count\":156,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":156}],\"total_token_count\":182},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Smart Agent: The current time is 2025-06-14 19:59:00.\n",
      "\n",
      "\n",
      "üßÆ Test 2: Math Calculation\n",
      "üí¨ You: Can you calculate 15 * 7 + 23 for me?\n",
      "ü§ñ Smart Agent is thinking and may invoke tools...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:59:03,441 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:03,441 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"Can you calculate 15 * 7 + 23 for me?\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:03,441 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:04,196 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:04,199 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-06-14 19:59:04,200 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "None\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "name: calculate_simple_math, args: {'expression': '15 * 7 + 23'}\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"function_call\":{\"args\":{\"expression\":\"15 * 7 + 23\"},\"name\":\"calculate_simple_math\"}}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.000024908779111380378}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":15,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":15}],\"prompt_token_count\":198,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":198}],\"total_token_count\":213},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:04,553 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:04,553 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"Can you calculate 15 * 7 + 23 for me?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{\"expression\":\"15 * 7 + 23\"},\"name\":\"calculate_simple_math\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"calculate_simple_math\",\"response\":{\"result\":128}}}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:04,554 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:05,145 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:05,148 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "The answer is 128.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"The answer is 128.\\n\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.07318317890167236}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":9,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":9}],\"prompt_token_count\":220,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":220}],\"total_token_count\":229},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Smart Agent: The answer is 128.\n",
      "\n",
      "\n",
      "üí° Test 3: Combined Conversation\n",
      "üí¨ You: What's the current time, and if I started learning ADK 2 hours ago, what time did I start?\n",
      "ü§ñ Smart Agent is thinking and may invoke tools...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:59:05,512 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:05,513 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"Can you calculate 15 * 7 + 23 for me?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{\"expression\":\"15 * 7 + 23\"},\"name\":\"calculate_simple_math\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"calculate_simple_math\",\"response\":{\"result\":128}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The answer is 128.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"What's the current time, and if I started learning ADK 2 hours ago, what time did I start?\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:05,513 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:06,207 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:06,209 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-06-14 19:59:06,210 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "None\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "name: get_current_time, args: {}\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.0317374587059021}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":5,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":5}],\"prompt_token_count\":254,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":254}],\"total_token_count\":259},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:06,561 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:06,561 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"Can you calculate 15 * 7 + 23 for me?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{\"expression\":\"15 * 7 + 23\"},\"name\":\"calculate_simple_math\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"calculate_simple_math\",\"response\":{\"result\":128}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The answer is 128.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"What's the current time, and if I started learning ADK 2 hours ago, what time did I start?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:06\"}}}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:06,562 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:07,453 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:07,456 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "The current time is 2025-06-14 19:59:06.  If you started learning ADK 2 hours ago, you started at 17:59:06.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:06.  If you started learning ADK 2 hours ago, you started at 17:59:06.\\n\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.024382451001335594}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":51,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":51}],\"prompt_token_count\":284,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":284}],\"total_token_count\":335},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Smart Agent: The current time is 2025-06-14 19:59:06.  If you started learning ADK 2 hours ago, you started at 17:59:06.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def test_smart_agent(question):\n",
    "    print(f\"üí¨ You: {question}\")\n",
    "    print(\"ü§ñ Smart Agent is thinking and may invoke tools...\")\n",
    "\n",
    "    content = types.Content(role=\"user\", parts=[types.Part(text=question)])\n",
    "    async for event in runner.run_async(user_id=\"user\", session_id=\"tool_session\", new_message=content):\n",
    "        if event.is_final_response():\n",
    "            print(f\"ü§ñ Smart Agent: {event.content.parts[0].text}\")\n",
    "\n",
    "print(\"üß™ TESTING SMART AGENT WITH TOOLS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\n‚è∞ Test 1: Current Time\")\n",
    "await test_smart_agent(\"What time is it right now?\")\n",
    "\n",
    "print(\"\\nüßÆ Test 2: Math Calculation\")\n",
    "await test_smart_agent(\"Can you calculate 15 * 7 + 23 for me?\")\n",
    "\n",
    "print(\"\\nüí° Test 3: Combined Conversation\")\n",
    "await test_smart_agent(\"What's the current time, and if I started learning ADK 2 hours ago, what time did I start?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations! You Built Your First Google ADK Agent!\n",
    "\n",
    "### üèÜ What You Just Accomplished:\n",
    "\n",
    "**‚úÖ Created AI Agents:**\n",
    "- Built your first basic agent with Google ADK\n",
    "- Created a smart agent with tools (time and math)\n",
    "- Used the same framework that powers Google's internal systems\n",
    "\n",
    "**‚úÖ Learned Core Concepts:**\n",
    "- Agent creation with `name`, `model`, and `instruction`\n",
    "- Tool integration for enhanced capabilities\n",
    "- Conversation handling with `await agent.run()`\n",
    "\n",
    "**‚úÖ Enterprise Foundation:**\n",
    "- You're using production-grade technology\n",
    "- Same patterns used by Fortune 500 companies\n",
    "- Ready to build more sophisticated systems\n",
    "\n",
    "### üöÄ Your AI Engineering Journey Starts Here\n",
    "\n",
    "**What This Means for Your Career:**\n",
    "- üíº **You're learning enterprise technology** - Google ADK is used in billion-dollar systems\n",
    "- üìà **High-demand skills** - ADK expertise commands $150K+ salaries\n",
    "- üéØ **Competitive advantage** - Most developers don't know this technology yet\n",
    "\n",
    "**Your Next Steps:**\n",
    "- üî® **Build More Agents** - Try different personalities and capabilities\n",
    "- üõ†Ô∏è **Add More Tools** - Web search, file processing, API integration\n",
    "- üè¢ **Enterprise Patterns** - Learn production deployment and monitoring\n",
    "- üíº **Portfolio Projects** - Create impressive projects for job interviews\n",
    "\n",
    "### üéØ Ready for More Advanced ADK?\n",
    "\n",
    "**In the next sections, you'll learn:**\n",
    "- Multi-agent systems that work together\n",
    "- Enterprise security and compliance\n",
    "- Production deployment and monitoring\n",
    "- Real-world business applications\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Try This at Home!\n",
    "\n",
    "**Experiment with your agent:**\n",
    "1. **Change the personality** - Make it funny, professional, or creative\n",
    "2. **Add new tools** - Weather, news, calculations\n",
    "3. **Try different questions** - Test its knowledge and capabilities\n",
    "4. **Share your success** - Show friends what you built with Google's technology!\n",
    "\n",
    "**Remember:** You just used the same technology that powers Google's billion-dollar AI systems. That's pretty amazing! üåü\n",
    "\n",
    "---\n",
    "\n",
    "*üéñÔ∏è Achievement Unlocked: Google ADK Developer*  \n",
    "*You've successfully created and tested AI agents using Google's enterprise framework!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
