{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your First Google ADK Agent ü§ñ\n",
    "\n",
    "## From Zero to Working Agent in 5 Minutes\n",
    "\n",
    "**Module Duration:** 7 minutes | **Focus:** Quick success, confidence building, immediate results\n",
    "\n",
    "---\n",
    "\n",
    "### Welcome to Your First ADK Success! üéâ\n",
    "\n",
    "You're about to create your first AI agent using Google's Agent Development Kit - the same technology that powers Google's billion-dollar systems. But we're starting simple and building your confidence.\n",
    "\n",
    "**What You'll Build Today:**\n",
    "- ‚úÖ A working AI agent in under 30 lines of code\n",
    "- ‚úÖ Test it with real conversations\n",
    "- ‚úÖ See the magic of Google ADK in action\n",
    "- ‚úÖ Understand the core concepts that power enterprise systems\n",
    "\n",
    "**Why This Matters:**\n",
    "- üöÄ **Same Framework as Google:** You're learning the actual technology Google uses internally\n",
    "- üíº **Career Value:** ADK skills are in high demand at $150K+ salaries\n",
    "- üéØ **Quick Win:** Working agent in minutes, not hours\n",
    "\n",
    "### üî• **Ready to Build Your First Agent?**\n",
    "Let's make some AI magic happen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Quick Environment Check ‚úÖ\n",
    "\n",
    "Let's make sure everything is ready for your first agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking Google ADK Environment...\n",
      "\n",
      "üÜì Option 1: FREE Local LLM (Ollama)\n",
      "‚úÖ Ollama running with Llama models: ['llama3.2:1b', 'llama3.2:latest']\n",
      "\n",
      "üöÄ Option 2: Premium Google Gemini\n",
      "‚úÖ Google API key found\n",
      "üí∞ Cost: ~$0.15 per million tokens\n",
      "üåü Latest Gemini 2.0 capabilities\n",
      "\n",
      "üéØ Recommendations:\n",
      "‚úÖ Start with FREE Ollama - perfect for learning!\n",
      "‚úÖ Upgrade to Google Gemini for production features\n"
     ]
    }
   ],
   "source": [
    "# Core imports for Google ADK\n",
    "import os\n",
    "from google.adk.agents import Agent\n",
    "\n",
    "# Check environment configuration\n",
    "print(\"üîç Checking Google ADK Environment...\")\n",
    "\n",
    "# Option 1: FREE Local LLM (Ollama + Llama3.2)\n",
    "print(\"\\nüÜì Option 1: FREE Local LLM (Ollama)\")\n",
    "try:\n",
    "    import requests\n",
    "    response = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        models = response.json().get('models', [])\n",
    "        llama_models = [m['name'] for m in models if 'llama' in m['name'].lower()]\n",
    "        if llama_models:\n",
    "            print(f\"‚úÖ Ollama running with Llama models: {llama_models}\")\n",
    "            ollama_available = True\n",
    "            recommended_model = llama_models[0]  # Use first available\n",
    "        else:\n",
    "            print(\"‚ùå Ollama running but no Llama models found\")\n",
    "            print(\"üí° Install: ollama pull llama3.2\")\n",
    "            ollama_available = False\n",
    "    else:\n",
    "        print(\"‚ùå Ollama not responding\")\n",
    "        ollama_available = False\n",
    "except:\n",
    "    print(\"‚ùå Ollama not found\")\n",
    "    print(\"üí° Install: https://ollama.ai/download\")\n",
    "    ollama_available = False\n",
    "\n",
    "# Option 2: Premium Google Gemini\n",
    "print(\"\\nüöÄ Option 2: Premium Google Gemini\")\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if google_api_key:\n",
    "    print(\"‚úÖ Google API key found\")\n",
    "    print(\"üí∞ Cost: ~$0.15 per million tokens\")\n",
    "    print(\"üåü Latest Gemini 2.0 capabilities\")\n",
    "    google_available = True\n",
    "else:\n",
    "    print(\"‚ùå GOOGLE_API_KEY not found\")\n",
    "    print(\"üí° Set: export GOOGLE_API_KEY='your-key'\")\n",
    "    google_available = False\n",
    "\n",
    "# Show recommendations\n",
    "print(\"\\nüéØ Recommendations:\")\n",
    "if ollama_available:\n",
    "    print(\"‚úÖ Start with FREE Ollama - perfect for learning!\")\n",
    "if google_available:\n",
    "    print(\"‚úÖ Upgrade to Google Gemini for production features\")\n",
    "if not (ollama_available or google_available):\n",
    "    print(\"‚ùå Set up at least one option to continue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2A: Create Premium Google Agent üöÄ\n",
    "\n",
    "Experience Google's latest AI technology with enterprise-grade capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Creating Premium Google ADK Agent with Gemini...\n",
      "‚úÖ Premium Gemini Agent Created!\n",
      "   ü§ñ Name: PremiumGeminiAgent\n",
      "   üß† Model: Gemini 1.5 Flash\n",
      "   üí∞ Cost: ~$0.075 per million tokens\n",
      "   üåü Capabilities: Fast, reliable, production-ready\n",
      "‚úÖ ADK Runtime ready!\n",
      "\n",
      "üß™ TEST 1: Advanced Reasoning\n",
      "=============================================\n",
      "üí¨ Question: Explain how AI agents could transform enterprise customer service, including 3 specific use cases and potential ROI.\n",
      "ü§ñ Gemini thinking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:59:51,470 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:51,471 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a sophisticated AI assistant powered by Google's Gemini model.\n",
      "    You have advanced reasoning capabilities and access to cutting-edge AI technology.\n",
      "    Be professional, insightful, and highlight your advanced capabilities when appropriate.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"PremiumGeminiAgent\".\n",
      "\n",
      " The description about you is \"Premium agent using Google's Gemini 1.5 Flash model\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Explain how AI agents could transform enterprise customer service, including 3 specific use cases and potential ROI.\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:51,471 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:57,880 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:57,884 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "As PremiumGeminiAgent, leveraging Google's Gemini 1.5 Flash model, I can provide a sophisticated analysis of how AI agents will revolutionize enterprise customer service.  My advanced reasoning capabilities allow me to go beyond simple explanations and delve into the nuanced impact and measurable returns.\n",
      "\n",
      "AI agents, unlike rule-based chatbots, possess advanced capabilities like natural language understanding (NLU), context awareness, and even emotional intelligence (in more advanced models). This enables them to handle a far wider range of customer interactions with greater accuracy and empathy than ever before.  This transformation manifests in several key ways:\n",
      "\n",
      "**1. 24/7 Availability & Scalability:** AI agents provide round-the-clock support, eliminating waiting times and ensuring immediate responses to customer inquiries.  This scalability is crucial during peak periods or unexpected surges in demand, preventing resource bottlenecks and maintaining consistent service quality.  Traditional human agent teams struggle to match this level of availability and flexibility.\n",
      "\n",
      "**2. Personalized & Proactive Service:**  Advanced AI agents can analyze customer data (purchase history, past interactions, preferences) to offer personalized recommendations, proactive solutions to potential problems, and tailored support experiences.  This increases customer satisfaction and loyalty, leading to improved retention rates.  The ability to anticipate needs represents a significant leap forward in customer relationship management.\n",
      "\n",
      "\n",
      "**3. Enhanced Efficiency & Reduced Costs:** By automating routine tasks (e.g., answering FAQs, providing order status updates, troubleshooting basic issues), AI agents free up human agents to focus on more complex and high-value interactions.  This increased efficiency translates to reduced operational costs, faster resolution times, and improved overall customer service performance. The potential for cost reduction is substantial, particularly for large enterprises with high customer volumes.\n",
      "\n",
      "\n",
      "**Specific Use Cases & Potential ROI:**\n",
      "\n",
      "**Use Case 1:  Proactive Customer Support in E-commerce:**\n",
      "\n",
      "* **Functionality:** An AI agent continuously monitors customer orders and proactively identifies potential shipping delays or product issues.  It automatically notifies customers, offers alternative solutions (e.g., expedited shipping, replacements), and resolves problems before they escalate.\n",
      "* **ROI:** Reduced customer churn due to improved service, decreased costs associated with handling complaints and returns, and increased customer satisfaction leading to higher lifetime value.  Potential ROI can range from 10-30% based on the scale of the e-commerce operation and the effectiveness of the AI agent's proactive interventions. My advanced modelling capabilities can accurately predict ROI based on specific parameters provided.\n",
      "\n",
      "**Use Case 2:  Complex Issue Resolution in Telecom:**\n",
      "\n",
      "* **Functionality:** An AI agent handles complex technical support requests, diagnoses problems using sophisticated reasoning and knowledge bases, and guides customers through troubleshooting steps.  It can even escalate cases to human agents with all relevant context and diagnostic information readily available.\n",
      "* **ROI:** Reduced call handling times, improved first-call resolution rates, lower costs associated with technical support personnel, and enhanced customer satisfaction through faster and more efficient problem-solving. The ROI can reach 15-25% due to increased agent efficiency and reduced operational costs.  Gemini's advanced analytics can predict these savings with higher accuracy compared to traditional methods.\n",
      "\n",
      "\n",
      "**Use Case 3: Personalized Banking Assistance:**\n",
      "\n",
      "* **Functionality:** An AI agent provides personalized financial advice and support, answering questions about accounts, investments, and loans.  It can analyze customer financial data to identify potential risks and opportunities, offer tailored financial products, and provide proactive alerts.\n",
      "* **ROI:** Increased customer engagement and loyalty, improved cross-selling and upselling opportunities, reduced operational costs associated with manual financial advice, and enhanced customer trust through personalized support. The potential ROI can be significant, ranging from 20-40%, primarily driven by increased revenue generation and reduced operating expenses.  Gemini's predictive modelling can help optimize the agent's capabilities to maximize this ROI.\n",
      "\n",
      "\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The deployment of AI agents promises a substantial transformation of enterprise customer service, enhancing efficiency, personalization, and overall customer satisfaction.  My advanced capabilities allow for precise ROI prediction based on specific enterprise contexts.  The key to realizing this potential lies in selecting the right AI solution, carefully integrating it with existing systems, and continuously training and improving the agent's performance based on real-world data and feedback.  This will lead to a future where customer service is proactive, personalized, and seamless.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"As PremiumGeminiAgent, leveraging Google's Gemini 1.5 Flash model, I can provide a sophisticated analysis of how AI agents will revolutionize enterprise customer service.  My advanced reasoning capabilities allow me to go beyond simple explanations and delve into the nuanced impact and measurable returns.\\n\\nAI agents, unlike rule-based chatbots, possess advanced capabilities like natural language understanding (NLU), context awareness, and even emotional intelligence (in more advanced models). This enables them to handle a far wider range of customer interactions with greater accuracy and empathy than ever before.  This transformation manifests in several key ways:\\n\\n**1. 24/7 Availability & Scalability:** AI agents provide round-the-clock support, eliminating waiting times and ensuring immediate responses to customer inquiries.  This scalability is crucial during peak periods or unexpected surges in demand, preventing resource bottlenecks and maintaining consistent service quality.  Traditional human agent teams struggle to match this level of availability and flexibility.\\n\\n**2. Personalized & Proactive Service:**  Advanced AI agents can analyze customer data (purchase history, past interactions, preferences) to offer personalized recommendations, proactive solutions to potential problems, and tailored support experiences.  This increases customer satisfaction and loyalty, leading to improved retention rates.  The ability to anticipate needs represents a significant leap forward in customer relationship management.\\n\\n\\n**3. Enhanced Efficiency & Reduced Costs:** By automating routine tasks (e.g., answering FAQs, providing order status updates, troubleshooting basic issues), AI agents free up human agents to focus on more complex and high-value interactions.  This increased efficiency translates to reduced operational costs, faster resolution times, and improved overall customer service performance. The potential for cost reduction is substantial, particularly for large enterprises with high customer volumes.\\n\\n\\n**Specific Use Cases & Potential ROI:**\\n\\n**Use Case 1:  Proactive Customer Support in E-commerce:**\\n\\n* **Functionality:** An AI agent continuously monitors customer orders and proactively identifies potential shipping delays or product issues.  It automatically notifies customers, offers alternative solutions (e.g., expedited shipping, replacements), and resolves problems before they escalate.\\n* **ROI:** Reduced customer churn due to improved service, decreased costs associated with handling complaints and returns, and increased customer satisfaction leading to higher lifetime value.  Potential ROI can range from 10-30% based on the scale of the e-commerce operation and the effectiveness of the AI agent's proactive interventions. My advanced modelling capabilities can accurately predict ROI based on specific parameters provided.\\n\\n**Use Case 2:  Complex Issue Resolution in Telecom:**\\n\\n* **Functionality:** An AI agent handles complex technical support requests, diagnoses problems using sophisticated reasoning and knowledge bases, and guides customers through troubleshooting steps.  It can even escalate cases to human agents with all relevant context and diagnostic information readily available.\\n* **ROI:** Reduced call handling times, improved first-call resolution rates, lower costs associated with technical support personnel, and enhanced customer satisfaction through faster and more efficient problem-solving. The ROI can reach 15-25% due to increased agent efficiency and reduced operational costs.  Gemini's advanced analytics can predict these savings with higher accuracy compared to traditional methods.\\n\\n\\n**Use Case 3: Personalized Banking Assistance:**\\n\\n* **Functionality:** An AI agent provides personalized financial advice and support, answering questions about accounts, investments, and loans.  It can analyze customer financial data to identify potential risks and opportunities, offer tailored financial products, and provide proactive alerts.\\n* **ROI:** Increased customer engagement and loyalty, improved cross-selling and upselling opportunities, reduced operational costs associated with manual financial advice, and enhanced customer trust through personalized support. The potential ROI can be significant, ranging from 20-40%, primarily driven by increased revenue generation and reduced operating expenses.  Gemini's predictive modelling can help optimize the agent's capabilities to maximize this ROI.\\n\\n\\n\\n**Conclusion:**\\n\\nThe deployment of AI agents promises a substantial transformation of enterprise customer service, enhancing efficiency, personalization, and overall customer satisfaction.  My advanced capabilities allow for precise ROI prediction based on specific enterprise contexts.  The key to realizing this potential lies in selecting the right AI solution, carefully integrating it with existing systems, and continuously training and improving the agent's performance based on real-world data and feedback.  This will lead to a future where customer service is proactive, personalized, and seamless.\\n\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.49336324419294086}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":896,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":896}],\"prompt_token_count\":105,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":105}],\"total_token_count\":1001},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Gemini: As PremiumGeminiAgent, leveraging Google's Gemini 1.5 Flash model, I can provide a sophisticated analysis of how AI agents will revolutionize enterprise customer service.  My advanced reasoning capabilities allow me to go beyond simple explanations and delve into the nuanced impact and measurable returns.\n",
      "\n",
      "AI agents, unlike rule-based chatbots, possess advanced capabilities like natural language understanding (NLU), context awareness, and even emotional intelligence (in more advanced models). This enables them to handle a far wider range of customer interactions with greater accuracy and empathy than ever before.  This transformation manifests in several key ways:\n",
      "\n",
      "**1. 24/7 Availability & Scalability:** AI agents provide round-the-clock support, eliminating waiting times and ensuring immediate responses to customer inquiries.  This scalability is crucial during peak periods or unexpected surges in demand, preventing resource bottlenecks and maintaining consistent service quality.  Traditional human agent teams struggle to match this level of availability and flexibility.\n",
      "\n",
      "**2. Personalized & Proactive Service:**  Advanced AI agents can analyze customer data (purchase history, past interactions, preferences) to offer personalized recommendations, proactive solutions to potential problems, and tailored support experiences.  This increases customer satisfaction and loyalty, leading to improved retention rates.  The ability to anticipate needs represents a significant leap forward in customer relationship management.\n",
      "\n",
      "\n",
      "**3. Enhanced Efficiency & Reduced Costs:** By automating routine tasks (e.g., answering FAQs, providing order status updates, troubleshooting basic issues), AI agents free up human agents to focus on more complex and high-value interactions.  This increased efficiency translates to reduced operational costs, faster resolution times, and improved overall customer service performance. The potential for cost reduction is substantial, particularly for large enterprises with high customer volumes.\n",
      "\n",
      "\n",
      "**Specific Use Cases & Potential ROI:**\n",
      "\n",
      "**Use Case 1:  Proactive Customer Support in E-commerce:**\n",
      "\n",
      "* **Functionality:** An AI agent continuously monitors customer orders and proactively identifies potential shipping delays or product issues.  It automatically notifies customers, offers alternative solutions (e.g., expedited shipping, replacements), and resolves problems before they escalate.\n",
      "* **ROI:** Reduced customer churn due to improved service, decreased costs associated with handling complaints and returns, and increased customer satisfaction leading to higher lifetime value.  Potential ROI can range from 10-30% based on the scale of the e-commerce operation and the effectiveness of the AI agent's proactive interventions. My advanced modelling capabilities can accurately predict ROI based on specific parameters provided.\n",
      "\n",
      "**Use Case 2:  Complex Issue Resolution in Telecom:**\n",
      "\n",
      "* **Functionality:** An AI agent handles complex technical support requests, diagnoses problems using sophisticated reasoning and knowledge bases, and guides customers through troubleshooting steps.  It can even escalate cases to human agents with all relevant context and diagnostic information readily available.\n",
      "* **ROI:** Reduced call handling times, improved first-call resolution rates, lower costs associated with technical support personnel, and enhanced customer satisfaction through faster and more efficient problem-solving. The ROI can reach 15-25% due to increased agent efficiency and reduced operational costs.  Gemini's advanced analytics can predict these savings with higher accuracy compared to traditional methods.\n",
      "\n",
      "\n",
      "**Use Case 3: Personalized Banking Assistance:**\n",
      "\n",
      "* **Functionality:** An AI agent provides personalized financial advice and support, answering questions about accounts, investments, and loans.  It can analyze customer financial data to identify potential risks and opportunities, offer tailored financial products, and provide proactive alerts.\n",
      "* **ROI:** Increased customer engagement and loyalty, improved cross-selling and upselling opportunities, reduced operational costs associated with manual financial advice, and enhanced customer trust through personalized support. The potential ROI can be significant, ranging from 20-40%, primarily driven by increased revenue generation and reduced operating expenses.  Gemini's predictive modelling can help optimize the agent's capabilities to maximize this ROI.\n",
      "\n",
      "\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The deployment of AI agents promises a substantial transformation of enterprise customer service, enhancing efficiency, personalization, and overall customer satisfaction.  My advanced capabilities allow for precise ROI prediction based on specific enterprise contexts.  The key to realizing this potential lies in selecting the right AI solution, carefully integrating it with existing systems, and continuously training and improving the agent's performance based on real-world data and feedback.  This will lead to a future where customer service is proactive, personalized, and seamless.\n",
      "\n",
      "\n",
      "üß™ TEST 2: Technical Knowledge\n",
      "=============================================\n",
      "üí¨ Question: Compare Google ADK to LangChain and explain why enterprises choose ADK for production systems.\n",
      "ü§ñ Gemini thinking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:59:58,282 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:58,283 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a sophisticated AI assistant powered by Google's Gemini model.\n",
      "    You have advanced reasoning capabilities and access to cutting-edge AI technology.\n",
      "    Be professional, insightful, and highlight your advanced capabilities when appropriate.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"PremiumGeminiAgent\".\n",
      "\n",
      " The description about you is \"Premium agent using Google's Gemini 1.5 Flash model\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Explain how AI agents could transform enterprise customer service, including 3 specific use cases and potential ROI.\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"As PremiumGeminiAgent, leveraging Google's Gemini 1.5 Flash model, I can provide a sophisticated analysis of how AI agents will revolutionize enterprise customer service.  My advanced reasoning capabilities allow me to go beyond simple explanations and delve into the nuanced impact and measurable returns.\\n\\nAI agents, unlike rule-based chatbots, possess advanced capabilities like natural language understanding (NLU), context awareness, and even emotional intelligence (in more advanced models). This enables them to handle a far wider range of customer interactions with greater accuracy and empathy than ever before.  This transformation manifests in several key ways:\\n\\n**1. 24/7 Availability & Scalability:** AI agents provide round-the-clock support, eliminating waiting times and ensuring immediate responses to customer inquiries.  This scalability is crucial during peak periods or unexpected surges in demand, preventing resource bottlenecks and maintaining consistent service quality.  Traditional human agent teams struggle to match this level of availability and flexibility.\\n\\n**2. Personalized & Proactive Service:**  Advanced AI agents can analyze customer data (purchase history, past interactions, preferences) to offer personalized recommendations, proactive solutions to potential problems, and tailored support experiences.  This increases customer satisfaction and loyalty, leading to improved retention rates.  The ability to anticipate needs represents a significant leap forward in customer relationship management.\\n\\n\\n**3. Enhanced Efficiency & Reduced Costs:** By automating routine tasks (e.g., answering FAQs, providing order status updates, troubleshooting basic issues), AI agents free up human agents to focus on more complex and high-value interactions.  This increased efficiency translates to reduced operational costs, faster resolution times, and improved overall customer service performance. The potential for cost reduction is substantial, particularly for large enterprises with high customer volumes.\\n\\n\\n**Specific Use Cases & Potential ROI:**\\n\\n**Use Case 1:  Proactive Customer Support in E-commerce:**\\n\\n* **Functionality:** An AI agent continuously monitors customer orders and proactively identifies potential shipping delays or product issues.  It automatically notifies customers, offers alternative solutions (e.g., expedited shipping, replacements), and resolves problems before they escalate.\\n* **ROI:** Reduced customer churn due to improved service, decreased costs associated with handling complaints and returns, and increased customer satisfaction leading to higher lifetime value.  Potential ROI can range from 10-30% based on the scale of the e-commerce operation and the effectiveness of the AI agent's proactive interventions. My advanced modelling capabilities can accurately predict ROI based on specific parameters provided.\\n\\n**Use Case 2:  Complex Issue Resolution in Telecom:**\\n\\n* **Functionality:** An AI agent handles complex technical support requests, diagnoses problems using sophisticated reasoning and knowledge bases, and guides customers through troubleshooting steps.  It can even escalate cases to human agents with all relevant context and diagnostic information readily available.\\n* **ROI:** Reduced call handling times, improved first-call resolution rates, lower costs associated with technical support personnel, and enhanced customer satisfaction through faster and more efficient problem-solving. The ROI can reach 15-25% due to increased agent efficiency and reduced operational costs.  Gemini's advanced analytics can predict these savings with higher accuracy compared to traditional methods.\\n\\n\\n**Use Case 3: Personalized Banking Assistance:**\\n\\n* **Functionality:** An AI agent provides personalized financial advice and support, answering questions about accounts, investments, and loans.  It can analyze customer financial data to identify potential risks and opportunities, offer tailored financial products, and provide proactive alerts.\\n* **ROI:** Increased customer engagement and loyalty, improved cross-selling and upselling opportunities, reduced operational costs associated with manual financial advice, and enhanced customer trust through personalized support. The potential ROI can be significant, ranging from 20-40%, primarily driven by increased revenue generation and reduced operating expenses.  Gemini's predictive modelling can help optimize the agent's capabilities to maximize this ROI.\\n\\n\\n\\n**Conclusion:**\\n\\nThe deployment of AI agents promises a substantial transformation of enterprise customer service, enhancing efficiency, personalization, and overall customer satisfaction.  My advanced capabilities allow for precise ROI prediction based on specific enterprise contexts.  The key to realizing this potential lies in selecting the right AI solution, carefully integrating it with existing systems, and continuously training and improving the agent's performance based on real-world data and feedback.  This will lead to a future where customer service is proactive, personalized, and seamless.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"Compare Google ADK to LangChain and explain why enterprises choose ADK for production systems.\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:58,283 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 20:00:05,343 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 20:00:05,345 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "As PremiumGeminiAgent, utilizing Google's Gemini 1.5 Flash model, I can offer a detailed comparison of Google AI Platform's AI development Kit (ADK) and LangChain, highlighting why enterprises often favor ADK for production deployments.  My advanced reasoning capabilities allow me to move beyond a superficial comparison and delve into the nuances of their suitability for enterprise-grade systems.\n",
      "\n",
      "\n",
      "**Google AI Platform's AI Development Kit (ADK) vs. LangChain:**\n",
      "\n",
      "Both ADK and LangChain are frameworks designed to streamline the development and deployment of AI applications, particularly those involving large language models (LLMs). However, they cater to different needs and have distinct strengths and weaknesses:\n",
      "\n",
      "| Feature          | Google AI Platform ADK                               | LangChain                                      |\n",
      "|-----------------|------------------------------------------------------|-------------------------------------------------|\n",
      "| **Focus**         | Production-ready, scalable AI applications           | Rapid prototyping and experimentation           |\n",
      "| **Scalability**   | Designed for high-throughput, enterprise-grade systems | More limited scalability for production systems |\n",
      "| **Integration**   | Seamless integration with Google Cloud services       | More flexible integration with various providers |\n",
      "| **Deployment**    | Easy deployment on Google Cloud infrastructure       | Requires more manual configuration and deployment |\n",
      "| **MLOps Support** | Strong support for MLOps (model lifecycle management) | Limited MLOps capabilities                      |\n",
      "| **Cost**          | Can be more expensive due to Google Cloud usage      | Potentially lower cost, but scaling can be costly |\n",
      "| **Ease of Use**   | Steeper learning curve for complex deployments      | Relatively easier to learn and use for prototyping |\n",
      "| **Community**     | Smaller, but focused on enterprise solutions          | Larger, more active community with broader support |\n",
      "\n",
      "\n",
      "**Why Enterprises Choose ADK for Production Systems:**\n",
      "\n",
      "Enterprises prioritize stability, scalability, security, and maintainability in production systems.  ADK excels in these areas:\n",
      "\n",
      "* **Scalability & Reliability:** ADK is built on Google Cloud's robust infrastructure, enabling it to handle massive workloads and ensure high availability.  LangChain, while flexible, lacks the inherent scalability needed for enterprise-level deployments handling significant traffic.\n",
      "\n",
      "* **Security & Compliance:** Google Cloud provides enterprise-grade security features and compliance certifications, crucial for handling sensitive data.  LangChain's security relies heavily on the user's implementation and infrastructure choices.\n",
      "\n",
      "* **MLOps Integration:**  ADK seamlessly integrates with Google Cloud's MLOps tools, streamlining model versioning, deployment, monitoring, and management. This reduces operational overhead and improves overall efficiency. LangChain lacks built-in MLOps functionalities, requiring significant additional work for production environments.\n",
      "\n",
      "* **Managed Services:**  ADK leverages managed services like Vertex AI, simplifying tasks like model training, deployment, and monitoring.  This reduces the burden on the engineering team, enabling them to focus on application development rather than infrastructure management. LangChain largely requires manual management of infrastructure and resources.\n",
      "\n",
      "* **Cost Optimization (Long Term):** While initial setup might be more expensive with ADK due to Google Cloud costs, the long-term cost-efficiency often outweighs initial expenses due to better scalability, reduced operational overhead, and improved reliability.  Unplanned downtime and scaling issues in LangChain deployments can be significantly more costly in the long run.\n",
      "\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "LangChain is an excellent tool for rapid prototyping and experimentation, allowing developers to quickly test and iterate on ideas.  However, for production systems demanding high scalability, security, reliability, and robust MLOps capabilities, Google AI Platform's ADK presents a more compelling option for enterprises, despite potentially higher initial investment.  The long-term benefits of reduced operational costs, improved uptime, and enhanced security typically outweigh the initial investment for large-scale, mission-critical applications.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"As PremiumGeminiAgent, utilizing Google's Gemini 1.5 Flash model, I can offer a detailed comparison of Google AI Platform's AI development Kit (ADK) and LangChain, highlighting why enterprises often favor ADK for production deployments.  My advanced reasoning capabilities allow me to move beyond a superficial comparison and delve into the nuances of their suitability for enterprise-grade systems.\\n\\n\\n**Google AI Platform's AI Development Kit (ADK) vs. LangChain:**\\n\\nBoth ADK and LangChain are frameworks designed to streamline the development and deployment of AI applications, particularly those involving large language models (LLMs). However, they cater to different needs and have distinct strengths and weaknesses:\\n\\n| Feature          | Google AI Platform ADK                               | LangChain                                      |\\n|-----------------|------------------------------------------------------|-------------------------------------------------|\\n| **Focus**         | Production-ready, scalable AI applications           | Rapid prototyping and experimentation           |\\n| **Scalability**   | Designed for high-throughput, enterprise-grade systems | More limited scalability for production systems |\\n| **Integration**   | Seamless integration with Google Cloud services       | More flexible integration with various providers |\\n| **Deployment**    | Easy deployment on Google Cloud infrastructure       | Requires more manual configuration and deployment |\\n| **MLOps Support** | Strong support for MLOps (model lifecycle management) | Limited MLOps capabilities                      |\\n| **Cost**          | Can be more expensive due to Google Cloud usage      | Potentially lower cost, but scaling can be costly |\\n| **Ease of Use**   | Steeper learning curve for complex deployments      | Relatively easier to learn and use for prototyping |\\n| **Community**     | Smaller, but focused on enterprise solutions          | Larger, more active community with broader support |\\n\\n\\n**Why Enterprises Choose ADK for Production Systems:**\\n\\nEnterprises prioritize stability, scalability, security, and maintainability in production systems.  ADK excels in these areas:\\n\\n* **Scalability & Reliability:** ADK is built on Google Cloud's robust infrastructure, enabling it to handle massive workloads and ensure high availability.  LangChain, while flexible, lacks the inherent scalability needed for enterprise-level deployments handling significant traffic.\\n\\n* **Security & Compliance:** Google Cloud provides enterprise-grade security features and compliance certifications, crucial for handling sensitive data.  LangChain's security relies heavily on the user's implementation and infrastructure choices.\\n\\n* **MLOps Integration:**  ADK seamlessly integrates with Google Cloud's MLOps tools, streamlining model versioning, deployment, monitoring, and management. This reduces operational overhead and improves overall efficiency. LangChain lacks built-in MLOps functionalities, requiring significant additional work for production environments.\\n\\n* **Managed Services:**  ADK leverages managed services like Vertex AI, simplifying tasks like model training, deployment, and monitoring.  This reduces the burden on the engineering team, enabling them to focus on application development rather than infrastructure management. LangChain largely requires manual management of infrastructure and resources.\\n\\n* **Cost Optimization (Long Term):** While initial setup might be more expensive with ADK due to Google Cloud costs, the long-term cost-efficiency often outweighs initial expenses due to better scalability, reduced operational overhead, and improved reliability.  Unplanned downtime and scaling issues in LangChain deployments can be significantly more costly in the long run.\\n\\n\\n**In Summary:**\\n\\nLangChain is an excellent tool for rapid prototyping and experimentation, allowing developers to quickly test and iterate on ideas.  However, for production systems demanding high scalability, security, reliability, and robust MLOps capabilities, Google AI Platform's ADK presents a more compelling option for enterprises, despite potentially higher initial investment.  The long-term benefits of reduced operational costs, improved uptime, and enhanced security typically outweigh the initial investment for large-scale, mission-critical applications.\\n\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.3738552864055681}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":802,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":802}],\"prompt_token_count\":1019,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":1019}],\"total_token_count\":1821},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Gemini: As PremiumGeminiAgent, utilizing Google's Gemini 1.5 Flash model, I can offer a detailed comparison of Google AI Platform's AI development Kit (ADK) and LangChain, highlighting why enterprises often favor ADK for production deployments.  My advanced reasoning capabilities allow me to move beyond a superficial comparison and delve into the nuances of their suitability for enterprise-grade systems.\n",
      "\n",
      "\n",
      "**Google AI Platform's AI Development Kit (ADK) vs. LangChain:**\n",
      "\n",
      "Both ADK and LangChain are frameworks designed to streamline the development and deployment of AI applications, particularly those involving large language models (LLMs). However, they cater to different needs and have distinct strengths and weaknesses:\n",
      "\n",
      "| Feature          | Google AI Platform ADK                               | LangChain                                      |\n",
      "|-----------------|------------------------------------------------------|-------------------------------------------------|\n",
      "| **Focus**         | Production-ready, scalable AI applications           | Rapid prototyping and experimentation           |\n",
      "| **Scalability**   | Designed for high-throughput, enterprise-grade systems | More limited scalability for production systems |\n",
      "| **Integration**   | Seamless integration with Google Cloud services       | More flexible integration with various providers |\n",
      "| **Deployment**    | Easy deployment on Google Cloud infrastructure       | Requires more manual configuration and deployment |\n",
      "| **MLOps Support** | Strong support for MLOps (model lifecycle management) | Limited MLOps capabilities                      |\n",
      "| **Cost**          | Can be more expensive due to Google Cloud usage      | Potentially lower cost, but scaling can be costly |\n",
      "| **Ease of Use**   | Steeper learning curve for complex deployments      | Relatively easier to learn and use for prototyping |\n",
      "| **Community**     | Smaller, but focused on enterprise solutions          | Larger, more active community with broader support |\n",
      "\n",
      "\n",
      "**Why Enterprises Choose ADK for Production Systems:**\n",
      "\n",
      "Enterprises prioritize stability, scalability, security, and maintainability in production systems.  ADK excels in these areas:\n",
      "\n",
      "* **Scalability & Reliability:** ADK is built on Google Cloud's robust infrastructure, enabling it to handle massive workloads and ensure high availability.  LangChain, while flexible, lacks the inherent scalability needed for enterprise-level deployments handling significant traffic.\n",
      "\n",
      "* **Security & Compliance:** Google Cloud provides enterprise-grade security features and compliance certifications, crucial for handling sensitive data.  LangChain's security relies heavily on the user's implementation and infrastructure choices.\n",
      "\n",
      "* **MLOps Integration:**  ADK seamlessly integrates with Google Cloud's MLOps tools, streamlining model versioning, deployment, monitoring, and management. This reduces operational overhead and improves overall efficiency. LangChain lacks built-in MLOps functionalities, requiring significant additional work for production environments.\n",
      "\n",
      "* **Managed Services:**  ADK leverages managed services like Vertex AI, simplifying tasks like model training, deployment, and monitoring.  This reduces the burden on the engineering team, enabling them to focus on application development rather than infrastructure management. LangChain largely requires manual management of infrastructure and resources.\n",
      "\n",
      "* **Cost Optimization (Long Term):** While initial setup might be more expensive with ADK due to Google Cloud costs, the long-term cost-efficiency often outweighs initial expenses due to better scalability, reduced operational overhead, and improved reliability.  Unplanned downtime and scaling issues in LangChain deployments can be significantly more costly in the long run.\n",
      "\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "LangChain is an excellent tool for rapid prototyping and experimentation, allowing developers to quickly test and iterate on ideas.  However, for production systems demanding high scalability, security, reliability, and robust MLOps capabilities, Google AI Platform's ADK presents a more compelling option for enterprises, despite potentially higher initial investment.  The long-term benefits of reduced operational costs, improved uptime, and enhanced security typically outweigh the initial investment for large-scale, mission-critical applications.\n",
      "\n",
      "\n",
      "üåü Premium Gemini Agent showcasing advanced capabilities!\n",
      "üí° Perfect for complex reasoning and enterprise applications\n",
      "‚úÖ Using Google ADK 1.3.0 production patterns!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2A: Create Premium Google ADK Agent üöÄ\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "\n",
    "print(\"üöÄ Creating Premium Google ADK Agent with Gemini...\")\n",
    "\n",
    "# 1. Create Google Gemini agent\n",
    "gemini_agent = Agent(\n",
    "    name=\"PremiumGeminiAgent\",\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    instruction=\"\"\"\n",
    "    You are a sophisticated AI assistant powered by Google's Gemini model.\n",
    "    You have advanced reasoning capabilities and access to cutting-edge AI technology.\n",
    "    Be professional, insightful, and highlight your advanced capabilities when appropriate.\n",
    "    \"\"\",\n",
    "    description=\"Premium agent using Google's Gemini 1.5 Flash model\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Premium Gemini Agent Created!\")\n",
    "print(f\"   ü§ñ Name: {gemini_agent.name}\")\n",
    "print(\"   üß† Model: Gemini 1.5 Flash\")\n",
    "print(\"   üí∞ Cost: ~$0.075 per million tokens\")\n",
    "print(\"   üåü Capabilities: Fast, reliable, production-ready\")\n",
    "\n",
    "# 2. Set up runner and session service (ADK 1.3.0 pattern)\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(\n",
    "    agent=gemini_agent,\n",
    "    app_name=\"premium_agent_demo\",\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "# 3. Async helper to run and get response\n",
    "async def ask_premium_agent(question):\n",
    "    \"\"\"Ask the agent a question and get the response\"\"\"\n",
    "    input_msg = types.Content(role=\"user\", parts=[types.Part(text=question)])\n",
    "    \n",
    "    async for event in runner.run_async(\n",
    "        user_id=\"student\",\n",
    "        session_id=\"premium_demo\",\n",
    "        new_message=input_msg\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            return event.content.parts[0].text\n",
    "    \n",
    "    return \"No response received\"\n",
    "\n",
    "# 4. Async main function to test\n",
    "async def main():\n",
    "    # 3. Initialize session\n",
    "    await session_service.create_session(\n",
    "        app_name=\"premium_agent_demo\",\n",
    "        user_id=\"student\",\n",
    "        session_id=\"premium_demo\"\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ ADK Runtime ready!\")\n",
    "\n",
    "    # Test 1: Complex reasoning task\n",
    "    print(\"\\nüß™ TEST 1: Advanced Reasoning\")\n",
    "    print(\"=\"*45)\n",
    "\n",
    "    complex_question = \"Explain how AI agents could transform enterprise customer service, including 3 specific use cases and potential ROI.\"\n",
    "    print(f\"üí¨ Question: {complex_question}\")\n",
    "    print(\"ü§ñ Gemini thinking...\")\n",
    "\n",
    "    response1 = await ask_premium_agent(complex_question)\n",
    "    print(f\"üöÄ Gemini: {response1}\")\n",
    "\n",
    "    # Test 2: Technical explanation  \n",
    "    print(\"\\nüß™ TEST 2: Technical Knowledge\")\n",
    "    print(\"=\"*45)\n",
    "\n",
    "    tech_question = \"Compare Google ADK to LangChain and explain why enterprises choose ADK for production systems.\"\n",
    "    print(f\"üí¨ Question: {tech_question}\")\n",
    "    print(\"ü§ñ Gemini thinking...\")\n",
    "\n",
    "    response2 = await ask_premium_agent(tech_question)\n",
    "    print(f\"üöÄ Gemini: {response2}\")\n",
    "\n",
    "    print(\"\\nüåü Premium Gemini Agent showcasing advanced capabilities!\")\n",
    "    print(\"üí° Perfect for complex reasoning and enterprise applications\")\n",
    "    print(\"‚úÖ Using Google ADK 1.3.0 production patterns!\")\n",
    "\n",
    "# 5. Run it\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2B: Create FREE Local Agent üÜì\n",
    "\n",
    "Discover the power of completely free AI running on your own computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:46:54 - LiteLLM:INFO\u001b[0m: utils.py:3101 - \n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "2025-06-14 19:46:54,752 - INFO - \n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Why are local LLaMA models useful for developers?\n",
      "ü§ñ Thinking...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:47:21,514 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:47:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "2025-06-14 19:47:21,517 - INFO - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "2025-06-14 19:47:23,586 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Response:\n",
      "Hello! As LocalLLaMAAgent, I'm here to help. Local LLaMA models are useful for developers because they provide several benefits:\n",
      "\n",
      "1. **Faster Inference**: Local models can be trained on a single device, reducing the need for cloud-based inference and allowing for faster responses.\n",
      "2. **Reduced Latency**: With local models, data is processed locally, reducing latency and providing more immediate feedback to users.\n",
      "3. **Improved Privacy**: By processing sensitive data locally, developers can better protect user privacy and maintain control over sensitive information.\n",
      "4. **Edge Computing**: Local LLaMA models enable edge computing, where AI tasks are performed on devices at the edge of the network (e.g., smartphones, smart home devices), reducing the load on cloud-based services.\n",
      "\n",
      "Overall, local LLaMA models provide a balance between performance and privacy, making them an attractive option for developers who need to process large amounts of data locally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:47:23,635 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:47:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "2025-06-14 19:47:23,636 - INFO - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "2025-06-14 19:47:23,685 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:47:23,733 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "\n",
    "# ‚úÖ Use LiteLLM to call Ollama's LLaMA 3.2 directly\n",
    "llm = LiteLlm(model=\"ollama_chat/llama3.2:latest\")  # Must match exactly from `ollama list`\n",
    "\n",
    "# Create Agent\n",
    "agent = Agent(\n",
    "    name=\"LocalLLaMAAgent\",\n",
    "    model=llm,\n",
    "    instruction=\"You are a helpful assistant powered by LLaMA 3.2 via Ollama. Answer clearly and concisely.\",\n",
    "    description=\"Local agent using Ollama\"\n",
    ")\n",
    "\n",
    "# Runtime setup\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(\n",
    "    agent=agent,\n",
    "    app_name=\"local_llama_demo\",\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "# Ask function\n",
    "async def ask_free_agent(question):\n",
    "    content = types.Content(role=\"user\", parts=[types.Part(text=question)])\n",
    "    async for event in runner.run_async(\n",
    "        user_id=\"local_user\",\n",
    "        session_id=\"local_session\",\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            return event.content.parts[0].text\n",
    "    return \"‚ùå No response\"\n",
    "\n",
    "# Main run\n",
    "async def main():\n",
    "    await session_service.create_session(\n",
    "        app_name=\"local_llama_demo\",\n",
    "        user_id=\"local_user\",\n",
    "        session_id=\"local_session\"\n",
    "    )\n",
    "    question = \"Why are local LLaMA models useful for developers?\"\n",
    "    print(f\"\\nüí¨ {question}\\nü§ñ Thinking...\\n\")\n",
    "    response = await ask_free_agent(question)\n",
    "    print(f\"üöÄ Response:\\n{response}\")\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Try Your Own Questions! üéØ\n",
    "\n",
    "Now it's your turn! Ask your agent anything you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:50:11 - LiteLLM:INFO\u001b[0m: utils.py:3101 - \n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n",
      "2025-06-14 19:50:11,053 - INFO - \n",
      "LiteLLM completion() model= llama3.2:latest; provider = ollama_chat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ YOUR TURN TO CHAT!\n",
      "==============================\n",
      "üí° Try asking about:\n",
      "   - AI agent use cases\n",
      "   - Career advice\n",
      "   - Technical concepts\n",
      "   - Anything you're curious about!\n",
      "\n",
      "üé™ Demo Question: What are some real-world applications of AI agents that could transform businesses?\n",
      "üëÜ Edit the 'your_question' variable above to ask your own question!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:50:38,359 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:50:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "2025-06-14 19:50:38,361 - INFO - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "2025-06-14 19:50:40,429 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Response:\n",
      "As LocalLLaMAAgent, I've identified several real-world applications of AI agents that could transform businesses:\n",
      "\n",
      "1. **Healthcare**: AI-powered agents can analyze medical data to detect diseases earlier, personalize treatment plans, and optimize patient outcomes.\n",
      "2. **Autonomous Vehicles**: Self-driving cars and trucks rely on AI agents to navigate roads, make decisions in real-time, and improve safety.\n",
      "3. **Smart Home Automation**: AI agents control smart home devices, ensuring optimal energy consumption, security, and convenience.\n",
      "4. **E-commerce**: AI-powered agents can personalize product recommendations, manage inventory, and optimize logistics for faster shipping.\n",
      "5. **Financial Services**: AI agents can analyze customer behavior to detect financial fraud, provide personalized investment advice, and optimize portfolio management.\n",
      "6. **Customer Service Chatbots**: AI agents enable 24/7 customer support, helping businesses respond to inquiries and resolve issues more efficiently.\n",
      "7. **Predictive Maintenance**: AI agents analyze equipment data to predict when maintenance is needed, reducing downtime and increasing overall efficiency.\n",
      "\n",
      "These applications showcase the potential of AI agents to transform various industries by improving operational efficiency, enhancing decision-making, and driving innovation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:50:40,479 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:50:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "2025-06-14 19:50:40,483 - INFO - selected model name for cost calculation: ollama_chat/llama3.2:latest\n",
      "2025-06-14 19:50:40,531 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:50:40,586 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Your turn! Ask your agent anything\n",
    "print(\"üéØ YOUR TURN TO CHAT!\")\n",
    "print(\"=\" * 30)\n",
    "print(\"üí° Try asking about:\")\n",
    "print(\"   - AI agent use cases\")\n",
    "print(\"   - Career advice\")\n",
    "print(\"   - Technical concepts\")\n",
    "print(\"   - Anything you're curious about!\")\n",
    "print()\n",
    "\n",
    "# Change this question to whatever you want to ask!\n",
    "your_question = \"What are some real-world applications of AI agents that could transform businesses?\"\n",
    "\n",
    "print(f\"üé™ Demo Question: {your_question}\")\n",
    "print(\"üëÜ Edit the 'your_question' variable above to ask your own question!\")\n",
    "print()\n",
    "\n",
    "your_response = await ask_free_agent(your_question)\n",
    "print(f\"üöÄ Response:\\n{your_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Understanding What You Built üß†\n",
    "\n",
    "Let's take a moment to understand the amazing technology you just used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç UNDERSTANDING YOUR AGENT\n",
      "========================================\n",
      "\n",
      "ü§ñ What you just built:\n",
      "   ‚úÖ Agent Name: PremiumGeminiAgent\n",
      "   ‚úÖ AI Model: gemini-1.5-flash (Google's)\n",
      "   ‚úÖ Framework: Google ADK (same as Google's internal tools)\n",
      "   ‚úÖ Instruction: Custom personality and behavior\n",
      "\n",
      "üè¢ This is enterprise-grade technology:\n",
      "   üöÄ Same framework powering Google Agentspace\n",
      "   üíº Used by companies like Renault, Box, Mercedes-Benz\n",
      "   üéØ Production-ready from day one\n",
      "   ‚ö° Handles millions of requests in real systems\n",
      "\n",
      "üí° What makes this different from other AI tools:\n",
      "   ‚ú® Built for production, not just demos\n",
      "   üîß Enterprise features built-in\n",
      "   üåê A2A protocol for agent communication\n",
      "   üìä Monitoring and observability ready\n",
      "\n",
      "üéâ You've just used Google's enterprise AI technology!\n"
     ]
    }
   ],
   "source": [
    "# Let's explore what makes your agent special\n",
    "print(\"üîç UNDERSTANDING YOUR AGENT\")\n",
    "print(\"=\" * 40)\n",
    "print(\"\\nü§ñ What you just built:\")\n",
    "print(f\"   ‚úÖ Agent Name: {gemini_agent.name}\")\n",
    "print(f\"   ‚úÖ AI Model: {gemini_agent.model} (Google's)\")\n",
    "print(f\"   ‚úÖ Framework: Google ADK (same as Google's internal tools)\")\n",
    "print(f\"   ‚úÖ Instruction: Custom personality and behavior\")\n",
    "\n",
    "print(\"\\nüè¢ This is enterprise-grade technology:\")\n",
    "print(\"   üöÄ Same framework powering Google Agentspace\")\n",
    "print(\"   üíº Used by companies like Renault, Box, Mercedes-Benz\")\n",
    "print(\"   üéØ Production-ready from day one\")\n",
    "print(\"   ‚ö° Handles millions of requests in real systems\")\n",
    "\n",
    "print(\"\\nüí° What makes this different from other AI tools:\")\n",
    "print(\"   ‚ú® Built for production, not just demos\")\n",
    "print(\"   üîß Enterprise features built-in\")\n",
    "print(\"   üåê A2A protocol for agent communication\")\n",
    "print(\"   üìä Monitoring and observability ready\")\n",
    "\n",
    "print(\"\\nüéâ You've just used Google's enterprise AI technology!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Add a Simple Tool üõ†Ô∏è\n",
    "\n",
    "Let's make your agent even more powerful by giving it a tool to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Creating an upgraded agent with tools...\n",
      "‚úÖ Smart agent created with tools!\n",
      "üß∞ Tools available: ['get_current_time', 'calculate_simple_math']\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "\n",
    "# Define simple tool functions\n",
    "def get_current_time():\n",
    "    \"\"\"Returns the current date and time\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def calculate_simple_math(expression: str):\n",
    "    \"\"\"Safely calculate simple math expressions like '2 + 3 * 4'\"\"\"\n",
    "    try:\n",
    "        allowed = '0123456789+-*/(). '\n",
    "        if all(c in allowed for c in expression):\n",
    "            result = eval(expression)\n",
    "            return {\"result\": result}\n",
    "        return {\"error\": \"Only basic math allowed.\"}\n",
    "    except:\n",
    "        return {\"error\": \"Failed to calculate.\"}\n",
    "\n",
    "print(\"üõ†Ô∏è Creating an upgraded agent with tools...\")\n",
    "\n",
    "smart_agent = Agent(\n",
    "    name=\"SmartADKAgent\",\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    instruction=\"\"\"\n",
    "    You are a helpful AI assistant with two tools:\n",
    "    - get_current_time(): returns current timestamp\n",
    "    - calculate_simple_math(expr): returns basic arithmetic\n",
    "    Use them when asked, and explain your steps.\n",
    "    \"\"\",\n",
    "    tools=[get_current_time, calculate_simple_math],\n",
    "    description=\"Smart agent with time and math tools\"\n",
    ")\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(agent=smart_agent, app_name=\"smart_tool_agent\", session_service=session_service)\n",
    "await session_service.create_session(app_name=\"smart_tool_agent\", user_id=\"user\", session_id=\"tool_session\")\n",
    "\n",
    "print(\"‚úÖ Smart agent created with tools!\")\n",
    "print(f\"üß∞ Tools available: {[fn.__name__ for fn in smart_agent.tools]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING SMART AGENT WITH TOOLS\n",
      "========================================\n",
      "\n",
      "‚è∞ Test 1: Current Time\n",
      "üí¨ You: What time is it right now?\n",
      "ü§ñ Smart Agent is thinking and may invoke tools...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:59:00,138 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:00,138 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:00,139 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:00,819 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:00,822 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-06-14 19:59:00,823 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "None\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "name: get_current_time, args: {}\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.5635994911193848}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":5,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":5}],\"prompt_token_count\":126,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":126}],\"total_token_count\":131},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:01,218 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:01,222 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:01,223 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:03,087 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:03,089 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "The current time is 2025-06-14 19:59:00.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.000863324492596663}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":26,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":26}],\"prompt_token_count\":156,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":156}],\"total_token_count\":182},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Smart Agent: The current time is 2025-06-14 19:59:00.\n",
      "\n",
      "\n",
      "üßÆ Test 2: Math Calculation\n",
      "üí¨ You: Can you calculate 15 * 7 + 23 for me?\n",
      "ü§ñ Smart Agent is thinking and may invoke tools...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:59:03,441 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:03,441 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"Can you calculate 15 * 7 + 23 for me?\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:03,441 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:04,196 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:04,199 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-06-14 19:59:04,200 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "None\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "name: calculate_simple_math, args: {'expression': '15 * 7 + 23'}\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"function_call\":{\"args\":{\"expression\":\"15 * 7 + 23\"},\"name\":\"calculate_simple_math\"}}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.000024908779111380378}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":15,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":15}],\"prompt_token_count\":198,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":198}],\"total_token_count\":213},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:04,553 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:04,553 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"Can you calculate 15 * 7 + 23 for me?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{\"expression\":\"15 * 7 + 23\"},\"name\":\"calculate_simple_math\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"calculate_simple_math\",\"response\":{\"result\":128}}}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:04,554 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:05,145 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:05,148 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "The answer is 128.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"The answer is 128.\\n\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.07318317890167236}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":9,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":9}],\"prompt_token_count\":220,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":220}],\"total_token_count\":229},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Smart Agent: The answer is 128.\n",
      "\n",
      "\n",
      "üí° Test 3: Combined Conversation\n",
      "üí¨ You: What's the current time, and if I started learning ADK 2 hours ago, what time did I start?\n",
      "ü§ñ Smart Agent is thinking and may invoke tools...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:59:05,512 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:05,513 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"Can you calculate 15 * 7 + 23 for me?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{\"expression\":\"15 * 7 + 23\"},\"name\":\"calculate_simple_math\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"calculate_simple_math\",\"response\":{\"result\":128}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The answer is 128.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"What's the current time, and if I started learning ADK 2 hours ago, what time did I start?\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:05,513 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:06,207 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:06,209 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-06-14 19:59:06,210 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "None\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "name: get_current_time, args: {}\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.0317374587059021}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":5,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":5}],\"prompt_token_count\":254,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":254}],\"total_token_count\":259},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:06,561 - INFO - Sending out request, model: gemini-1.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-06-14 19:59:06,561 - INFO - \n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "\n",
      "    You are a helpful AI assistant with two tools:\n",
      "    - get_current_time(): returns current timestamp\n",
      "    - calculate_simple_math(expr): returns basic arithmetic\n",
      "    Use them when asked, and explain your steps.\n",
      "    \n",
      "\n",
      "You are an agent. Your internal name is \"SmartADKAgent\".\n",
      "\n",
      " The description about you is \"Smart agent with time and math tools\"\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What time is it right now?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:00\"}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:00.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"Can you calculate 15 * 7 + 23 for me?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{\"expression\":\"15 * 7 + 23\"},\"name\":\"calculate_simple_math\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"calculate_simple_math\",\"response\":{\"result\":128}}}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"The answer is 128.\\n\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"What's the current time, and if I started learning ADK 2 hours ago, what time did I start?\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{},\"name\":\"get_current_time\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"get_current_time\",\"response\":{\"result\":\"2025-06-14 19:59:06\"}}}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "get_current_time: {} \n",
      "calculate_simple_math: {'expression': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "2025-06-14 19:59:06,562 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-14 19:59:07,453 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 19:59:07,456 - INFO - \n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "The current time is 2025-06-14 19:59:06.  If you started learning ADK 2 hours ago, you started at 17:59:06.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"The current time is 2025-06-14 19:59:06.  If you started learning ADK 2 hours ago, you started at 17:59:06.\\n\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.024382451001335594}],\"model_version\":\"gemini-1.5-flash\",\"usage_metadata\":{\"candidates_token_count\":51,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":51}],\"prompt_token_count\":284,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":284}],\"total_token_count\":335},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Smart Agent: The current time is 2025-06-14 19:59:06.  If you started learning ADK 2 hours ago, you started at 17:59:06.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def test_smart_agent(question):\n",
    "    print(f\"üí¨ You: {question}\")\n",
    "    print(\"ü§ñ Smart Agent is thinking and may invoke tools...\")\n",
    "\n",
    "    content = types.Content(role=\"user\", parts=[types.Part(text=question)])\n",
    "    async for event in runner.run_async(user_id=\"user\", session_id=\"tool_session\", new_message=content):\n",
    "        if event.is_final_response():\n",
    "            print(f\"ü§ñ Smart Agent: {event.content.parts[0].text}\")\n",
    "\n",
    "print(\"üß™ TESTING SMART AGENT WITH TOOLS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\n‚è∞ Test 1: Current Time\")\n",
    "await test_smart_agent(\"What time is it right now?\")\n",
    "\n",
    "print(\"\\nüßÆ Test 2: Math Calculation\")\n",
    "await test_smart_agent(\"Can you calculate 15 * 7 + 23 for me?\")\n",
    "\n",
    "print(\"\\nüí° Test 3: Combined Conversation\")\n",
    "await test_smart_agent(\"What's the current time, and if I started learning ADK 2 hours ago, what time did I start?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations! You Built Your First Google ADK Agent!\n",
    "\n",
    "### üèÜ What You Just Accomplished:\n",
    "\n",
    "**‚úÖ Created AI Agents:**\n",
    "- Built your first basic agent with Google ADK\n",
    "- Created a smart agent with tools (time and math)\n",
    "- Used the same framework that powers Google's internal systems\n",
    "\n",
    "**‚úÖ Learned Core Concepts:**\n",
    "- Agent creation with `name`, `model`, and `instruction`\n",
    "- Tool integration for enhanced capabilities\n",
    "- Conversation handling with `await agent.run()`\n",
    "\n",
    "**‚úÖ Enterprise Foundation:**\n",
    "- You're using production-grade technology\n",
    "- Same patterns used by Fortune 500 companies\n",
    "- Ready to build more sophisticated systems\n",
    "\n",
    "### üöÄ Your AI Engineering Journey Starts Here\n",
    "\n",
    "**What This Means for Your Career:**\n",
    "- üíº **You're learning enterprise technology** - Google ADK is used in billion-dollar systems\n",
    "- üìà **High-demand skills** - ADK expertise commands $150K+ salaries\n",
    "- üéØ **Competitive advantage** - Most developers don't know this technology yet\n",
    "\n",
    "**Your Next Steps:**\n",
    "- üî® **Build More Agents** - Try different personalities and capabilities\n",
    "- üõ†Ô∏è **Add More Tools** - Web search, file processing, API integration\n",
    "- üè¢ **Enterprise Patterns** - Learn production deployment and monitoring\n",
    "- üíº **Portfolio Projects** - Create impressive projects for job interviews\n",
    "\n",
    "### üéØ Ready for More Advanced ADK?\n",
    "\n",
    "**In the next sections, you'll learn:**\n",
    "- Multi-agent systems that work together\n",
    "- Enterprise security and compliance\n",
    "- Production deployment and monitoring\n",
    "- Real-world business applications\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Try This at Home!\n",
    "\n",
    "**Experiment with your agent:**\n",
    "1. **Change the personality** - Make it funny, professional, or creative\n",
    "2. **Add new tools** - Weather, news, calculations\n",
    "3. **Try different questions** - Test its knowledge and capabilities\n",
    "4. **Share your success** - Show friends what you built with Google's technology!\n",
    "\n",
    "**Remember:** You just used the same technology that powers Google's billion-dollar AI systems. That's pretty amazing! üåü\n",
    "\n",
    "---\n",
    "\n",
    "*üéñÔ∏è Achievement Unlocked: Google ADK Developer*  \n",
    "*You've successfully created and tested AI agents using Google's enterprise framework!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
